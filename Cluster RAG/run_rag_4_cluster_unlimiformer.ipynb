{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ragatouille\n",
    "!git clone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragatouille import RAGPretrainedModel\n",
    "\n",
    "\n",
    "indexes = []\n",
    "GROUP_NUM = 3 # 1, 2, or 3\n",
    "\n",
    "for i in range(GROUP_NUM+1):\n",
    "    path_to_index = \".ragatouille/colbert/indexes/GROUP{}_cluster{}\".format(GROUP_NUM, i)\n",
    "    RAG = RAGPretrainedModel.from_index(path_to_index)\n",
    "    indexes.append(RAG.as_langchain_retriever(k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.retrievers import BaseRetriever, RetrieverLike, RetrieverOutputLike\n",
    "from langchain_core.language_models import BaseLLM\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "\n",
    "\n",
    "\n",
    "class CustomRetriever(BaseRetriever):\n",
    "\n",
    "\n",
    "    vectorstore : List[RetrieverLike]\n",
    "\n",
    "    def flatten_extend(self, matrix):\n",
    "        flat_list = []\n",
    "        for row in matrix:\n",
    "            flat_list.extend(row)\n",
    "        return flat_list\n",
    "\n",
    "    def _get_relevant_documents(self, query: str, *, run_manager: CallbackManagerForRetrieverRun) -> List[Document]:\n",
    "\n",
    "        all_docs = []\n",
    "        for i in self.vectorstore:\n",
    "            all_docs.append(i.get_relevant_documents(query, k=3))\n",
    "\n",
    "        all_docs = self.flatten_extend(all_docs)\n",
    "        return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customRetriever = CustomRetriever(vectorstore=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionsFileName = \"FINALQUESTIONS.txt\"\n",
    "\n",
    "\n",
    "f = open(questionsFileName, \"r\")\n",
    "questions = f.readlines()\n",
    "f.close()\n",
    "\n",
    "questions = [i.strip() for i in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir unlimiformer/docs\n",
    "\n",
    "for count, i in enumerate(questions):\n",
    "  if (count % 100 == 0):\n",
    "    print(count)\n",
    "  doc = customRetriever.get_relevant_documents(i)\n",
    "  context = \"\"\n",
    "  for d in doc:\n",
    "    context += d.page_content + \"\\n\"\n",
    "\n",
    "  prompt = \"Question: {}\\n\\nContext: {}\\n\\nAnswer: \".format(i, context)\n",
    "  f = open(\"unlimiformer/docs/q{}.txt\".format(count), \"w\")\n",
    "  f.write(prompt)\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd unlimiformer\n",
    "\n",
    "!python src/run_generation.py --model_type llama --model_name_or_path meta-llama/Llama-2-7b-chat-hf \\\n",
    "    --prefix \"<s>[INST] <<SYS>>\\n You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use one sentence maximum and keep the answer CONCISE. Keep the answer CONCISE. \\n<</SYS>>\\n\\n\" \\\n",
    "    --prompt example_inputs/rag.txt \\\n",
    "    --suffix \" [/INST]\" --test_unlimiformer --fp16 --length 314 --layer_begin 36 \\\n",
    "    --index_devices 0 --datastore_device 0"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
