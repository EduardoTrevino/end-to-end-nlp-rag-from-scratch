{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade --quiet  langchain langchain-community langchainhub gpt4all chromadb \n",
    "# !pip3 install unstructured\n",
    "# !pip3 install sentence-transformers\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.embeddings import JinaEmbeddings\n",
    "\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [\"Web Scholar PDFs\", \"Data/About Scottie\", \"Data/Buggy News\", \"academic_calendars\", \"Data/history_of_cmu\", \"Data/history_of_scs\", \"Data/Kiltie Band\", \"Data/lti_faculty\", \"Data/lti_programs\", \"program_handbooks\", \"Data/Tartan Facts\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for i in directories:\n",
    "    loader = DirectoryLoader(i, glob=\"*\", exclude=\"annotation.txt\", show_progress=True)\n",
    "    docs.append(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = []\n",
    "for i in docs:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "    all_splits.append(text_splitter.split_documents(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "# with open('noWebScholarSplitDocuments.pkl', \"wb\") as f:\n",
    "#     pkl.dump(all_splits[1:], f)\n",
    "\n",
    "\n",
    "with open('splitDocuments.pkl','rb') as f: \n",
    "  all_splits = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "# model_name = \"Salesforce/SFR-Embedding-Mistral\"\n",
    "# model_kwargs = {\"device\": \"cuda\"}\n",
    "# embedding_function = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "\n",
    "# import chromadb.utils.embedding_functions as embedding_functions\n",
    "# huggingface_ef = embedding_functions.HuggingFaceEmbeddingFunction(\n",
    "#     model_name=\"BAAI/llm-embedder\"\n",
    "# )\n",
    "\n",
    "model_name = \"BAAI/llm-embedder\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "for i in all_splits:\n",
    "    vectorstore = Chroma.from_documents(documents=i, embedding=embeddings, persist_directory=\"llm-embedder/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
