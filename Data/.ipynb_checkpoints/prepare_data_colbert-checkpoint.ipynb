{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peparing triplet data for ColBERT/Ragatouille fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from ragatouille import RAGTrainer\n",
    "from ragatouille import RAGPretrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RAGTrainer\n",
    "# RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "trainer = RAGTrainer(model_name=\"colbertv2.0_cmu_lti_finetunev1.0\", pretrained_model_name=\"colbert-ir/colbertv2.0\", n_usable_gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store all documents\n",
    "all_documents = []\n",
    "# List to store raw data in the required format\n",
    "raw_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each folder and read documents and annotations\n",
    "for folder in [\"About Scottie\", \"Buggy News\", \"history_of_cmu\", \"history_of_scs\", \"Kiltie Band\", \"lti_faculty\", \"lti_programs\", \"Tartan Facts\"]:\n",
    "    folder_path = Path(folder)\n",
    "    # Read and store documents\n",
    "    for doc_file in folder_path.glob(\"*.txt\"):\n",
    "        if doc_file.name != \"annotation.txt\":\n",
    "            with open(doc_file, 'r', encoding='utf-8') as file:\n",
    "                all_documents.append(file.read())\n",
    "\n",
    "    # Read annotations and prepare raw data\n",
    "    annotation_path = folder_path / \"annotation.txt\"\n",
    "    with open(annotation_path, 'r', encoding='utf-8') as file:\n",
    "        annotations = file.read().split(\"\\n\\n\")  # Assuming each Q/A/D/T block is separated by two newlines\n",
    "#         raw_data = [(lines[0].replace(\"Q: \", \"\"), lines[1].replace(\"A: \", \"\")) for block in annotations for lines in [block.strip().split(\"\\n\")] if len(lines) == 4]\n",
    "        for block in annotations:\n",
    "            lines = block.split(\"\\n\")\n",
    "#             print(len(lines))\n",
    "            if len(lines) == 4:  # Ensure it's a full block\n",
    "                question = lines[0].replace(\"Q: \", \"\")\n",
    "                answer = lines[1].replace(\"A: \", \"\")\n",
    "                raw_data.append((question, answer))\n",
    "# #                 question = lines[0][3:]  # Remove \"Q: \"\n",
    "# #                 print(question)\n",
    "# #                 answer = lines[1][3:]  # Remove \"A: \"\n",
    "# #                 print(answer)\n",
    "# #                 doc_ref = lines[2][3:]  # Remove \"D: \"\n",
    "\n",
    "#                 question = lines[0].replace(\"Q: \", \"\")\n",
    "#                 answer = lines[1].replace(\"A: \", \"\")\n",
    "#                 print(f\"Appending: {question} | {answer}\")\n",
    "#                 # Here you could use the doc_ref to link the question-answer pair with the specific document content if needed\n",
    "#                 # For simplicity, we'll just use the question and answer for now\n",
    "#                 raw_data.append((question, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('When was The Kiltie Band founded?', 'The Kiltie Band was founded in 1908.'), ('Who founded Carnegie Mellon University and what type of pet did he keep?', 'Andrew Carnegie founded Carnegie Mellon University and had a Scottish terrier.'), ('When did Carnegie Mellon officially start the process to select a mascot?', 'The mascot selection process at Carnegie Mellon began in November 2006.'), ('Who co-chaired the Mascot Identity Task Force at Carnegie Mellon?', 'Susan Bassett and Jennifer Church co-chaired the Mascot Identity Task Force.'), ('How did the Carnegie Mellon community participate in the mascot selection process?', 'The community participated in the mascot choice through surveys and a Town Hall.'), ('What percentage of students voted for the Scottish terrier as the mascot in the 2007 survey?', '78% of 2,370 students voted for the Scottish terrier as the mascot in 2007.'), ('What misconception did approximately 25 percent of surveyed alumni have about the Scottish terrier?', '25% of surveyed alumni mistakenly believed the Scottish terrier was already the mascot.'), ('Which company did Carnegie Mellon partner with to develop the graphics for the mascot?', 'Carnegie Mellon collaborated with SME Branding for mascot graphics.'), ('When did the official mascot of Carnegie Mellon debut?', 'The mascot debuted at the home football game on Nov. 10, 2007.'), (\"What does the graphic of Carnegie Mellon's official mascot feature?\", 'The mascot graphic features a Scottish terrier with a plaid scarf in a shield.'), ('When was the official Scotty costume unveiled?', 'The Scotty costume was revealed at the 2008 Spring Carnival.'), (\"What breed is Carnegie Mellon University's mascot?\", \"The university's mascot is a Scottish terrier.\"), ('What was the role of focus groups in the mascot selection process?', 'Focus groups with students and alumni helped select the mascot image.'), ('What are some of the temperament traits of the Scottish Terrier breed?', 'The Scottish Terrier is known for its keen, alert, intelligence, and determined temperament.'), (\"Why was the Scottish Terrier chosen as Carnegie Mellon University's mascot?\", \"It was chosen as the mascot for embodying CMU's traits like strength, agility, and determination.\"), ('What physical aspects of the Scottish Terrier exemplify its representation as a mascot?', 'Its representation includes strength, power, and agility in a compact form.'), (\"How does the Scottish Terrier's temperament reflect on Carnegie Mellon University's ethos?\", \"The terrier's temperament of determination and thoughtfulness reflects CMU's ethos.\"), ('What qualities make the Scottish Terrier a natural choice for a university mascot, specifically Carnegie Mellon?', 'Its keen, alert intelligence, strength, and agility make it a fitting mascot for CMU.'), (\"Can you describe the Scottish Terrier's expression and how it relates to its role as a mascot?\", \"The terrier's keen, alert, and intelligent look symbolizes CMU's valued qualities.\"), (\"What are the key physical traits of the Scottish Terrier that align with Carnegie Mellon University's image?\", \"Key traits include strength, power, and agility, aligning with CMU's image.\"), (\"How does the Scottish Terrier's agility contribute to its symbolic representation for Carnegie Mellon University?\", \"Its agility symbolizes CMU's ability to adapt and innovate.\"), (\"In what way does the Scottish Terrier's determined temperament mirror the characteristics of Carnegie Mellon University?\", \"The terrier's determination mirrors CMU's dedication to excellence.\"), (\"How does the combination of physical and temperament traits of the Scottish Terrier enhance its suitability as Carnegie Mellon University's mascot?\", \"Its physical and temperament traits together symbolize CMU's values of strength, intelligence, and determination.\"), ('Who won the vote for the mascot of Carnegie Mellon University?', 'Nearly 78 percent of 2,370 students surveyed in February 2007 voted for the Scottish terrier.'), ('Why was the Scottish terrier chosen as the mascot of Carnegie Mellon University?', 'The Scottish terrier was chosen as the mascot because it won the vote in a series of surveys and a university Town Hall meeting. Additionally, Carnegie Mellon University had a history of connection with the breed.'), ('What is the graphic of the official mascot of Carnegie Mellon University?', \"The graphic of the official mascot of Carnegie Mellon University features a profile of a distinguished, bold Scottish terrier sporting a plaid scarf around his neck. The dog is contained in a shield, representing Carnegie Mellon's Scottish heritage.\"), ('What is the term \"Buggy\" used to describe in Sweepstakes slang?', 'Buggy refers to both the vehicle being raced and the competition itself.'), ('What does \"Chute\" signify in the context of the Buggy Races?', 'Chute is a section of the freeroll portion of the buggy course where buggies make a sharp right-hand turn from Schenley Drive onto Frew Street.'), ('Who is a \"Chute Flagger\"?', 'A Chute Flagger is a team member who signals buggy drivers to start the right-hand turn from Schenley Drive onto Frew Street.'), ('Define \"Driver\" in Sweepstakes terms.', 'A Driver is the person who controls the buggy via steering and braking systems while traveling with it.'), ('What is a \"Pushbar\"?', 'A Pushbar is a structure attached to a buggy that allows a person to push and propel the buggy forward.'), ('What role does a \"Pusher\" play in the Buggy Races?', 'A Pusher propels a buggy using a pushbar along one of the five hills of the buggy course.'), ('What is meant by \"Shell\" in the context of a buggy?', 'Shell refers to the entire outer structure or covering of a buggy that affects its aerodynamic characteristics.'), ('Explain \"Transition\" in Sweepstakes slang.', 'Transition is the process where one pusher finishes pushing a buggy, and the next pusher starts to push that same buggy.'), ('How long has the tradition of Sweepstakes, or Buggy Races, been running at Carnegie Mellon University?', 'The Buggy Races tradition at Carnegie Mellon University has been running for 104 years.'), ('What has changed about the vehicles used in the Buggy Races since its inception?', 'It changed froma a two-man teams changing places mid-race with simple constructions to slick, torpedo-like vessels requiring six people (five pushers and a driver) to maneuver a .84-mile course.'), ('How many people does it take to navigate the current Buggy Race course?', 'Six people.'), ('Where is the current Buggy Race course located?', \"The course goes around Schenley Park's Flagstaff Hill.\"), ('What are the basic components of a buggy?', 'A body, pushbar, wheels, a safety harness, and driving and braking mechanisms. Some also have fairings to reduce drag.'), ('How do teams typically approach the construction of their buggies?', 'Teams are often secretive about their construction methods, particularly regarding brakes, steering, and the types of wheels used.'), ('What is the significance of fairings in buggy construction?', 'Fairings are used to reduce drag, make the vehicle quieter, and enhance its appearance. They have been a key feature for the Fringe team.'), ('Can you name a team that is known for having quiet buggies on the course?', 'The Fringe team is known for having the quietest buggies on the course.'), ('How do teams name their buggies, and can you give examples?', 'Teams name their buggies based on themes. For example, Fringe names theirs with the letter \"B\" (e.g., Boson, Blueshift), Apex uses names connoting fire, and SDC uses names like Vice, Bane, Avarice, and Malice.'), ('When are new buggy names revealed to the public?', 'At the Buggy Showcase.'), ('Where are new buggy names revealed to the public?', '2 p.m. EST in Weigand Gymnasium in the Cohon University Center.'), ('What is required for a driver to qualify to race in the Buggy Races?', 'Each driver must log a number of practice runs to qualify to race.'), ('How do buggies accommodate their drivers?', 'Buggies are often built around their drivers, ensuring a snug fit. Drivers are often less than 5 feet, 3 inches in height, and most are women.'), ('What safety gear is required for all drivers?', 'Drivers are required to have five pieces of safety gear: mouth guard, goggles, a harness with three points of contact to the buggy, gloves, and a helmet.'), ('How does the condition of the race course impact the races?', 'The condition of the race course, especially potholes, can significantly affect the safety and speed of the races. Poorly filled potholes make it dangerous to drive.'), ('What challenges are faced by drivers due to the condition of the race course?', 'Potholes are create challenging conditions, potentially leading to most heats running just two lanes instead of three.'), ('Who was Andrew Carnegie?', \"Andrew Carnegie was a self-educated entrepreneur and industrialist who founded the world's largest steel producing company by the end of the 19th century.\"), ('What is Andrew Carnegie known for?', \"He is known for founding the world's largest steel producing company.\"), ('When did Andrew Carnegie emigrate from Scotland?', 'Andrew Carnegie emigrated from Scotland in 1848.'), ('Where did Andrew Carnegie settle when he emigrated from Scotland?', 'He settled in Pittsburgh, Pennsylvania.'), ('How did Andrew Carnegie educate himself?', 'He attended night school and borrowed books to educate himself.'), (\"What was Andrew Carnegie's job before he became a successful entrepreneur?\", 'Carnegie worked as a factory worker in a textile mill.'), ('How did Andrew Carnegie rise to prominence?', \"He rose to prominence by founding what became the world's largest steel producing company.\"), (\"What was Andrew Carnegie's nationality before he emigrated to the United States?\", 'Andrew Carnegie was Scottish before he emigrated to the United States.'), ('Was Andrew Carnegie always successful in his career?', 'No, he started as a factory worker in a textile mill before eventually becoming a successful entrepreneur and industrialist.'), ('How did Andrew Carnegie contribute to the industrial era in the United States?', \"Andrew Carnegie contributed to the industrial era by founding the world's largest steel producing company.\"), ('Who founded the Carnegie Technical Schools?', 'Andrew Carnegie founded the Carnegie Technical Schools.'), (\"What was Andrew Carnegie's belief about wealth?\", 'Andrew Carnegie believed that \"to die rich is to die disgraced.\"'), ('For what purpose did Andrew Carnegie donate $1 million in 1900?', 'He donated $1 million for the creation of a technical institute for the city of Pittsburgh.'), (\"What motto is associated with the Carnegie Technical Schools, reflecting Andrew Carnegie's values?\", 'The motto is \"My heart is in the work.\"'), ('What types of programs did the Carnegie Technical Schools offer?', 'The schools offered two- and three-year certificates in the arts and in engineering disciplines.'), ('Was there a specific college for women at the Carnegie Technical Schools? If so, what was its name?', 'Yes, there was a college for women named Margaret Morrison Carnegie College.'), ('How did Andrew Carnegie view his post-wealth phase of life?', 'He viewed it as a time for writing, social activism, and philanthropy, focusing on establishing educational opportunities.'), ('What demographic did the Carnegie Technical Schools primarily aim to serve?', 'The schools primarily aimed to serve working-class men and women of Pittsburgh.'), ('What transformation did Carnegie Technical Schools undergo in its early years?', 'Carnegie Technical Schools began offering bachelor\\'s degrees through its College of Engineering and College of Fine Arts, becoming the Carnegie Institute of Technology, or \"Carnegie Tech.\"'), ('How did Carnegie Tech expand during the first half of the 20th century?', 'It expanded from two buildings into an elegant 20th century campus designed in the beaux arts architectural style, with machine shops, studios, and laboratories.'), ('What pioneering educational programs did Carnegie Tech offer?', 'It pioneered conservatory degree programs in music and drama, as well as visual art and design programs, and awarded the first U.S. drama degree in 1914.'), ('When was the first doctorate awarded at Carnegie Tech, and in which field?', 'The first doctorate was awarded in 1919, in the field of civil engineering.'), ('Who received the first doctorate from Carnegie Tech?', 'Mao Yisheng, a student from China, received the first doctorate.'), ('How did Carnegie Tech contribute to the development of research institutions?', 'It laid the groundwork for a research institution by recruiting leading scientists, offering sponsored fellowships, and pioneering interdisciplinary research.'), ('What is the hallmark of Carnegie Mellon research, as established by Carnegie Tech?', 'Interdisciplinary research, bringing together various scientific disciplines, is the hallmark of Carnegie Mellon research.'), (\"What was the 'Carnegie Plan' initiated in 1938?\", \"The 'Carnegie Plan' required science and engineer students to take courses in humanities and social sciences to better understand the needs of society.\"), (\"How did Carnegie Tech's campus evolve architecturally in the early 20th century?\", 'The campus evolved into an elegant 20th century campus designed in the beaux arts architectural style.'), ('What was the significance of the first U.S. drama degree awarded at Carnegie Tech?', 'The awarding of the first U.S. drama degree in 1914 marked Carnegie Tech as a pioneer in conservatory degree programs for drama.'), ('In what year did Andrew Carnegie die, and what is said about his vision?', 'Andrew Carnegie died in 1919, and it is noted that his vision for an educated public lived on after him.'), ('How did Carnegie Tech address the practical learning aspect in its curriculum?', 'It housed a wealth of machine shops, studios, and laboratories as the hands-on center of learning.'), ('What was the first graduate degree offered by Carnegie Tech, and to whom?', 'The first graduate degree, a doctorate in civil engineering, was offered to Mao Yisheng.'), (\"How did Carnegie Tech's early curriculum adapt to societal needs?\", \"By initiating the 'Carnegie Plan' which required science and engineering students to take humanities and social sciences courses.\"), ('When did Carnegie Tech get its first IBM computer?', 'The first IBM computer arrived on campus in 1956.'), ('What major change happened at Carnegie Tech in 1973?', 'In 1973, Margaret Morrison closed, and women joined their male peers in classrooms and dorms.'), ('What was the first new school opened by Carnegie Tech in the post-war years, and what was it later renamed?', 'The first new school opened was the Graduate School of Industrial Administration in 1948, later renamed the David A. Tepper School of Business.'), ('What field did the David A. Tepper School of Business focus on?', 'The David A. Tepper School of Business focused on quantitative analysis and pioneered the field of management science.'), ('When was the School of Urban and Public Affairs opened, and what is its current name?', 'It was opened in 1968 and is currently named the H. John Heinz III College.'), ('What does the H. John Heinz III College specialize in?', 'The H. John Heinz III College provides graduate training for work in the public sector.'), ('When was the School of Computer Science founded, and what fields did it pioneer?', 'The School of Computer Science was founded in 1986, pioneering computing and artificial intelligence.'), ('Who were the interdisciplinary leaders of the School of Computer Science?', 'Allen Newell and Herbert Simon were the interdisciplinary leaders of the School of Computer Science.'), ('How did the university culture at Carnegie Tech change with the arrival of the first IBM computer?', 'The arrival of the first IBM computer initiated a culture where information technology pervaded virtually all areas of study.'), ('What was the impact of women joining male peers in classrooms and dorms in 1973?', 'It marked a significant change in university culture, promoting gender integration in academic and residential life.'), ('What was the primary focus of the newly founded schools at Carnegie Tech in the post-war years?', 'The focus was on management science, public sector training, and pioneering computing and artificial intelligence.'), ('How did Carnegie Tech position itself in the latter half of the 20th century?', 'Carnegie Tech positioned itself at the forefront of educational innovation by embracing information technology and expanding its academic offerings.'), ('When did Carnegie Tech merge with the Mellon Institute to become Carnegie Mellon University?', 'Carnegie Tech merged with the Mellon Institute to become Carnegie Mellon University in 1967.'), ('Who founded the Mellon Institute, which later merged with Carnegie Tech?', 'The Mellon Institute was founded by the Mellon family of Pittsburgh.'), ('What was the significance of the merger between Carnegie Tech and the Mellon Institute for Carnegie Mellon University?', 'The merger allowed Carnegie Mellon University to establish its last current pillars, including the Mellon College of Science and the College of Humanities and Social Sciences, enhancing its higher education, research, and discovery capabilities.'), ('What are the names of the two colleges established as a result of the Carnegie Tech and Mellon Institute merger?', 'The two colleges established were the Mellon College of Science and the College of Humanities and Social Sciences, now known as Marianna Brown Dietrich College of Humanities and Social Sciences.'), ('When did Carnegie Mellon celebrate the 50th anniversary of its founding through the merger?', 'Carnegie Mellon celebrated the 50th anniversary of the merger in 2017.'), ('What was the original name of the College of Humanities and Social Sciences at Carnegie Mellon?', 'The original name was the College of Humanities and Social Sciences before it was renamed to Marianna Brown Dietrich College of Humanities and Social Sciences.'), ('How has the merger between Carnegie Tech and the Mellon Institute impacted the world of higher education, according to the document?', 'The merger has had a significant impact on the world of higher education, research, and discovery.'), ('Who provided support for Carnegie Tech before its merger with the Mellon Institute?', 'The Mellon family of Pittsburgh provided support for Carnegie Tech before the merger.'), ('What is the importance of the Mellon family in the history of Carnegie Mellon University?', \"The Mellon family played a crucial role in the university's history through the founding of the Mellon Institute and their support for Carnegie Tech, which eventually led to the establishment of Carnegie Mellon University.\"), ('What vision was revisited during the 50th anniversary celebration of Carnegie Mellon University?', 'The shared vision of the founders was revisited during the 50th anniversary celebration.'), (\"How did the merger between Carnegie Tech and the Mellon Institute contribute to the establishment of Carnegie Mellon University's current structure?\", \"The merger contributed to the establishment of the university's current structure by adding the last of its current pillars, which include the Mellon College of Science and the College of Humanities and Social Sciences.\"), ('What is the future impact of the Carnegie Tech and Mellon Institute merger on Carnegie Mellon University?', 'The impact of the merger will continue to be significant in the future of higher education, research, and discovery.'), ('How long has Carnegie Mellon been established?', 'Carnegie Mellon has been established for 115 years.'), ('What is Carnegie Mellon known for?', 'Carnegie Mellon is known for innovation, solving real-world problems, and interdisciplinary collaboration.'), ('Can you list some fields where Carnegie Mellon alumni have excelled?', 'Carnegie Mellon alumni have excelled in various fields including winning Tony Awards, Nobel Prizes, Turing Awards, becoming CEOs, entrepreneurs, professors, and artists.'), ('When did Carnegie Mellon begin offering degree programs outside of Pittsburgh?', 'Carnegie Mellon began offering degree programs outside of Pittsburgh in the 2000s.'), ('Where does Carnegie Mellon have campuses?', 'Carnegie Mellon has campuses in Qatar and Silicon Valley, California.'), ('How many degree-granting locations does Carnegie Mellon have?', 'Carnegie Mellon has more than a dozen degree-granting locations.'), ('How many research partnerships does Carnegie Mellon have?', 'Carnegie Mellon has more than 20 research partnerships.'), ('Can you name a few places where Carnegie Mellon has research partnerships?', 'Carnegie Mellon has research partnerships in places like Los Angeles, New York City, Washington, D.C., Australia, China, Portugal, and Rwanda.'), (\"What was the reason for Carnegie Mellon's expansion to international educational opportunities?\", 'The expansion to international educational opportunities was in response to demand for expanded international educational opportunities.'), ('How has Carnegie Mellon contributed to innovation since its founding?', 'Carnegie Mellon has contributed to innovation by being a birthplace of innovation, known for solving real-world problems through interdisciplinary collaboration.'), (\"What types of professionals can be found among Carnegie Mellon's alumni?\", \"Among Carnegie Mellon's alumni, there are CEOs, entrepreneurs, professors, and artists.\"), ('What significant change is happening at CMU in the coming years?', 'CMU will see the largest expansion to the Pittsburgh campus since 1900.'), (\"What are CMU's main areas of focus according to the Strategic Plan 2025?\", 'The university will focus on advancing the individual student experience, the broader Carnegie Mellon community experience, and the social impact of Carnegie Mellon throughout the world.'), ('How does CMU plan to maintain its status as a world-class university?', 'Through research, innovation, and creativity at the intersection of technology and humanity.'), (\"What is the significance of the year 1900 in the context of CMU's campus development?\", 'It marks the previous major expansion before the upcoming largest expansion.'), ('In what ways does CMU intend to impact the world?', 'By focusing on the social impact of Carnegie Mellon throughout the world.'), ('How does CMU view the relationship between technology and humanity?', 'CMU views technology and humanity as intersecting areas that guide its future.'), ('What does the Strategic Plan 2025 aim to advance at CMU?', 'It aims to advance the individual student experience and the broader Carnegie Mellon community experience.'), (\"What rank did CMU's Management Information Systems program receive from U.S. News & World Report in 2022?\", '#1, First Place Ranking.'), ('How many countries do CMU students come from?', '126 countries.'), (\"What was the percentage of women among CMU's Computer Science first-year students?\", 'In 2019, 49.8%.'), ('What is the motto of Andrew Carnegie, the founder of Carnegie Mellon University?', '\"My Heart is in the Work.\"'), ('How many living alumni does CMU have?', '117,257.'), ('What significant contribution did James Gosling, a CMU alumnus, make to the field of computer programming?', 'Invented the Java computer programming language.'), (\"What was CMU's global ranking according to Times Higher Education World University Ranking in 2023?\", '#28 in the world.'), ('How many companies has the CMU community launched to date?', 'More than 400 startups.'), ('Who invented Duolingo, and what was its achievement in the year following its launch?', 'Invented by professor Luis von Ahn; had 10 million downloads in 12 months and was named Apple’s 2013 app of the year.'), ('How many Turing Awards has the CMU community received?', '13 Turing Awards.'), ('What was the first in the field of email innovations credited to a CMU professor?', 'The first smile in an email, created in 1982 by professor Scott Fahlman.'), (\"What percentage of CMU's undergraduate students are international?\", '35% international.'), ('How many Academy Awards has the CMU community won?', '13 Academy Awards.'), ('What is the economic impact of CMU on Pittsburgh, specifically in terms of attracting major companies?', 'CMU has attracted major companies like Google, Intel, Uber, and GE to locate operations and create new jobs in Pittsburgh.'), ('How many countries do CMU faculty come from?', 'Faculty come from 56 countries.'), (\"What is the rank of CMU's College of Engineering according to U.S. News & World Report in 2022?\", '#1.'), ('Who is the President of Carnegie Mellon University?', 'Farnam Jahanian.'), ('What groundbreaking invention related to personal safety materials was created by a CMU alumna?', 'Kevlar Fiber, invented by alumna Stephanie Kwolek.'), ('When did the School of Computer Science at CMU celebrate its 25th year?', 'In 2014.'), ('What was the first college devoted solely to computer science in the United States?', 'The School of Computer Science at Carnegie Mellon University.'), (\"Who established Carnegie Tech's first Computation Center?\", 'Herb Simon (H’90) and Alan Perlis (S’42).'), ('What significant computing device arrived at Carnegie Tech in 1956?', 'An IBM 650 computer.'), ('Who were the creators of the Logic Theorist?', 'Simon, Allen Newell (IA’57), and Cliff Shaw of RAND.'), ('In what year did Alan Perlis begin teaching the first freshman-level computer programming course in the United States?', 'In 1958.'), ('What interdisciplinary Ph.D. program did Carnegie Tech create in 1961?', 'Systems and Communications Sciences.'), ('When was the Computer Science Department at Carnegie Tech established?', 'In 1965.'), ('What were C.mmp and Cm*?', 'The first shared-memory multiprocessor computer and a 50-processor computer, respectively.'), ('Which CMU faculty member received the Nobel Prize in Economics and for what?', 'Herb Simon, for his work on decision-making theory.'), ('What year was the Robotics Institute created at CMU?', 'In 1979.'), ('What was the purpose of the Andrew Project at CMU?', 'To develop a high-speed computer network reaching virtually every room on campus and provide networked PCs or workstations for students, faculty, and employees.'), (\"When did CMU's Faculty Senate agree to elevate the Department of Computer Science to college status?\", 'In the fall of 1988.'), (\"Who was appointed as CMU's first Dean of Computer Science?\", 'A. Nico Habermann.'), ('How did the undergraduate computer science program at CMU begin?', 'Undergraduates interested in computer science pursued an \"applied math/CS\" bachelor’s degree offered by the Mathematics Department before a dedicated undergraduate program was created during the 1989-90 academic year.'), ('Describe the \"three-M\" machine initiative led by Raj Reddy.', 'Inspired by the Xerox Alto, Reddy aimed to develop CMU’s own personal workstation with a megabyte of memory, a megapixel display, and at least one million instructions per second of processing power.'), ('How did CMU become the best-wired campus in the world?', 'Through the Andrew Project, which established a high-speed network and provided networked computing resources, making CMU the most connected university at the time.'), ('What led to the creation of the School of Computer Science at CMU?', \"Concerns that the Computer Science Department's needs were inadequately represented led to the proposal and eventual establishment of the School of Computer Science.\"), ('How has SCS expanded in terms of departments and areas of study since its inception?', 'New departments and areas of study were added, including the Human-Computer Interaction Institute, the Institute for Software Research, the Machine Learning Department, and the Lane Center for Computational Biology.'), (\"What was CMU's role in the creation of the Pittsburgh Supercomputing Center?\", 'CMU was a key collaborator in the creation of the Pittsburgh Supercomputing Center in 1986, along with the University of Pittsburgh and Westinghouse Electric Corp.'), ('Compare the size of the Computer Science Department in 1982 to its size in 2013.', 'In 1982, the Computer Science Department had over 30 faculty members and 100 graduate students. By 2013, SCS had 284 faculty members and nearly 1,700 students, including undergraduates, master’s, and Ph.D. students.'), ('What was the significance of the Logic Theorist program developed by Simon, Newell, and Shaw?', 'The Logic Theorist was significant as a computer program that could develop proofs for theorems in a manner similar to human reasoning, marking a foundational achievement in artificial intelligence.'), ('How did the creation of the first freshman-level computer programming course impact the field of computer science education?', 'It marked the beginning of formal undergraduate education in computer science in the United States, setting a precedent for the establishment of computer science as a distinct academic discipline.'), (\"How did CMU's approach to computer science education and research evolve from the 1950s to the 2010s?\", \"CMU's approach evolved from pioneering the first computer science courses and interdisciplinary Ph.D. programs to establishing a leading School of Computer Science with a broad interdisciplinary focus, incorporating advances in AI, robotics, and human-computer interaction among others.\"), (\"What role did CMU's Computer Science Department play in the advancement of multiprocessor systems?\", 'It played a pivotal role by developing C.mmp and Cm*, early multiprocessor systems that were forerunners to today’s multi-core computing architectures.'), (\"How does the School of Computer Science at CMU maintain its founders' vision in the 21st century?\", 'By embracing all facets of computing, including big data and connected computing, and continuing to lead in education and research across a wide variety of computing disciplines.'), ('What year was the first artificial intelligence program created?', '1955-56'), ('Can you describe the contributions of CMU to the field of computer chess?', \"CMU researcher Hans Berliner developed Hitech, the first computer to achieve grandmaster status, and CMU alumni played key roles in developing IBM's Deep Blue, which beat chess champion Garry Kasparov in 1997.\"), ('How did the introduction of multi-core processors at CMU impact computer performance?', 'CMU researchers improved computer performance by linking together multiple processors, creating a pioneering computer that significantly sped up the processing of speech and graphics programs.'), ('What is your opinion on the lasting impact of emoticons, introduced by CMU in 1982?', 'Emoticons have had a significant and enduring impact on digital communication by providing a simple way to convey emotions and intentions, reducing misunderstandings in text-based messages.'), ('How many students benefit from cognitive tutoring programs developed at CMU annually?', 'Hundreds of thousands of students benefit annually.'), ('List the areas where CMU has made pioneering contributions in computer science.', 'Artificial intelligence, multi-core processors, tutoring machines, speech recognition, emoticons, the Andrew project, autonomous robots, user interfaces, machine translation, Mach kernel, computer chess, Java, email attachments, web search engines, model checking, CAPTCHAs, robotic video cameras, self-driving vehicles, thought reading programs, kidney donor matching, RNA sequencing via videogames, language learning software, question-answering computers, encrypting online information, smart traffic signals.'), ('According to the document, what was a significant milestone in language translation technology achieved by CMU?', 'CMU developed pioneering systems for handheld, portable speech-to-speech translators, moving closer to real-life universal translators.'), ('How did the Andrew project aim to revolutionize computer access?', 'The Andrew project aimed to provide every student, faculty member, and employee with access to email, word processing, file-transfer services, and graphics programs, making CMU the most-wired campus in the world.'), ('Compare the importance of the Mach kernel with the development of Java at CMU.', \"The Mach kernel is crucial as it underpins all modern Apple devices, while Java's significance lies in its platform independence, enabling applications to run on almost any device.\"), ('When did CMU develop the first successful web search engine?', '1994'), (\"How did CMU's CAPTCHAs contribute to internet security?\", 'CAPTCHAs helped distinguish between humans and automated bots, mitigating spam and malicious attacks on the internet.'), (\"What was the outcome of CMU's self-driving SUV named BOSS in 2007?\", 'BOSS won the 2007 DARPA Urban Challenge road race.'), ('How does Duolingo, a CMU spinoff, assist in language learning?', 'Duolingo offers free language tutoring software through its website and mobile apps, enabling users to learn multiple languages while also helping to translate the web.'), ('What role did CMU play in the development of online information encryption?', 'CMU alumna Shafi Goldwasser developed an encryption scheme that makes online data like credit card numbers safer, earning her a Turing Award.'), ('When was The Kiltie Band founded?', 'The Kiltie Band was founded in 1908.'), ('How many students formed The Kiltie Band initially?', 'Seven students.'), ('When did The Kiltie Band have its first official performance?', 'November 25th, 1922.'), ('On whose birthday did The Kiltie Band perform for the first time?', \"The Kiltie Band performed for the first time on Andrew Carnegie's 87th birthday.\"), ('What events does The Kiltie Marching Band play at?', 'The Kiltie Marching Band plays at all Carnegie Mellon home football games.'), ('How often does The Kiltie Band change its show during the football season?', 'There is a new show every week during the football season.'), ('What kind of music does The Kiltie Band perform?', 'The Kiltie Band performs a variety of music, including traditional marches, oldies, current pop tunes, and jazz standards.'), ('Besides football games, at what other events does The Kiltie Band perform?', 'The Kiltie Band also performs at a holiday concert, two spring concerts, and acts as a pep band for the basketball teams.'), ('When does the Kiltie Concert Band play its holiday concert?', 'After the football season.'), ('How many spring concerts does The Kiltie Band perform, and at what special event do they perform?', 'The Kiltie Band performs two spring concerts. The special event they perform is at Carnegie Mellon’s Spring Carnival.'), ('In what capacity does The Kiltie Band support the basketball teams?', 'The Kiltie Band acts as a pep band for the basketball teams.'), ('Which campus entity recognizes The Kiltie Band?', 'The Kiltie Band is recognized by the Student Senate.'), ('What department administers The Kiltie Band?', 'The Kiltie Band is administered by the Department of Athletics, Physical Education, and Recreation.'), ('Is there an audition requirement for joining The Kiltie Band?', 'No, Membership is open to all members of the campus/community without audition.'), ('How can I get kicked out from The Kiltie Band?', \"Participants must promote the ensemble's success through attendance, attitude, and dependability.\"), ('When are rehearsals?', 'During Football season: Mondays and Thursdays from 5:30 p.m.-7:30 p.m. and Game Day 9:30-11:00a.m. During Concert Season: Mondays and Thursdays from 5:30-6:30 p.m.'), ('Where are rehearsals?', 'Rehearsals during football, and concert seasons are at the CUC Studio Theater.'), ('When are performances?', 'Times and dates for all performances are announced at the first practice.'), ('Where are performances? ', 'The Kiltie Band performs at all home football games, a holiday concert, and two spring concerts.'), ('Are there auditions?', 'No, any member of the campus community with music experience is able to join the Kiltie Band!'), ('Do I have to memorize music?', 'No, the music is changed for every show. You should invest in a good and trusty lyre.'), ('When is the first rehearsal?', 'On the first day of class (Monday) at 5:30 p.m. in the CUC Studio Theater. If you have questions, please email the Direcator at jolisar@andrew.cmu.edu.'), ('Can I borrow a school instrument?', 'There are several Kiltie-owned instruments available for your use. Loans begin at 4:30 p.m. before the first rehearsal.'), ('What do they wear under those kilts?', 'Join and you’ll find out!'), (\"What is Yonatan Bisk's research area?\", 'Grounding, RoboNLP, Vision and Language, Embodiment, Unsupervised Learning'), ('Who specializes in Machine Translation at the Language Technologies Institute?', 'Lori Levin, Lei Li, Graham Neubig, Alexander Waibel'), ('What is the office number for Jamie Callan?', '5419 Gates & Hillman Centers'), ('Describe the research interests of Bhiksha Ramakrishnan.', 'Machine Learning, Multimodal Computing and Interaction, Speech Processing, Spoken Interfaces and Dialogue Processing, Privacy'), ('How many faculty members are listed with an interest in Information Retrieval?', '7'), ('List the faculty members who have provided their phone numbers.', 'Ralf Brown, Jamie Callan, Justine Cassell, Mona Diab, Fernando Diaz, Scott Fahlman, Robert Frederking, Anatole Gershman, Alexander Hauptmann, Daphne Ippolito, Lori Levin, Lei Li, Teruko Mitamura, Louis-Philippe Morency, David Mortensen, Eric Nyberg, Bhiksha Ramakrishnan, Carolyn Rosé, Alexander Rudnicky, Michael Shamos, Rita Singh, Alexander Waibel, Shinji Watanabe, Eric P. Xing, Chenyan Xiong, Yiming Yang'), ('Who is the contact for RoboNLP at the Language Technologies Institute?', 'Yonatan Bisk'), ('Compare the number of faculty interested in Machine Learning to those in Natural Language Processing.', 'The document lists 4 faculty members with a specific interest in Machine Learning and over 10 with interests in various areas of Natural Language Processing.'), (\"Which faculty member's research includes Fairness and Ethics in Language Technology?\", 'Fernando Diaz, Maarten Sap'), ('What is the phone number for the faculty member specializing in Spoken Language Translation?', '412-268-7676 (Alexander Waibel)'), ('Who has an office at the Qatar Campus?', 'Kemal Oflazer'), ('Identify faculty members involved in Speech Processing.', 'Bhiksha Ramakrishnan, Alexander Rudnicky, Shinji Watanabe, Alexander Waibel'), ('What research areas does Justine Cassell focus on?', \"The document does not specify Justine Cassell's research areas.\"), ('How can someone contact Daphne Ippolito?', 'Email: daphnei@cmu.edu, Phone: 412-268-7250'), ('List the offices for all faculty members whose research includes Information Extraction.', 'Ralf Brown: 5711 Gates & Hillman Centers, Anatole Gershman: 6415 Gates & Hillman Centers, Alexander Hauptmann: 5519 Gates & Hillman Centers, Teruko Mitamura: 6711 Gates & Hillman Centers, Eric Nyberg: 6715 Gates & Hillman Centers'), ('Who focuses on Embodiment in their research at the Language Technologies Institute?', 'Yonatan Bisk'), ('What is the email address for the faculty member with interests in Creativity and Evaluation in NLP?', 'diazf@cmu.edu (Fernando Diaz)'), ('Can you provide the phone numbers for faculty with interests in Machine Learning?', 'Lei Li: 412-268-6355, Louis-Philippe Morency: 412-268-5508, Bhiksha Ramakrishnan: 412-268-9826, Alexander Waibel: 412-268-7676'), ('Which faculty member has an office located at 205 407 South Craig Street?', 'Alexander Waibel'), ('How many faculty members have an interest in Spoken Interfaces and Dialogue Processing?', '4'), ('Can you describe the main focus of the Ph.D. in Language and Information Technology program at LTI?', 'The program focuses on developing the next generation of scientific and entrepreneurial leaders in computer science, particularly in language and information technologies, through research that advances the state-of-the-art.'), ('What are the expected career paths for graduates of the LTI Ph.D. program?', 'Most graduates become professors and research scientists, while a few have started their own companies.'), ('How many units of graduate-level courses must a student pass to obtain a Ph.D. in Language and Information Technologies at LTI?', 'Students must pass at least 96 units of graduate-level courses.'), ('What are the course requirements for obtaining a Ph.D. in Language and Information Technologies at LTI?', 'Students must complete at least 72 units of LTI courses, 24 units of SCS courses, and two lab courses in two different research areas.'), ('How does the curriculum for the Ph.D. in Language and Information Technology change over the five-year schedule?', 'The first two years include specific courses and labs, while the remaining years focus on directed research.'), ('Compare the early application fee to the regular application fee for the Ph.D. program at LTI.', 'The early application fee is $80, while the regular application fee is $100.'), ('What is the final application deadline for fall admission to the Ph.D. program at LTI for the year 2024?', 'December 13, 2023, at 3 p.m. EST.'), ('What is the partnership country for the Dual-Degree Ph.D. in Language and Information Technologies offered by LTI?', 'Portugal.'), ('Can you describe the curriculum structure for the Dual-Degree Ph.D. program in Language and Information Technologies?', 'The curriculum includes a year in Portugal for classes and directed study, two years at Carnegie Mellon for coursework in linguistics, computer science, statistical learning, and task orientation, followed by extensive research in Portugal leading to a dissertation.'), ('How long do students spend in Portugal as part of the Dual-Degree Ph.D. program?', 'Students spend their first year and the last two years of the program in Portugal.'), ('What is the cost of applying to the Dual-Degree Ph.D. program in Language and Information Technologies?', '$100 per program, with a reduced fee of $80 for early applications submitted by November 29, 2023.'), ('What are the application requirements for the Dual-Degree Ph.D. program at LTI?', 'Application requirements include GRE scores, English proficiency score for non-native speakers, official transcripts, resume, statement of purpose, three letters of recommendation, and optionally a short video and an official award letter for outside funding.'), ('How does the year-by-year study plan look for students in the Dual-Degree Ph.D. program?', 'The study plan includes a mix of classes, directed study, and required research in Portugal for the first year, followed by coursework and directed research in Pittsburgh for the next four years.'), ('What is the final application deadline for Fall 2024 admission to the Dual-Degree Ph.D. program?', 'December 13, 2023, at 3:00 p.m. EST.'), ('How does the LTI Dual-Degree Ph.D. program compare to traditional Ph.D. programs in terms of structure and focus?', 'The LTI Dual-Degree Ph.D. program emphasizes a balance of coursework in linguistics, computer science, statistical learning, and task orientation, with extensive research in Portugal, unlike traditional Ph.D. programs which may focus solely on research or coursework in a single location.'), ('Can you describe the structure and focus of the MLT program at LTI?', 'The MLT program is designed to prepare students for research careers in either academia or industry, involving two years of study split between coursework and research, including two summers dedicated solely to research. It emphasizes hands-on experience and a rigorous curriculum, with a requirement of 120 course units, including LTI and School of Computer Science courses.'), ('What are the graduation requirements for the MLT program?', 'To graduate from the MLT program, students must complete two years of study, which includes two summers of required research, and take 120 or more course units, with at least 72 units being LTI courses and 24 units from the School of Computer Science.'), ('Is a thesis required for the MLT program?', 'Completing an MLT thesis is optional, but guidelines for those choosing to complete one can be found in the MLT Handbook.'), ('How many course units must MLT students complete, and what is the distribution among different types of courses?', 'MLT students must complete 120 or more course units, of which at least 72 must be LTI courses, 24 must be School of Computer Science courses, and the remaining units can be taken from the LTI or other approved senior- or graduate-level courses at CMU or Pitt.'), ('What courses are offered in the first year of the MLT program?', 'In the first year fall semester, courses include Grammars and Lexicons, Algorithms for NLP, and Directed Study. The spring semester offers Search Engines or Machine Learning for Text Mining, Machine Translation, a Self-Paced Lab, and Directed Study.'), ('How does the MLT program integrate research into its curriculum?', 'The MLT program integrates research through required research in both summers, directed research during the academic years under the guidance of faculty advisors, and the option to complete a thesis.'), ('What is the application deadline and fee for the MLT program for Fall 2024 admission?', 'The final application deadline for Fall 2024 admission is December 13, 2023, at 3 p.m. EST, with a fee of $100 per program, or $80 for applications submitted before the early deadline of November 29, 2023, at 3PM EST.'), ('What are the practical experiences required for MIIS students at LTI?', 'MIIS students must complete software development projects supervised by their advisor, a summer internship, and a capstone project executed in a group of peers.'), ('Can you describe the MIIS degree program at LTI?', 'The MIIS degree program focuses on content analysis and machine learning, offering hands-on experience, rigorous curriculum, and opportunities for directed study projects, summer internships, and a group-oriented capstone project.'), ('How does the MIIS program prepare students for their careers?', 'The program prepares students through a combination of classroom instruction, professional experience, and significant projects, enabling them to pursue successful careers in industry or government, often with job offers within six weeks of graduation.'), ('What are the differences between the MIIS-16 and MIIS-21 degree options at LTI?', 'The MIIS-16 is a 16-month track completed in three semesters and a summer internship, while the MIIS-21 is a 21-month track with an additional semester for in-depth study in a concentration area and also includes a summer internship.'), ('How many units must MIIS-16 students complete, and what areas do these units cover?', 'MIIS-16 students must complete at least 84 units covering human language, machine learning, and language technology applications breadth requirements.'), ('What types of careers have alumni of the MIIS program pursued?', 'Alumni have pursued careers at notable organizations like Apple, IBM, and Google.'), ('What is required for admission to the MIIS program at LTI?', 'Requirements include GRE scores, proof of English language proficiency, official transcripts, a current resume, a statement of purpose, three letters of recommendation, and a short video response to a prompt question.'), ('How does the curriculum of the MIIS degree program at LTI vary between the MIIS-16 and MIIS-21 options?', 'The MIIS-16 option focuses on a standard track completed in three semesters and a summer internship, requiring 84 units. In contrast, the MIIS-21 option allows for deeper study in a concentration area over four semesters and a summer internship, requiring at least 108 units.'), ('What is the focus of the Master of Computational Data Science (MCDS) degree at LTI?', 'The MCDS degree focuses on engineering and deploying large-scale information systems, including developing technology layers and analyzing data these systems generate.'), ('Describe the curriculum requirements for an MCDS student.', 'An MCDS student must complete 144 units, including eight 12-unit courses, two 12-unit seminar courses, one 24-unit capstone course, and pass the undergraduate course 15-513 with a grade of B- or better.'), ('How can MCDS students complete their degree, and what are the differences in timing?', 'MCDS students can complete their degree through Standard Timing (16 months, graduating in December) or Extended Timing (20 months, graduating in May), with differences in semester unit requirements and study duration.'), ('What are the majors offered in the MCDS program?', 'The MCDS program offers three majors: Systems, Analytics, and Human-Centered Data Science.'), ('How many course credits are required to graduate from the MCDS program?', 'MCDS students must complete a minimum of 144 units to graduate.'), ('What are the options for the timing of completing the MCDS degree?', 'The options are Standard Timing (16 months) and Extended Timing (20 months).'), ('How does the MCDS program prepare students for their careers?', 'The MCDS program prepares students through a comprehensive curriculum, hands-on experience, internship, and a capstone project, equipping them with the skills for roles as software engineers, data scientists, and project managers.'), ('Compare the Standard Timing and Extended Timing options of the MCDS program.', 'Standard Timing involves 16 months of study with graduation in December, while Extended Timing spans 20 months with graduation in May, with differences in semester unit requirements and the length of study.'), ('What is the final deadline for fall admission to the Master of Science in Artificial Intelligence and Innovation program for 2024?', 'December 13, 2023, at 3:00 p.m. EST.'), ('How many units of study must a student complete to earn the MSAII degree?', 'A student must complete 192 eligible units of study to earn the MSAII degree.'), ('What is required from students for the capstone project in the MSAII program?', 'Students must work on a development project as part of the Core Curriculum for their capstone project.'), ('Can you list some core curriculum courses in the MSAII program?', 'Core curriculum courses include Artificial Intelligence and Future Markets, Law of Computer Technology, Coding Bootcamp, and Machine Learning.'), (\"What are the application requirements for the MSAII program at Carnegie Mellon's School of Computer Science?\", 'Application requirements include a GPA of 3.0 or higher, GRE scores, English Language Proficiency score (for non-native speakers), unofficial transcripts, current resume, Statement of Purpose, three letters of recommendation, and a strongly suggested short video about the applicant.'), ('How does the MSAII program prepare its graduates?', 'The program prepares graduates for entrepreneurship and intrapreneurship by equipping them with AI and machine learning knowledge, practical skills like making technical presentations, and experience in developing a product in cooperation with external stakeholders.'), ('What types of undergraduate degrees do incoming MSAII students generally hold?', 'Incoming students generally hold undergraduate degrees in computer science, software engineering, bioinformatics, or bioengineering.'), ('How does the MSAII program relate to its predecessor?', 'The MSAII program is a successor to the M.S. in Biotechnology, Innovation, and Computing (MSBIC), combining a rigorous AI and machine learning curriculum with real-world team experience.'), ('What is the core course required for the Language Technologies Concentration at LTI?', 'The core course required is Human Language for Artificial Intelligence (11-411).'), ('Can you describe the types of expertise the LTI degree programs prepare students for?', 'The LTI degree programs prepare students for a wide range of career options by emphasizing different types of expertise related to human language technologies, including information retrieval, machine translation, speech technology, text mining, natural language processing, and language-based tutoring.'), ('What are the prerequisites for applying to the language technologies minor at LTI?', \"Prerequisites include Principles of Imperative Computation (15-122), Principles of Functional Programming (15-150), and it's strongly encouraged to take courses in calculus, matrices and linear transformations, and probability.\"), ('What is the deadline to apply for a minor in language technologies at LTI?', 'Students must apply for admission no later than September 30 of their senior year.'), ('How many elective courses must students choose for the Language Technologies Concentration?', 'Students must choose three elective courses of at least 9 units each.'), ('What are the options for elective courses in the Language Technologies Concentration?', 'Elective options include courses on natural language processing, machine learning, search engines, speech processing, neural networks for NLP, and several others related to language and computing.'), ('How is the undergraduate research project requirement fulfilled for the Language Technologies Concentration?', 'The requirement is fulfilled by completing a semester-long directed research project in the context of being registered for an independent study or thesis in an area related to a chosen elective.'), (\"How do the LTI's degree programs incorporate human language technologies?\", \"The LTI's degree programs incorporate human language technologies by offering a minor that allows students to learn about and apply knowledge in areas like information retrieval, machine translation, speech technology, text mining, and natural language processing through coursework and a directed project.\"), ('Who founded Carnegie Technical Schools?', 'Andrew Carnegie founded Carnegie Technical Schools.'), ('When was Carnegie Technical Schools founded?', 'Carnegie Technical Schools was founded in 1900.'), ('What was the original name of the Carnegie Institute of Technology?', 'The original name was Carnegie Technical Schools.'), ('When did Carnegie Technical Schools become the Carnegie Institute of Technology?', 'It became the Carnegie Institute of Technology twelve years later, in 1912.'), ('What did the Carnegie Institute of Technology merge with to become Carnegie Mellon University?', 'It merged with Mellon Institute.'), ('When did the merger that formed Carnegie Mellon University occur?', 'The merger occurred in 1967.'), ('What is a Tartan?', 'A Tartan is a twilled woolen fabric with a plaid design, of Scottish origin, denoting a particular family lineage.'), ('What are common misrepresentations of a Tartan?', 'Tartans are often misrepresented as a fierce warrior from either the Asian tundra or Scottish highlands.'), ('What is the actual meaning of a Tartan?', 'The actual meaning of a Tartan refers to a type of fabric characterized by stripes of various colors and widths against a solid ground, associated with Scottish family lineages.'), ('Why are Carnegie Mellon\\'s athletic teams nicknamed the \"Tartans\"?', 'The nickname \"Tartans\" pays homage to Andrew Carnegie\\'s Scottish heritage.'), (\"Who was Andrew Carnegie's heritage?\", \"Andrew Carnegie's heritage was Scottish, as he was born in Dunfermline, Scotland.\"), ('When did Andrew Carnegie found Carnegie Technical Schools?', 'Andrew Carnegie founded Carnegie Technical Schools in Pittsburgh in 1900.'), ('What does the Scottish terrier mascot performer wear?', 'The Scottish terrier mascot performer sports attire made from Carnegie tartan.'), (\"What is unique about the graphic mascot's appearance?\", 'The graphic mascot is uniquely adorned with a plaid scarf around its neck.'), ('What defines a tartan pattern in fabric?', 'A tartan is defined by its check or pattern of various colors in woven fabric, where bands of color are repeated in equal proportion in both the warp (lengthwise) and weft (across), resulting in solid colors at the intersections of vertical and horizontal stripes of the same color.'), ('How does the arrangement of colored threads in a tartan compare in the warp and the weft?', 'The arrangement of colored threads in a tartan is identical in both the warp and the weft, ensuring that each stripe of the warp crosses every stripe of the weft at equal intervals.'), ('What happens when vertical and horizontal stripes of the same color cross in a tartan pattern?', 'When vertical and horizontal stripes of the same color cross in a tartan pattern, the result is a solid color at the point of intersection.'), ('Where can you find items featuring the official tartan pattern?', 'Items featuring the official tartan pattern can be found in the University Store.'), ('When did Carnegie Mellon University officially adopt the Scottish terrier as its mascot?', 'Carnegie Mellon University officially adopted the Scottish terrier as its mascot in 2007.'), ('What is the official mascot of Carnegie Mellon University?', 'The official mascot of Carnegie Mellon University is the Scottish terrier, known as Scotty.'), (\"How was the name for Carnegie Mellon University's mascot chosen?\", \"The name for Carnegie Mellon University's mascot, Scotty, was chosen through a vote by students, faculty, staff, and alumni.\"), ('Before becoming the official mascot in 2007, how long had students dressed as a Scottish terrier?', 'Before becoming the official mascot in 2007, students had dressed as a Scottish terrier for 50 years.'), ('Does the name \"Scotty\" refer only to the costumed mascot at Carnegie Mellon University?', 'No, the name \"Scotty\" refers both to the costumed mascot and the live dog mascot at Carnegie Mellon University.'), ('Where is Carnegie Mellon University (CMU) located?', 'Pittsburgh, Pennsylvania (PA) 15213.'), ('When was Carnegie Mellon University (CMU) founded?', '1900.'), ('How many undergraduate students were enrolled at Carnegie Mellon University (CMU)?', 'As of Fall 2021, 6,982 students.'), ('How many graduate and doctoral students were enrolled at Carnegie Mellon University (CMU)?', 'As of Fall 2021, 7,062 gradyate and doctoral students.'), ('How many alumni does Carnegie Mellon University (CMU) have?', 'As of 2021, 102,577 alumni.'), ('What is the nickname for Carnegie Mellon University (CMU)?', 'Tartans.'), ('What is the mascot for Carnegie Mellon University (CMU)?', 'Scottie Dog.'), ('What are the school colors for Carnegie Mellon University (CMU)?', 'Cardinal and Gray.'), ('What is the name of the football stadium and/or track and field at Carnegie Mellon University (CMU)?', 'Gesling Stadium.'), ('What is the capacity of Gesling Stadium?', '3,500.'), ('What type of surface does Gesling Stadium have?', 'FieldTurf.'), ('What is the name of the basketball and/or volleyball gym at Carnegie Mellon University (CMU)?', 'Wiegand Gymnasium.'), ('What is the capacity of Wiegand Gymnasium?', '500.'), ('What is the name of the soccer stadium at Carnegie Mellon University (CMU)?', 'CMU Soccer Field.'), ('What is the capacity of the CMU Soccer Field?', '250.'), ('What type of surface does the CMU Soccer Field have?', 'FieldTurf.'), ('What NCAA division is Carnegie Mellon University (CMU) affiliated with?', 'NCAA Division III.'), ('In which athletic conferences does Carnegie Mellon University (CMU) participate?', \"University Athletic Association (UAA) Presidents' Athletic Conference for Football only.\"), ('Who is the president of Carnegie Mellon University?', 'Dr. Farnam Jahanian.'), ('What is the alma mater of the president of Carnegie Mellon University (CMU)?', 'University of Texas at Austin (UT).'), ('Who is the athletic director at Carnegie Mellon University (CMU)?', 'Dr. Josh Centor.'), (\"What is the alma mater and graduation year of Carnegie Mellon University's athletic director?\", 'Brandeis, 2004.'), ('What is the phone number for the Athletic Department at Carnegie Mellon University?', '412-268-8054.'), ('What is the mailing address for Carnegie Mellon University?', '5000 Forbes Avenue, Pittsburgh, PA 15213.')]\n"
     ]
    }
   ],
   "source": [
    "# print(annotation_path)\n",
    "print(raw_data)\n",
    "# print(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Hard Negative SimpleMiner dense embedding model BAAI/bge-small-en-v1.5...\n",
      "Building hard negative index for 357 documents...\n",
      "All documents embedded, now adding to index...\n",
      "save_index set to False, skipping saving hard negative index\n",
      "Hard negative index generated\n",
      "Training data prepared and stored at: ./data/\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "data_out_path = trainer.prepare_training_data(raw_data=raw_data, all_documents=all_documents)\n",
    "print(f\"Training data prepared and stored at: {data_out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "nranks = 4 \t num_gpus = 4 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"index_bsize\": 64,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 20,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 32,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 5e-6,\n",
      "    \"maxsteps\": 500000,\n",
      "    \"save_every\": 10,\n",
      "    \"warmup\": 10,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": \"colbertv2.0_cmu_lti_finetunev1.0\",\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 256,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"colbert-ir\\/colbertv2.0\",\n",
      "    \"triples\": \"data\\/triples.train.colbert.jsonl\",\n",
      "    \"collection\": \"data\\/corpus.train.colbert.tsv\",\n",
      "    \"queries\": \"data\\/queries.train.colbert.tsv\",\n",
      "    \"index_name\": null,\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \".ragatouille\\/\",\n",
      "    \"experiment\": \"colbert\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-03\\/06\\/12.27.36\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 4,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 4,\n",
      "    \"avoid_fork_if_possible\": false\n",
      "}\n",
      "Using config.bsize = 8 (per process) and config.accumsteps = 1\n",
      "[Mar 06, 14:31:09] #> Loading the queries from data/queries.train.colbert.tsv ...\n",
      "[Mar 06, 14:31:09] #> Got 326 queries. All QIDs are unique.\n",
      "\n",
      "[Mar 06, 14:31:09] #> Loading collection...\n",
      "0M nranks = 4 \t num_gpus = 4 \t device=3\n",
      "Using config.bsize = 8 (per process) and config.accumsteps = 1\n",
      "[Mar 06, 14:31:09] #> Loading the queries from data/queries.train.colbert.tsv ...\n",
      "[Mar 06, 14:31:09] #> Got 326 queries. All QIDs are unique.\n",
      "\n",
      "[Mar 06, 14:31:09] #> Loading collection...\n",
      "0M nranks = 4 \t num_gpus = 4 \t device=1\n",
      "Using config.bsize = 8 (per process) and config.accumsteps = 1\n",
      "[Mar 06, 14:31:09] #> Loading the queries from data/queries.train.colbert.tsv ...\n",
      "[Mar 06, 14:31:09] #> Got 326 queries. All QIDs are unique.\n",
      "\n",
      "[Mar 06, 14:31:09] #> Loading collection...\n",
      "0M nranks = 4 \t num_gpus = 4 \t device=2\n",
      "Using config.bsize = 8 (per process) and config.accumsteps = 1\n",
      "[Mar 06, 14:31:09] #> Loading the queries from data/queries.train.colbert.tsv ...\n",
      "[Mar 06, 14:31:09] #> Got 326 queries. All QIDs are unique.\n",
      "\n",
      "[Mar 06, 14:31:09] #> Loading collection...\n",
      "0M \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 570/570 [00:00<00:00, 5.48MB/s]\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> LR will use 10 warmup steps and linear decay over 500000 steps.\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the mascot for Carnegie Mellon University (CMU)?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996, 13314,  2005, 11298, 22181,  2118,\n",
      "         1006,  4642,  2226,  1007,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "\t\t\t\t 0.5804923176765442 2.2281312942504883\n",
      "#>>>    16.63 11.21 \t\t|\t\t 5.419999999999998\n",
      "[Mar 06, 14:31:22] 0 2.8086235523223877\n",
      "\t\t\t\t 2.778505802154541 3.4276678562164307\n",
      "#>>>    17.9 16.81 \t\t|\t\t 1.0899999999999999\n",
      "[Mar 06, 14:31:23] 1 2.8120211026668547\n",
      "\t\t\t\t 1.7655978202819824 3.7759363651275635\n",
      "#>>>    15.62 13.13 \t\t|\t\t 2.4899999999999984\n",
      "[Mar 06, 14:31:23] 2 2.8147506159880162\n",
      "\t\t\t\t 1.0965962409973145 1.4661993980407715\n",
      "#>>>    19.1 13.23 \t\t|\t\t 5.870000000000001\n",
      "[Mar 06, 14:31:23] 3 2.8144986610110663\n",
      "\t\t\t\t 0.28836148977279663 1.079058051109314\n",
      "#>>>    18.06 11.65 \t\t|\t\t 6.409999999999998\n",
      "[Mar 06, 14:31:23] 4 2.8130515818313326\n",
      "\t\t\t\t 0.3518877625465393 2.351139783859253\n",
      "#>>>    15.59 11.95 \t\t|\t\t 3.6400000000000006\n",
      "[Mar 06, 14:31:23] 5 2.8129415577363024\n",
      "\t\t\t\t 0.52132248878479 1.595088243484497\n",
      "#>>>    19.09 12.53 \t\t|\t\t 6.5600000000000005\n",
      "[Mar 06, 14:31:23] 6 2.812245026910835\n",
      "\t\t\t\t 0.5183565616607666 1.5834883451461792\n",
      "#>>>    18.6 11.49 \t\t|\t\t 7.110000000000001\n",
      "[Mar 06, 14:31:23] 7 2.811534626671522\n",
      "\t\t\t\t 2.271012783050537 2.706254005432129\n",
      "#>>>    14.96 12.67 \t\t|\t\t 2.290000000000001\n",
      "[Mar 06, 14:31:24] 8 2.813700358833333\n",
      "\t\t\t\t 0.4587567150592804 2.0348055362701416\n",
      "#>>>    17.36 11.01 \t\t|\t\t 6.35\n",
      "[Mar 06, 14:31:24] 9 2.813380220696027\n",
      "\t\t\t\t 0.9663764238357544 1.1227108240127563\n",
      "#>>>    15.66 10.8 \t\t|\t\t 4.859999999999999\n",
      "[Mar 06, 14:31:24] 10 2.8126559277231795\n",
      "\t\t\t\t 2.3404316902160645 2.0738675594329834\n",
      "#>>>    14.44 11.77 \t\t|\t\t 2.67\n",
      "[Mar 06, 14:31:24] 11 2.814257570806687\n",
      "\t\t\t\t 1.9137389659881592 2.4769511222839355\n",
      "#>>>    17.36 14.72 \t\t|\t\t 2.639999999999999\n",
      "[Mar 06, 14:31:24] 12 2.8158340030857336\n",
      "\t\t\t\t 3.03484845161438 3.4215176105499268\n",
      "#>>>    15.61 14.23 \t\t|\t\t 1.379999999999999\n",
      "[Mar 06, 14:31:24] 13 2.819474535144812\n",
      "\t\t\t\t 2.1084139347076416 2.003283977508545\n",
      "#>>>    17.66 13.29 \t\t|\t\t 4.370000000000001\n",
      "[Mar 06, 14:31:24] 14 2.820766758760302\n",
      "\t\t\t\t 1.4104253053665161 1.4424883127212524\n",
      "#>>>    19.0 15.33 \t\t|\t\t 3.67\n",
      "[Mar 06, 14:31:24] 15 2.8207989056196294\n",
      "\t\t\t\t 0.5643205642700195 1.2603181600570679\n",
      "#>>>    18.92 16.31 \t\t|\t\t 2.610000000000003\n",
      "[Mar 06, 14:31:24] 16 2.819802745438337\n",
      "\t\t\t\t 2.150061845779419 2.6696510314941406\n",
      "#>>>    15.88 14.82 \t\t|\t\t 1.0600000000000005\n",
      "[Mar 06, 14:31:25] 17 2.8218026553317537\n",
      "\t\t\t\t 0.34857115149497986 1.2607861757278442\n",
      "#>>>    17.47 9.3 \t\t|\t\t 8.169999999999998\n",
      "[Mar 06, 14:31:25] 18 2.820590210033447\n",
      "\t\t\t\t 2.754932403564453 3.319772481918335\n",
      "#>>>    13.69 14.03 \t\t|\t\t -0.33999999999999986\n",
      "[Mar 06, 14:31:25] 19 2.8238443249473146\n",
      "\t\t\t\t 2.7177374362945557 3.0533063411712646\n",
      "#>>>    16.64 14.13 \t\t|\t\t 2.51\n",
      "[Mar 06, 14:31:25] 20 2.826791524399833\n",
      "\t\t\t\t 0.11101549863815308 0.3196786046028137\n",
      "#>>>    19.23 11.87 \t\t|\t\t 7.360000000000001\n",
      "[Mar 06, 14:31:25] 21 2.8243954269786737\n",
      "\t\t\t\t 0.5043258666992188 2.358753204345703\n",
      "#>>>    14.74 10.15 \t\t|\t\t 4.59\n",
      "[Mar 06, 14:31:25] 22 2.82443411062274\n",
      "\t\t\t\t 1.2113585472106934 1.2068760395050049\n",
      "#>>>    17.37 14.54 \t\t|\t\t 2.830000000000002\n",
      "[Mar 06, 14:31:25] 23 2.824027911098833\n",
      "\t\t\t\t 1.2733458280563354 3.6952884197235107\n",
      "#>>>    14.1 12.12 \t\t|\t\t 1.9800000000000004\n",
      "[Mar 06, 14:31:25] 24 2.8261725173163046\n",
      "\t\t\t\t 0.7894762754440308 1.2268346548080444\n",
      "#>>>    17.72 13.03 \t\t|\t\t 4.6899999999999995\n",
      "[Mar 06, 14:31:25] 25 2.8253626557292404\n",
      "\t\t\t\t 0.7644659280776978 0.4923585057258606\n",
      "#>>>    18.84 13.05 \t\t|\t\t 5.789999999999999\n",
      "[Mar 06, 14:31:25] 26 2.8237941175669197\n",
      "\t\t\t\t 0.8608464598655701 1.8581267595291138\n",
      "#>>>    15.64 10.21 \t\t|\t\t 5.43\n",
      "[Mar 06, 14:31:25] 27 2.8236892966091425\n",
      "\t\t\t\t 0.17293551564216614 0.07418940961360931\n",
      "#>>>    19.24 13.18 \t\t|\t\t 6.059999999999999\n",
      "[Mar 06, 14:31:25] 28 2.821112732237789\n",
      "\t\t\t\t 2.054658889770508 3.4891698360443115\n",
      "#>>>    17.89 15.0 \t\t|\t\t 2.8900000000000006\n",
      "[Mar 06, 14:31:26] 29 2.8238354484697847\n",
      "\t\t\t\t 0.4193221926689148 1.4096125364303589\n",
      "#>>>    13.39 9.34 \t\t|\t\t 4.050000000000001\n",
      "[Mar 06, 14:31:26] 30 2.8228405476908094\n",
      "\t\t\t\t 1.186597228050232 0.7300026416778564\n",
      "#>>>    15.15 11.5 \t\t|\t\t 3.6500000000000004\n",
      "[Mar 06, 14:31:26] 31 2.821934307012847\n",
      "\t\t\t\t 0.30813732743263245 0.18892602622509003\n",
      "#>>>    19.64 10.65 \t\t|\t\t 8.99\n",
      "[Mar 06, 14:31:26] 32 2.8196094360445905\n",
      "\t\t\t\t 0.8792521357536316 0.42144593596458435\n",
      "#>>>    18.96 14.84 \t\t|\t\t 4.120000000000001\n",
      "[Mar 06, 14:31:26] 33 2.818090524650462\n",
      "\t\t\t\t 0.04438713565468788 0.06434586644172668\n",
      "#>>>    21.17 11.56 \t\t|\t\t 9.610000000000001\n",
      "[Mar 06, 14:31:26] 34 2.815381167124183\n",
      "\t\t\t\t 0.9496954679489136 1.4284703731536865\n",
      "#>>>    16.3 11.29 \t\t|\t\t 5.010000000000002\n",
      "[Mar 06, 14:31:26] 35 2.814943951678952\n",
      "\t\t\t\t 0.39651134610176086 1.1751623153686523\n",
      "#>>>    20.91 13.15 \t\t|\t\t 7.76\n",
      "[Mar 06, 14:31:26] 36 2.813700681358941\n",
      "\t\t\t\t 0.5646709203720093 1.4676225185394287\n",
      "#>>>    17.0 11.6 \t\t|\t\t 5.4\n",
      "[Mar 06, 14:31:26] 37 2.8129192739972844\n",
      "\t\t\t\t 0.04468250647187233 0.1394805610179901\n",
      "#>>>    21.57 13.66 \t\t|\t\t 7.91\n",
      "[Mar 06, 14:31:26] 38 2.8102905177870516\n",
      "\t\t\t\t 0.18179365992546082 0.3404582738876343\n",
      "#>>>    19.18 14.05 \t\t|\t\t 5.129999999999999\n",
      "[Mar 06, 14:31:26] 39 2.80800247923288\n",
      "\t\t\t\t 0.25522875785827637 0.3786722421646118\n",
      "#>>>    17.16 12.97 \t\t|\t\t 4.1899999999999995\n",
      "[Mar 06, 14:31:27] 40 2.80582837775367\n",
      "\t\t\t\t 0.33498653769493103 0.0777396410703659\n",
      "#>>>    18.54 10.69 \t\t|\t\t 7.85\n",
      "[Mar 06, 14:31:27] 41 2.8034352755397802\n",
      "\t\t\t\t 0.017177293077111244 1.42853581905365\n",
      "#>>>    20.9 9.84 \t\t|\t\t 11.059999999999999\n",
      "[Mar 06, 14:31:27] 42 2.802077553426663\n",
      "\t\t\t\t 0.1230931356549263 0.14285461604595184\n",
      "#>>>    20.2 12.23 \t\t|\t\t 7.969999999999999\n",
      "[Mar 06, 14:31:27] 43 2.7995414236323874\n",
      "\t\t\t\t 0.5453363060951233 0.7472080588340759\n",
      "#>>>    17.01 13.76 \t\t|\t\t 3.2500000000000018\n",
      "[Mar 06, 14:31:27] 44 2.798034426573684\n",
      "\t\t\t\t 0.03862515464425087 0.16508184373378754\n",
      "#>>>    20.12 11.65 \t\t|\t\t 8.47\n",
      "[Mar 06, 14:31:27] 45 2.7954400991417625\n",
      "\t\t\t\t 0.03463337942957878 0.8356943130493164\n",
      "#>>>    18.38 11.25 \t\t|\t\t 7.129999999999999\n",
      "[Mar 06, 14:31:27] 46 2.793514986753726\n",
      "\t\t\t\t 0.39744460582733154 0.6244754791259766\n",
      "#>>>    14.34 9.13 \t\t|\t\t 5.209999999999999\n",
      "[Mar 06, 14:31:27] 47 2.7917433918519254\n",
      "\t\t\t\t 0.07152195274829865 0.9239049553871155\n",
      "#>>>    16.79 11.49 \t\t|\t\t 5.299999999999999\n",
      "[Mar 06, 14:31:27] 48 2.7899470753533078\n",
      "\t\t\t\t 0.004350308328866959 0.05688551813364029\n",
      "#>>>    17.99 11.13 \t\t|\t\t 6.859999999999998\n",
      "[Mar 06, 14:31:27] 49 2.787218364104417\n",
      "\t\t\t\t 0.08409814536571503 0.13704729080200195\n",
      "#>>>    17.25 12.07 \t\t|\t\t 5.18\n",
      "[Mar 06, 14:31:27] 50 2.7846522911764806\n",
      "\t\t\t\t 1.500845193862915 2.1307530403137207\n",
      "#>>>    18.1 9.98 \t\t|\t\t 8.120000000000001\n",
      "[Mar 06, 14:31:27] 51 2.785499237119481\n",
      "\t\t\t\t 0.9930780529975891 0.40172725915908813\n",
      "#>>>    17.92 13.15 \t\t|\t\t 4.770000000000001\n",
      "[Mar 06, 14:31:28] 52 2.7841085431945185\n",
      "\t\t\t\t 0.006506367586553097 0.21234208345413208\n",
      "#>>>    18.95 11.18 \t\t|\t\t 7.77\n",
      "[Mar 06, 14:31:28] 53 2.781543283103296\n",
      "\t\t\t\t 0.009160731919109821 0.1335277259349823\n",
      "#>>>    20.42 11.68 \t\t|\t\t 8.740000000000002\n",
      "[Mar 06, 14:31:28] 54 2.7789044282733903\n",
      "\t\t\t\t 0.06157230585813522 0.2825468182563782\n",
      "#>>>    17.96 10.56 \t\t|\t\t 7.4\n",
      "[Mar 06, 14:31:28] 55 2.776469642976682\n",
      "\t\t\t\t 0.4428246021270752 0.4881242513656616\n",
      "#>>>    18.38 11.45 \t\t|\t\t 6.93\n",
      "[Mar 06, 14:31:28] 56 2.774624122187198\n",
      "\t\t\t\t 0.3091840147972107 0.5392826199531555\n",
      "#>>>    16.07 10.26 \t\t|\t\t 5.8100000000000005\n",
      "[Mar 06, 14:31:28] 57 2.772697964699761\n",
      "\t\t\t\t 0.11816280335187912 0.7074559926986694\n",
      "#>>>    17.81 11.55 \t\t|\t\t 6.259999999999998\n",
      "[Mar 06, 14:31:28] 58 2.7707508855385625\n",
      "\t\t\t\t 0.5848888158798218 0.5449075698852539\n",
      "#>>>    20.43 12.53 \t\t|\t\t 7.9\n",
      "[Mar 06, 14:31:28] 59 2.769109931038789\n",
      "\t\t\t\t 0.06475349515676498 0.391966313123703\n",
      "#>>>    19.93 11.17 \t\t|\t\t 8.76\n",
      "[Mar 06, 14:31:28] 60 2.7667975409234815\n",
      "\t\t\t\t 0.0007272017537616193 0.2996308505535126\n",
      "#>>>    22.33 12.41 \t\t|\t\t 9.919999999999998\n",
      "[Mar 06, 14:31:28] 61 2.76433110143958\n",
      "\t\t\t\t 0.6747518181800842 0.3378129303455353\n",
      "#>>>    16.06 10.66 \t\t|\t\t 5.399999999999999\n",
      "[Mar 06, 14:31:28] 62 2.7625793351164685\n",
      "\t\t\t\t 1.099318027496338 1.201550006866455\n",
      "#>>>    18.09 9.4 \t\t|\t\t 8.69\n",
      "[Mar 06, 14:31:28] 63 2.7621176238157146\n",
      "\t\t\t\t 0.48405325412750244 0.19517803192138672\n",
      "#>>>    21.76 15.68 \t\t|\t\t 6.080000000000002\n",
      "[Mar 06, 14:31:29] 64 2.7600347374779477\n",
      "\t\t\t\t 0.14369989931583405 0.17422246932983398\n",
      "#>>>    20.54 12.88 \t\t|\t\t 7.659999999999998\n",
      "[Mar 06, 14:31:29] 65 2.757592625094214\n",
      "\t\t\t\t 0.1251019984483719 0.15814463794231415\n",
      "#>>>    18.36 12.08 \t\t|\t\t 6.279999999999999\n",
      "[Mar 06, 14:31:29] 66 2.7551182791055107\n",
      "\t\t\t\t 0.034505363553762436 0.0847901925444603\n",
      "#>>>    20.09 11.54 \t\t|\t\t 8.55\n",
      "[Mar 06, 14:31:29] 67 2.752482456378778\n",
      "\t\t\t\t 0.10778925567865372 0.15653443336486816\n",
      "#>>>    17.26 10.26 \t\t|\t\t 7.000000000000002\n",
      "[Mar 06, 14:31:29] 68 2.749994297603992\n",
      "\t\t\t\t 0.5934193730354309 0.7013787627220154\n",
      "#>>>    17.26 11.49 \t\t|\t\t 5.770000000000001\n",
      "[Mar 06, 14:31:29] 69 2.748539101442146\n",
      "\t\t\t\t 0.18965153396129608 0.03618213161826134\n",
      "#>>>    18.55 12.08 \t\t|\t\t 6.470000000000001\n",
      "[Mar 06, 14:31:29] 70 2.746016396010009\n",
      "\t\t\t\t 0.33570483326911926 0.5463578701019287\n",
      "#>>>    20.74 13.36 \t\t|\t\t 7.379999999999999\n",
      "[Mar 06, 14:31:29] 71 2.7441524422875676\n",
      "\t\t\t\t 0.02943645976483822 0.22475925087928772\n",
      "#>>>    17.36 12.18 \t\t|\t\t 5.18\n",
      "[Mar 06, 14:31:29] 72 2.7416624855652376\n",
      "\t\t\t\t 0.1037556529045105 0.7502908706665039\n",
      "#>>>    18.82 11.28 \t\t|\t\t 7.540000000000001\n",
      "[Mar 06, 14:31:29] 73 2.7397748696032433\n",
      "\t\t\t\t 0.4319668114185333 0.4936861991882324\n",
      "#>>>    19.14 12.85 \t\t|\t\t 6.290000000000001\n",
      "[Mar 06, 14:31:29] 74 2.7379607477144448\n",
      "\t\t\t\t 0.5862407088279724 0.012468514032661915\n",
      "#>>>    21.66 13.78 \t\t|\t\t 7.880000000000001\n",
      "[Mar 06, 14:31:29] 75 2.735821496192385\n",
      "\t\t\t\t 0.10475583374500275 0.19153453409671783\n",
      "#>>>    16.93 10.35 \t\t|\t\t 6.58\n",
      "[Mar 06, 14:31:30] 76 2.7333819650640345\n",
      "\t\t\t\t 0.014050214551389217 0.025112725794315338\n",
      "#>>>    18.94 9.59 \t\t|\t\t 9.350000000000001\n",
      "[Mar 06, 14:31:30] 77 2.7306877460402474\n",
      "\t\t\t\t 0.001981292385607958 0.07081717997789383\n",
      "#>>>    20.31 11.78 \t\t|\t\t 8.53\n",
      "[Mar 06, 14:31:30] 78 2.7280298567698305\n",
      "\t\t\t\t 0.014303715899586678 0.0071786148473620415\n",
      "#>>>    21.03 10.79 \t\t|\t\t 10.240000000000002\n",
      "[Mar 06, 14:31:30] 79 2.725323309242876\n",
      "\t\t\t\t 0.0001487204135628417 0.13217075169086456\n",
      "#>>>    21.02 10.96 \t\t|\t\t 10.059999999999999\n",
      "[Mar 06, 14:31:30] 80 2.7227303053989127\n",
      "\t\t\t\t 0.02553759515285492 0.4084397256374359\n",
      "#>>>    19.24 9.92 \t\t|\t\t 9.319999999999999\n",
      "[Mar 06, 14:31:30] 81 2.720441552399403\n",
      "\t\t\t\t 0.0012909634970128536 0.004754943773150444\n",
      "#>>>    22.42 8.81 \t\t|\t\t 13.610000000000001\n",
      "[Mar 06, 14:31:30] 82 2.717727156754274\n",
      "\t\t\t\t 0.0017501270631328225 0.12562550604343414\n",
      "#>>>    19.48 9.26 \t\t|\t\t 10.22\n",
      "[Mar 06, 14:31:30] 83 2.715136805230044\n",
      "\t\t\t\t 0.001032007159665227 0.06721148639917374\n",
      "#>>>    18.26 9.17 \t\t|\t\t 9.090000000000002\n",
      "[Mar 06, 14:31:30] 84 2.712489911920934\n",
      "\t\t\t\t 0.0004189710889477283 0.009961401112377644\n",
      "#>>>    21.15 8.77 \t\t|\t\t 12.379999999999999\n",
      "[Mar 06, 14:31:30] 85 2.709787802381418\n",
      "\t\t\t\t 0.004437767434865236 1.0088300704956055\n",
      "#>>>    19.22 12.14 \t\t|\t\t 7.079999999999998\n",
      "[Mar 06, 14:31:30] 86 2.7080912824537546\n",
      "\t\t\t\t 0.47809216380119324 0.6272373199462891\n",
      "#>>>    19.92 11.6 \t\t|\t\t 8.320000000000002\n",
      "[Mar 06, 14:31:30] 87 2.7064885206848506\n",
      "\t\t\t\t 0.5002303719520569 0.11389869451522827\n",
      "#>>>    17.86 10.96 \t\t|\t\t 6.899999999999999\n",
      "[Mar 06, 14:31:31] 88 2.7043961612306333\n",
      "\t\t\t\t 0.05360168591141701 0.03072705678641796\n",
      "#>>>    20.11 11.11 \t\t|\t\t 9.0\n",
      "[Mar 06, 14:31:31] 89 2.701776093810238\n",
      "\t\t\t\t 0.0022052328567951918 0.027015648782253265\n",
      "#>>>    18.7 8.96 \t\t|\t\t 9.739999999999998\n",
      "[Mar 06, 14:31:31] 90 2.6991035385973685\n",
      "\t\t\t\t 0.06703989952802658 0.08085000514984131\n",
      "#>>>    18.85 10.27 \t\t|\t\t 8.580000000000002\n",
      "[Mar 06, 14:31:31] 91 2.6965523249708996\n",
      "\t\t\t\t 0.00026900216471403837 0.001708562602289021\n",
      "#>>>    22.3 10.07 \t\t|\t\t 12.23\n",
      "[Mar 06, 14:31:31] 92 2.6938577502106957\n",
      "\t\t\t\t 0.0007531933952122927 0.013449203222990036\n",
      "#>>>    20.47 8.96 \t\t|\t\t 11.509999999999998\n",
      "[Mar 06, 14:31:31] 93 2.69117809485687\n",
      "\t\t\t\t 0.016361668705940247 0.24612432718276978\n",
      "#>>>    20.35 13.59 \t\t|\t\t 6.760000000000002\n",
      "[Mar 06, 14:31:31] 94 2.688749402743001\n",
      "\t\t\t\t 0.014661861583590508 0.34153732657432556\n",
      "#>>>    18.28 11.98 \t\t|\t\t 6.300000000000001\n",
      "[Mar 06, 14:31:31] 95 2.6864168525153773\n",
      "\t\t\t\t 0.002337012207135558 0.003752757329493761\n",
      "#>>>    21.11 10.5 \t\t|\t\t 10.61\n",
      "[Mar 06, 14:31:31] 96 2.683736525432166\n",
      "\t\t\t\t 0.05566006898880005 0.44797831773757935\n",
      "#>>>    18.99 8.43 \t\t|\t\t 10.559999999999999\n",
      "[Mar 06, 14:31:31] 97 2.68155642729346\n",
      "\t\t\t\t 0.006166794337332249 0.06445759534835815\n",
      "#>>>    18.9 10.24 \t\t|\t\t 8.659999999999998\n",
      "[Mar 06, 14:31:31] 98 2.678945495254921\n",
      "\t\t\t\t 0.00299658952280879 0.025415971875190735\n",
      "#>>>    19.51 7.99 \t\t|\t\t 11.520000000000001\n",
      "[Mar 06, 14:31:31] 99 2.67629496232153\n",
      "\t\t\t\t 0.22961795330047607 0.3099311888217926\n",
      "#>>>    19.33 12.98 \t\t|\t\t 6.349999999999998\n",
      "[Mar 06, 14:31:32] 100 2.6741582164715285\n",
      "[Mar 06, 14:31:32] #> Done with all triples!\n",
      "\n",
      "#> LR will use 10 warmup steps and linear decay over 500000 steps.\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the mascot for Carnegie Mellon University (CMU)?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996, 13314,  2005, 11298, 22181,  2118,\n",
      "         1006,  4642,  2226,  1007,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:3')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:3')\n",
      "\n",
      "\n",
      "#> LR will use 10 warmup steps and linear decay over 500000 steps.\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the mascot for Carnegie Mellon University (CMU)?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996, 13314,  2005, 11298, 22181,  2118,\n",
      "         1006,  4642,  2226,  1007,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:1')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:1')\n",
      "\n",
      "\n",
      "#> LR will use 10 warmup steps and linear decay over 500000 steps.\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the mascot for Carnegie Mellon University (CMU)?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996, 13314,  2005, 11298, 22181,  2118,\n",
      "         1006,  4642,  2226,  1007,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:2')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:2')\n",
      "\n",
      "#> Saving a checkpoint to .ragatouille/colbert/none/2024-03/06/12.27.36/checkpoints/colbert ..\n",
      "#> Joined...\n",
      "#> Joined...\n",
      "#> Joined...\n",
      "#> Joined...\n",
      "Model fine-tuned and saved at: None\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory where the processed training data has been saved\n",
    "# data_dir = './triplet_data/'\n",
    "\n",
    "# Parameters for fine-tuning used the default ones but added for future configuration\n",
    "batch_size = 32\n",
    "nbits = 2\n",
    "maxsteps = 500000\n",
    "use_ib_negatives = True\n",
    "learning_rate = 5e-6  # Adjust based on your needs and observations\n",
    "dim = 128\n",
    "doc_maxlen = 256\n",
    "use_relu = False\n",
    "warmup_steps = 'auto'  # Auto will default to 10% of total steps\n",
    "accumsteps = 1\n",
    "\n",
    "# Call the train method to start fine-tuning\n",
    "model_path = trainer.train(\n",
    "    batch_size=batch_size,\n",
    "    nbits=nbits,\n",
    "    maxsteps=maxsteps,\n",
    "    use_ib_negatives=use_ib_negatives,\n",
    "    learning_rate=learning_rate,\n",
    "    dim=dim,\n",
    "    doc_maxlen=doc_maxlen,\n",
    "    use_relu=use_relu,\n",
    "    warmup_steps=warmup_steps,\n",
    "    accumsteps=accumsteps\n",
    ")\n",
    "    \n",
    "\n",
    "print(f\"Model fine-tuned and saved at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG = RAGPretrainedModel.from_pretrained(\".ragatouille/colbert/none/2024-03/06/12.27.36/checkpoints/colbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Base directory containing your folders\n",
    "base_dir = \".\"\n",
    "\n",
    "# Folders containing your data\n",
    "folders = [\"About Scottie\", \"Buggy News\", \"history_of_cmu\", \"history_of_scs\", \"Kiltie Band\", \"lti_faculty\", \"lti_programs\", \"Tartan Facts\"]\n",
    "\n",
    "# Initialize empty list to hold all document texts\n",
    "collection = []\n",
    "# Optionally, prepare a list for document IDs if you wish to use custom IDs\n",
    "# document_ids = []\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    \n",
    "    # Iterate over each text file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\") and filename != \"annotation.txt\":\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                # Read the document content and add it to the collection\n",
    "                document_text = file.read()\n",
    "                collection.append(document_text)\n",
    "                \n",
    "                # Optionally, add a custom document ID, e.g., foldername-filename\n",
    "#                 document_id = f\"{folder}-{filename}\"\n",
    "#                 document_ids.append(document_id)\n",
    "\n",
    "# At this point, `collection` contains all your documents, and `document_ids` contains their IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(collection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "WARNING! You have a GPU available, but only `faiss-cpu` is currently installed.\n",
      " This means that indexing will be slow. To make use of your GPU.\n",
      "Please install `faiss-gpu` by running:\n",
      "pip uninstall --y faiss-cpu & pip install faiss-gpu\n",
      " ________________________________________________________________________________\n",
      "Will continue with CPU indexing in 5 seconds...\n",
      "New index_name received! Updating current index_name (colbertv2.0_cmu_lti_finetunev1.0) to colbertv2.0_cmu_lti_finetunev1.0\n",
      "\n",
      "\n",
      "[Mar 06, 16:49:46] #> Note: Output directory .ragatouille/colbert/indexes/colbertv2.0_cmu_lti_finetunev1.0 already exists\n",
      "\n",
      "\n",
      "[Mar 06, 16:49:46] #> Will delete 1 files already at .ragatouille/colbert/indexes/colbertv2.0_cmu_lti_finetunev1.0 in 20 seconds...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "nranks = 4 \t num_gpus = 4 \t device=1\n",
      "[Mar 06, 16:50:13] [1] \t\t #> Encoding 31 passages..\n",
      "nranks = 4 \t num_gpus = 4 \t device=3\n",
      "[Mar 06, 16:50:13] [3] \t\t #> Encoding 28 passages..\n",
      "nranks = 4 \t num_gpus = 4 \t device=0\n",
      "[Mar 06, 16:50:13] [0] \t\t #> Encoding 31 passages..\n",
      "nranks = 4 \t num_gpus = 4 \t device=2\n",
      "[Mar 06, 16:50:14] [2] \t\t #> Encoding 31 passages..\n",
      "[Mar 06, 16:50:16] [0] \t\t avg_doclen_est = 165.18519592285156 \t len(local_sample) = 31\n",
      "[Mar 06, 16:50:16] [3] \t\t avg_doclen_est = 165.18519592285156 \t len(local_sample) = 28\n",
      "[Mar 06, 16:50:16] [2] \t\t avg_doclen_est = 165.18519592285156 \t len(local_sample) = 31\n",
      "[Mar 06, 16:50:16] [1] \t\t avg_doclen_est = 165.18519592285156 \t len(local_sample) = 31\n",
      "[Mar 06, 16:50:16] [0] \t\t Creating 2,048 partitions.\n",
      "[Mar 06, 16:50:16] [0] \t\t *Estimated* 19,987 embeddings.\n",
      "[Mar 06, 16:50:16] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/colbertv2.0_cmu_lti_finetunev1.0/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 19014 points to 2048 centroids: please provide at least 79872 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 19014 points in 128D to 2048 clusters, redo 1 times, 20 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 19 (0.17 s, search 0.15 s): objective=3017.31 imbalance=1.549 nsplit=0       \n",
      "[Mar 06, 16:50:18] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/infra/launcher.py\", line 134, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 33, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 68, in run\n",
      "    self.train(shared_lists) # Trains centroids from selected passages\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 237, in train\n",
      "    bucket_cutoffs, bucket_weights, avg_residual = self._compute_avg_residual(centroids, heldout)\n",
      "                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 315, in _compute_avg_residual\n",
      "    compressor = ResidualCodec(config=self.config, centroids=centroids, avg_residual=None)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/codecs/residual.py\", line 24, in __init__\n",
      "    ResidualCodec.try_load_torch_extensions(self.use_gpu)\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/codecs/residual.py\", line 103, in try_load_torch_extensions\n",
      "    decompress_residuals_cpp = load(\n",
      "                               ^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1306, in load\n",
      "    return _jit_compile(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1710, in _jit_compile\n",
      "    _write_ninja_file_and_build_library(\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1793, in _write_ninja_file_and_build_library\n",
      "    verify_ninja_availability()\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1842, in verify_ninja_availability\n",
      "    raise RuntimeError(\"Ninja is required to load C++ extensions\")\n",
      "RuntimeError: Ninja is required to load C++ extensions\n",
      "[rank2]:[E ProcessGroupNCCL.cpp:523] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600274 milliseconds before timing out.\n",
      "[rank2]:[E ProcessGroupNCCL.cpp:537] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "[rank2]:[E ProcessGroupNCCL.cpp:543] To avoid data inconsistency, we are taking the entire process down.\n",
      "[rank2]:[E ProcessGroupNCCL.cpp:1182] [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600274 milliseconds before timing out.\n",
      "Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f3a664d3d87 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libc10.so)\n",
      "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7f3a6767b6e6 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7f3a6767ec3d in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7f3a6767f839 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0xdbbf4 (0x7f3ab13abbf4 in /home/trevea/miniconda3/envs/nlp-rag/bin/../lib/libstdc++.so.6)\n",
      "frame #5: <unknown function> + 0x81ca (0x7f3ab30931ca in /lib64/libpthread.so.0)\n",
      "frame #6: clone + 0x43 (0x7f3ab2575e73 in /lib64/libc.so.6)\n",
      "\n",
      "[rank3]:[E ProcessGroupNCCL.cpp:523] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600276 milliseconds before timing out.\n",
      "[rank3]:[E ProcessGroupNCCL.cpp:537] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "[rank3]:[E ProcessGroupNCCL.cpp:543] To avoid data inconsistency, we are taking the entire process down.\n",
      "[rank3]:[E ProcessGroupNCCL.cpp:1182] [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600276 milliseconds before timing out.\n",
      "Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f091ec28d87 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libc10.so)\n",
      "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7f091fdd06e6 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7f091fdd3c3d in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7f091fdd4839 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0xdbbf4 (0x7f0969b00bf4 in /home/trevea/miniconda3/envs/nlp-rag/bin/../lib/libstdc++.so.6)\n",
      "frame #5: <unknown function> + 0x81ca (0x7f096b7e81ca in /lib64/libpthread.so.0)\n",
      "frame #6: clone + 0x43 (0x7f096accae73 in /lib64/libc.so.6)\n",
      "\n",
      "[rank1]:[E ProcessGroupNCCL.cpp:523] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600282 milliseconds before timing out.\n",
      "[rank1]:[E ProcessGroupNCCL.cpp:537] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "[rank1]:[E ProcessGroupNCCL.cpp:543] To avoid data inconsistency, we are taking the entire process down.\n",
      "[rank1]:[E ProcessGroupNCCL.cpp:1182] [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600282 milliseconds before timing out.\n",
      "Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fba26bf8d87 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libc10.so)\n",
      "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7fba27da06e6 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7fba27da3c3d in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7fba27da4839 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0xdbbf4 (0x7fba71ad0bf4 in /home/trevea/miniconda3/envs/nlp-rag/bin/../lib/libstdc++.so.6)\n",
      "frame #5: <unknown function> + 0x81ca (0x7fba737b81ca in /lib64/libpthread.so.0)\n",
      "frame #6: clone + 0x43 (0x7fba72c9ae73 in /lib64/libc.so.6)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolbertv2.0_cmu_lti_finetunev1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Choose an appropriate name for your index\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming RAG is your initialized RAGPretrainedModel with the loaded checkpoint\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m index_path \u001b[38;5;241m=\u001b[39m \u001b[43mRAG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;43;03m#     document_ids=document_ids,  # Include this only if you prepared document IDs\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True to overwrite existing index of the same name\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_document_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust based on your document length distribution\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True if documents should be split into shorter segments\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex created at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/ragatouille/RAGPretrainedModel.py:210\u001b[0m, in \u001b[0;36mRAGPretrainedModel.index\u001b[0;34m(self, collection, document_ids, document_metadatas, index_name, overwrite_index, max_document_length, split_documents, document_splitter_fn, preprocessing_fn, bsize)\u001b[0m\n\u001b[1;32m    201\u001b[0m     document_splitter_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    202\u001b[0m collection, pid_docid_map, docid_metadata_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_corpus(\n\u001b[1;32m    203\u001b[0m     collection,\n\u001b[1;32m    204\u001b[0m     document_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     max_document_length,\n\u001b[1;32m    209\u001b[0m )\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpid_docid_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpid_docid_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocid_metadata_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocid_metadata_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_document_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_document_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/ragatouille/models/colbert.py:368\u001b[0m, in \u001b[0;36mColBERT.index\u001b[0;34m(self, collection, pid_docid_map, docid_metadata_map, index_name, max_document_length, overwrite, bsize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexer \u001b[38;5;241m=\u001b[39m Indexer(\n\u001b[1;32m    363\u001b[0m     checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint,\n\u001b[1;32m    364\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    365\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    366\u001b[0m )\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexer\u001b[38;5;241m.\u001b[39mconfigure(avoid_fork_if_possible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 368\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m    373\u001b[0m     Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mroot)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mexperiment)\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_name\n\u001b[1;32m    377\u001b[0m )\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m    379\u001b[0m     Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mroot) \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mexperiment) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexer.py:80\u001b[0m, in \u001b[0;36mIndexer.index\u001b[0;34m(self, name, collection, overwrite)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merase()\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_does_not_exist \u001b[38;5;129;01mor\u001b[39;00m overwrite \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreuse\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexer.py:98\u001b[0m, in \u001b[0;36mIndexer.__launch\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m     95\u001b[0m shared_queues \u001b[38;5;241m=\u001b[39m [manager\u001b[38;5;241m.\u001b[39mQueue(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnranks)]\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Encodes collection into index using the CollectionIndexer class\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m \u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_queues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/infra/launcher.py:72\u001b[0m, in \u001b[0;36mLauncher.launch\u001b[0;34m(self, custom_config, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m print_memory_stats(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAIN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# TODO: If the processes crash upon join, raise an exception and don't block on .get() below!\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([\u001b[43mreturn_value_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m all_procs])\n\u001b[1;32m     73\u001b[0m return_values \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m rank, val \u001b[38;5;129;01min\u001b[39;00m return_values]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_all:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/connection.py:430\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 430\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/connection.py:395\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "index_name = \"colbertv2.0_cmu_lti_finetunev1.0\"  # Choose an appropriate name for your index\n",
    "\n",
    "# Assuming RAG is your initialized RAGPretrainedModel with the loaded checkpoint\n",
    "index_path = RAG.index(\n",
    "    collection=collection,\n",
    "#     document_ids=document_ids,  # Include this only if you prepared document IDs\n",
    "    index_name=index_name,\n",
    "    overwrite_index=True,  # Set to True to overwrite existing index of the same name\n",
    "    max_document_length=256,  # Adjust based on your document length distribution\n",
    "    split_documents=True,  # Set to True if documents should be split into shorter segments\n",
    ")\n",
    "\n",
    "print(f\"Index created at: {index_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-rag",
   "language": "python",
   "name": "nlp-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
