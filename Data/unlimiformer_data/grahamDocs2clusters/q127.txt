Question: According to the framework tax paper, what is observed to be growing as hardware speed increases over time?

Context: this phenomenon as the framework tax, and ob- serve that the disparity is growing as hard- ware speed increases over time. In this work, we examine this phenomenon through a se- ries of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/ JaredFern/Framework-Tax.
We introduce the concept of the framework tax to describe when improvements in hardware speed and reductions in required computation fail to trans- late to speedups in model latency and throughput due to bottlenecks incurred by deep learning frame- works. We hope that these observations raise aware- ness of the impact and limitations created by choice of deep learning frameworks on model develop- ment and deployment.

7 Limitations
In this work, we conduct a systematic investiga- tion in which we show that improvements to neural network architectures and hardware have not trans- lated into reductions in inference latency. We show that this breakdown is largely due to overhead in- troduced by deep learning frameworks. We refer to this phenomenon as the framework tax, and show that it exists across all deep learning framework paradigms (e.g. eager execution, just-in-time, and ahead-of-time compilation).
15. Model checking, 1994 CMU professor Edmund Clarke had long stressed the importance of verifying computer hardware and software through a formal problem-solving technique called “model checking.” In 1994, his arguments gained new weight with the discovery that Intel’s amazing new Pentium chip made errors on certain math problems. Clarke would go on to receive the Turing Award for his role in the development of model checking.
2. Multi-core processors, 1971 Multi-core processors are common in today’s computers, but they were still science fiction in the early 1970s. But when CMU researchers found their existing machines too slow to keep pace with the advance of speech and graphics programs, they knew they had to do something. They solved the problem by ganging together 16 processors to build a pioneering computer called C.mmp—then topped the feat by linking 50 processors into Cm*.
16. CAPTCHAs, 2000 “Spam” and malicious attacks were a growing problem on the Internet when hackers developed automated “bots” that could sign up for email and other Web services without human intervention. Luis von Ahn (CS’03,’05), Nick Hopper (CS’04), John Langford (CS’02) and CMU professor Manuel Blum invented a “Completely Automated Public Turing Test to tell Computers and Humans Apart,” or CAPTCHA, to help foil the bots. A later variation, reCAPTCHA, is helping digitize old books and


Answer: 