Question: Which professor from LTI worked on the paper Advancing Regular Language Reasoning in Linear Recurrent Neural Networks?

Context: 3 2 0 2

p e S 4 1

] L C . s c [

1 v 2 1 4 7 0 . 9 0 3 2 : v i X r a

Advancing Regular Language Reasoning in Linear Recurrent Neural Networks Ting-Han Fan∗ Independent Researcher tinghanf@alumni.princeton.edu

Ta-Chung Chi∗ Carnegie Mellon University tachungc@andrew.cmu.edu

Alexander I. Rudnicky Carnegie Mellon University air@cs.cmu.edu

Abstract
In recent studies, linear recurrent neural net- works (LRNNs) have achieved Transformer- level performance in natural language modeling and long-range modeling while offering rapid parallel training and constant inference costs. With the resurged interest in LRNNs, we study whether they can learn the hidden rules in train- ing sequences, such as the grammatical struc- tures of regular language. We theoretically ana- lyze some existing LRNNs and discover their limitations on regular language.
Stephen Merity, Nitish Shirish Keskar, and Richard Socher. Regularizing and optimizing LSTM language

models. In Proceedings of ICLR, 2018.

Hermann Ney, Ute Essen, and Reinhard Kneser. On structuring probabilistic dependences in stochastic

language modelling. Computer Speech & Language, 8(1):1–38, 1994.

Gabriel Pereyra, George Tucker, Jan Chorowski, Łukasz Kaiser, and Geoffrey Hinton. Regularizing neural
dialogue systems, information retrieval, machine translation, speech processing,  video

understanding, multimodal systems, automated reasoning, and other topics related to analysis

and understanding of unstructured information  (e.g., machine learning, and software engineering

of intelligent systems).

1.2 Department Personnel

The people responsible for administering the LTI Ph.D.  degree are:

Jamie Callan

Ph.D. Program Director

Professor

GHC 5419

callan@cs.cmu.edu
garlan@cs.cmu.edu

http://www.cs.cmu.edu/~garlan/academics.htm

C a r o l y n  R o s é

Interim Director, Language Technologies Institute  Professor  GHC 5415

412-268-7130

cprose@cs.cmu.edu

8 MSAII Policies

The Language Technologies Institute (LTI) ha s prepared this statement of policies, program

requirements, guidance, process a nd procedures for students in the M.S. in Artificial Intelligence

and Innovation (MSAII) program. A copy of this handbook is also available online at the
11-727: Computational Semantics for NLP ( only if the course project was done as a

group project)

11-731: Machine Translation

11-747: Neural Networks for NLP

11-751:  Speech Recognition

11-775:  Large -Scale Multimedia

11-776: Multimodal Affective Computing

11-777: Multimodal Machine Learning

11-785:  Deep Learning

11-797: Question Answering

Students may request to have other  LTI course s with a group engineering project component to

be added to this list.


Answer: 