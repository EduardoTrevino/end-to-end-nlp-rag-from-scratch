Question: What is the name of the novel framework introduced for learning unified multi-sensory object property representations?

Context: capability to tackle complex manipulation tasks. Our research introduces a versatile framework for learning unified multi-sensory representations from raw sensory data acquired during robot-object interactions, offering adaptabil- ity across diverse downstream tasks. The generality of our network architecture has been is demonstrated across various applications with strong performance, and the inclusion of self-attention mechanisms further bolsters its performance. Unified Multi-Sensory
We introduce MOSAIC (Multi-modal Object property learning with Self-Attention and Integrated Comprehension), an approach to acquire versatile representations adaptable to various interactive perception tasks within robotics. MO- SAIC is designed to extract unified multi-sensory object property representations, enabling understanding of object properties by leveraging diverse sensory modalities. This approach rests on the premise that natural language provides a versatile embedding space whose
Abstractâ€” A holistic understanding of object properties across diverse sensory modalities (e.g., visual, audio, and haptic) for tasks ranging from object catego- rization to complex manipulation. Drawing inspiration from cognitive science studies that emphasize the significance of multi-sensory integration in human perception, we introduce MOSAIC (Multi-modal Object property learning with Self- Attention and Integrated Comprehension), a novel framework designed to facilitate the learning of
11-777 Advanced Multimodal Machine Learning 11-791 Design of Intelligent Information Systems 10-605 Machine Learning with Large Datasets 10-608 Conversational Machine Learning

10-702 Statistical Machine Learning

15-624 Foundations of Cyber-Physical Systems 15-645 Database Systems 15-681 AI: Representation and Problem Solving

15-688 Practical Data Science

16-720 Computer Vision 16-725 Medical Image Analysis 16-772 Sensing and Sensors 16-824 Visual Learning and Recognition
email access@andrew.cmu.edu to begin the interactive accommodation process.

Students with physical, sensory, cognitive, or emotional disabilities are encouraged to self-

identify with the Office of Disability Reso urces and request needed accommodations. Any

questions about the process can be directed to access@andrew.cmu.edu , or call (412) 268-6121.

14.1.5  Eberly Center for Teaching Excellence & Educational Innovation

www.cmu.edu/teaching
11-727: Computational Semantics for NLP ( only if the course project was done as a

group project)

11-731: Machine Translation

11-747: Neural Networks for NLP

11-751:  Speech Recognition

11-775:  Large -Scale Multimedia

11-776: Multimodal Affective Computing

11-777: Multimodal Machine Learning

11-785:  Deep Learning

11-797: Question Answering

Students may request to have other  LTI course s with a group engineering project component to

be added to this list.


Answer: 