Question: How much increase in throughput (multi GPU setup) does SAMA showcase in large-scale meta learning benchmarks?

Context: scalability and the overall performance of SAMA on a multitude of large-scale meta learning benchmarks involving large language models (e.g., BERT [31] and RoBERTa [39]) or large datasets (e.g., ImageNet-1k [10]). Notably, SAMA showcases up to 1.7/4.8× increase in throughput and 2.0/3.8× decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. In addition, we observe that SAMA- based data optimization consistently leads to
designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8× increase in throughput and 2.0/3.8× decrease in memory consumption respectively on
single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.
11-777 Advanced Multimodal Machine Learning 11-791 Design of Intelligent Information Systems 10-605 Machine Learning with Large Datasets 10-608 Conversational Machine Learning

10-702 Statistical Machine Learning

15-624 Foundations of Cyber-Physical Systems 15-645 Database Systems 15-681 AI: Representation and Problem Solving

15-688 Practical Data Science

16-720 Computer Vision 16-725 Medical Image Analysis 16-772 Sensing and Sensors 16-824 Visual Learning and Recognition
10-605, Machine Learning with Large Data sets (12 units). First spring semester.

11-611, Natural Language Processing (12 units). Second fall semester.

11-785, Deep Learning (12 unit s). Second spring semester.

One more 12-unit AI, ML or NLP course of the student’s choice (with approval of the

Program Director)

In the event that a course is not available, a course covering equivalent material with a
11-727: Computational Semantics for NLP ( only if the course project was done as a

group project)

11-731: Machine Translation

11-747: Neural Networks for NLP

11-751:  Speech Recognition

11-775:  Large -Scale Multimedia

11-776: Multimodal Affective Computing

11-777: Multimodal Machine Learning

11-785:  Deep Learning

11-797: Question Answering

Students may request to have other  LTI course s with a group engineering project component to

be added to this list.


Answer: 