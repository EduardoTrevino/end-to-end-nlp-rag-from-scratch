Question: In the paper "Decoder-only Architecture for Speech Recognition with CTC Prompts and Text Data Augmentation, what is the reduction in word error rates achieved by the proposed models on Switchboard?

Context: 2https://github.com/google/sentencepiece

the joint CTC/attention-based encoder-decoder models that are used in acoustic feature-based end-to-end speech recognition systems [38]. Note that a randomly initialized linear embedding layer is used before the encoder to extract learnable features for input discrete tokens.

2.3. Data Augmentation for ASR with Discretized Input
This paper presents an end-to-end model designed to im- prove automatic speech recognition (ASR) for a particular speaker in a crowded, noisy environment. The model utilizes a single-channel speech enhancement module that isolates the speaker’s voice from background noise (ConVoiFilter) and an ASR module. The model can decrease ASR’s word error rate (WER) from 80% to 26.4% through this approach. Typically, these two components are adjusted independently due to vari- ations in data requirements.
Self-supervised learning of speech representations [13] has recently shown its effectiveness in utilizing unlabeled speech data, resulting in outperforming the state-of-the-art (SoTA) in many automatic speech recognition (ASR) datasets. For our study, we utilized the pre-trained wav2vec2 model [10] to construct our ASR model. The wav2vec2 model acts as a speech encoder, and for the decoder, we used an RNN trans- ducer [14]. Despite having a speech enhancement module to eliminate noise from the
Course number: 18495

Title: Speech Technology for Conversational AI

Units: 12.0

Section: A

Days: MW

Start: 03:30PM

End: 04:50PM

Room: GHC 5222

Locations: Pittsburgh, Pennsylvania

Instructors: Watanabe

Spring 2024

Course number: 18500

Title: ECE Design Experience

Units: 12.0

Section: A,E,B,C,D,Lec

Days: MW

Start: 10:00AM

End: 11:50AM

Room: TBA,HH 1307

Locations: Pittsburgh, Pennsylvania

Instructors: Fedder,Kim,Sullivan,Mukherjee,Savvides

Spring 2024

Course number: 18525
End: 04:50PM

Room: GHC 4401

Locations: Pittsburgh, Pennsylvania

Instructors: Callan

Spring 2024

Course number: 11753

Title: Advanced Laboratory in Speech Recognition

Units: 6.0

Section: A

Days: TBA

Start:

End:

Room: TBA

Locations: Pittsburgh, Pennsylvania

Instructors: Instructor TBA

Spring 2024

Course number: 11754

Title: Project Course: Conversational Systems

Units: 6.0

Section: A

Days: T

Start: 05:00PM

End: 06:20PM

Room: BH 154A

Locations: Pittsburgh, Pennsylvania
Course number: 11743

Title: Self-Paced Lab: IR

Units: 6.0

Section: A

Days: TBA

Start:

End:

Room: DNM DNM

Locations: Pittsburgh, Pennsylvania

Instructors: Callan

Fall 2023

Course number: 11751

Title: Speech Recognition and Understanding

Units: 12.0

Section: A

Days: MW

Start: 03:30PM

End: 04:50PM

Room: GHC 4307

Locations: Pittsburgh, Pennsylvania

Instructors: Watanabe

Fall 2023

Course number: 11755

Title: Machine Learning for Signal Processing

Units: 12.0

Section: A,B
Sweepstakes Committee: Robert Kerr (Chair)

Race Results: (1) DU; (2) PiKA; (3) DTD

Design Comp: (1) PiKA

Weather: Overcast turning to Rain on Friday; Drizzle on Saturday; High of 65/63, Low of 52/49

For the second year in a row, we had another controversial Finals involving PiKA (but thanks to limited info in the Tartan, we’re missing some juicy details). But this time it earned one fraternity, with their unique buggy/driver combo, their first and only winning trophy.
Sweepstakes Committee: Jack Johnson (Chair)

Race Results: (1) DTD (2:42.5 – COURSE RECORD); (2) PiKA (2:43.5); (3) KapSig

Design Comp: (1) SAE; (Honorable Mention) PiKA

Weather: Sunny; 66-72 Degrees on Friday, 70-75 Degrees on Saturday

In 1949, DTD earned its second straight nose-length victory and set a course record in doing so. Other than that, the year seemed uneventful.
the 3 teams qualifying for Finals, broke the post-war record. In the finals, it was another close battle, with DTD squeaking it out over PiKA. DTD’s winning time of 2:42.5 was fast enough to set the course record, and PiKA’s 2:43.5 was only ½ second behind the prior record. SAE’s Best Design. SAE took home the trophy for Design Comp with their sleek aluminum buggy. Unfortunately, we haven’t found a photo. [Ed. Update: Based on the buggies from 1950, the 1950 Thistle’s actual description of
Fall 2: - Machine Learning for Text Mining - MIIS Capstone Project

Example Course of Study #2 This schedule would satisfy course requirements for a student interested in voice-based computer applications.

Fall 1:

Machine Learning

Algorithms for NLP

Speech Recognition and Understanding

Directed Study

Spring: - Applied Machine Learning - Competitive Engineering - Design and Implementation of Speech Recognition Systems - Directed Study - MIIS Capstone Planning Seminar

Summer:

Internship
4. Speech recognition, 1976 If you have an iPhone, ask Siri to look up “Hearsay I,” the first computer system capable of continuous speech recognition. It was developed by future Turing Award winner and future SCS dean Raj Reddy along with his students. Their work on subsequent systems established many of the principles that still underlie speech recognition software.
11-727: Computational Semantics for NLP ( only if the course project was done as a

group project)

11-731: Machine Translation

11-747: Neural Networks for NLP

11-751:  Speech Recognition

11-775:  Large -Scale Multimedia

11-776: Multimodal Affective Computing

11-777: Multimodal Machine Learning

11-785:  Deep Learning

11-797: Question Answering

Students may request to have other  LTI course s with a group engineering project component to

be added to this list.


Answer: 