Question: Which model performed the best in "Syntax and Semantics Meet in the “Middle”: Probing the Syntax-Semantics Interface of LMs Through Agentivity"?

Context: 3 2 0 2

l u J

0 1

] L C . s c [

2 v 5 8 1 8 1 . 5 0 3 2 : v i X r a

Syntax and Semantics Meet in the “Middle”: Probing the Syntax-Semantics Interface of LMs Through Agentivity

Lindia Tjuatja, Emmy Liu, Lori Levin, Graham Neubig Language Technologies Institute Carnegie Mellon University {ltjuatja, mengyan3, lsl, gneubig}@cs.cmu.edu

1

Abstract
In order to gain insight into the behavior of LMs with respect to the syntax-semantics interface, we created a suite of prompting experiments focus- ing on agentivity. We prompt varying sizes of BLOOM, GPT-2, and GPT-3 to see if they are sen- sitive to aspects of agentivity at the lexical level, and then to see if they can either utilize or discard these word-level priors given the appropriate syn- tactic context. GPT-3 davinci-003 performs exceptionally well in all three of our experiments—
Recent advances in large language models have prompted researchers to examine their abilities across a variety of linguistic tasks, but little has been done to investigate how models han- dle the interactions in meaning across words and larger syntactic forms—i.e. phenomena at the intersection of syntax and semantics. We present the semantic notion of agentivity as a case study for probing such interactions. We created a novel evaluation dataset by utilitiz- ing the unique linguistic properties
Course number: 10708

Title: Probabilistic Graphical Models

Units: 12.0

Section: A

Days: TR

Start: 12:30PM

End: 01:50PM

Room: POS 153

Locations: Pittsburgh, Pennsylvania

Instructors: Risteski

Fall 2023

Course number: 10714

Title: Deep Learning Systems: Algorithms and Implementation

Units: 12.0

Section: A

Days: TR

Start: 11:00AM

End: 12:20PM

Room: TEP 1403

Locations: Pittsburgh, Pennsylvania

Instructors: Kolter, Chen

Fall 2023

Course number: 10715
Title: Substructural Logics:

Units: 12.0

Section: A,

Days:  ,TR

Start: 09:30AM,

End: 10:50AM,

Room:  ,GHC 4215

Locations:  ,Pittsburgh, Pennsylvania

Instructors: Pfenning

Fall 2023

Course number: 15856

Title: Introduction to Cryptography

Units: 12.0

Section: A

Days: TR

Start: 08:00AM

End: 09:20AM

Room: GHC 4303

Locations: Pittsburgh, Pennsylvania

Instructors: Jain

Fall 2023

Course number: 15857

Title: Analytical Performance Modeling & Design of Computer Systems:
Course number: 18789

Title: Deep Generative Modeling

Units: 12.0

Section: A

Days: MW

Start: 02:00PM

End: 03:20PM

Room: HH 1107

Locations: Pittsburgh, Pennsylvania

Instructors: Fanti, Chen

Spring 2024

Course number: 18799

Title: Special Topics in Signal Processing:

Units: 12.0

Section: R, ,RW

Days:  ,MW

Start:  ,12:00PM,10:00AM

End: 11:50AM, ,01:50PM

Room:  ,CMR F309

Locations:  ,Kigali, Rwanda

Instructors: Busogi, Gueye,Vernon

Spring 2024

Course number: 18845
1946 – PiKA’s Buggy (from the 1947 Thistle). It didn’t win Design Competition, but it had the best aesthetic design. Prelim Heats and Results. The Prelims were run in 3 heats, with 3 teams in each. The rules initially stated that the winner of each heat would compete in the finals, but it seems that the rules changed to be the three fastest times instead, as the Prelim results printed in the May 7, 1946 Tartan indicate that the Finals was just a rematch of Prelim Heat 1. According to the May 7
1948 – Design Competition (from the 1949 Thistle). Identified buggies: KapSig (3rd from the left, back row); PiKA (4th from the left, back row); Beta Sigma Rho (far left, back row). We also believe that the bottom buggy in the front row (3 wheels, no shell) belongs to Citcom Clan.

1948 – Hill 1 of the Finals (from the 1949 Thistle). KapSig in Lane 1 (left), DTD in Lane 2 (middle), PiKA in Lane 3 (right)
1947 – Starting Line of a Prelims Heat (from the 1948 Thistle). Unknown buggy in Lane 1, Theta Xi in Lane 2, and an unknown (barely visible) buggy in Lane 3.

1947 – Prelim (Unknown Heat) Back Hills (from the 1948 Thistle). Beta’s snow plow buggy (with dragon) leading (far left), KapSig 2nd (far right), SigNu trailing (middle)

Who wore it best? 1947 – DU and DTD on Hill 1 during what we now believe might be the Finals (from the 1948 Thistle).
11-727: Computational Semantics for NLP ( only if the course project was done as a

group project)

11-731: Machine Translation

11-747: Neural Networks for NLP

11-751:  Speech Recognition

11-775:  Large -Scale Multimedia

11-776: Multimodal Affective Computing

11-777: Multimodal Machine Learning

11-785:  Deep Learning

11-797: Question Answering

Students may request to have other  LTI course s with a group engineering project component to

be added to this list.
Question Answering

Intro to Deep Learning

MIIS Capstone Planning Seminar

MIIS Directed Study

Summer:

Internship

Fall 2:

MIIS Capstone Project

Machine Translation

Spring 2:

Comp Semantics for NLP

Neural Networks for NLP

Elective

Example Course of Study #3 This example would satisfy course requirements for a student interested in deepening their expertise in Human Language area of concentration

Fall 1:

Natural Language Processing

Algorithms for NLP

Intro to ML (MLD)
15. Model checking, 1994 CMU professor Edmund Clarke had long stressed the importance of verifying computer hardware and software through a formal problem-solving technique called “model checking.” In 1994, his arguments gained new weight with the discovery that Intel’s amazing new Pentium chip made errors on certain math problems. Clarke would go on to receive the Turing Award for his role in the development of model checking.


Answer: 