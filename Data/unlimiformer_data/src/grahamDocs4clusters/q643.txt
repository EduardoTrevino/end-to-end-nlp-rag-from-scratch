Question: In "Pengi: An Audio Language Model for Audio Tasks," on how many downstream tasks is the model evaluated on?

Context: 5.1 Benchmarking Pengi We assessed Pengi on 21 downstream tasks covering various domains. Pengi is the first audio model that can perform both, open-ended and close-ended tasks. A fair comparison against another model that can perform both is not possible. We chose CLAP [17] as the baseline because it is the only Zero-Shot model with a comprehensive evaluation (16 downstream tasks). The next best evaluation was only on 8 tasks. Thus, providing no evidence of performance across domains like
7 Conclusions We proposed Pengi, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks. It takes as input, an audio recording, and a text prompt, and generates free-form text as output. Pengi is capable of handling both, close-ended and open-ended audio tasks. We benchmarked Pengi on 21 downstream tasks and show it yields SoTA performance in several of them. Our findings break ground in prompting language models with audio for general-
We extensively evaluated Pengi on 21 downstream tasks across various audio domains yielding state-of-the-art performance in several of them. Thus, establishing a baseline for general-purpose ALM.
Title: Engineering AI Project Methods

Units: 6.0

Section: A1

Days: MW

Start: 06:00PM

End: 07:50PM

Room: CMR F205

Locations: Kigali, Rwanda

Instructors: Brown

Fall 2023

Course number: 04654

Title: Introduction to Probabilistic Graphical Model:

Units: 12.0

Section: J,

Days:  ,TR

Start:  ,03:00PM

End:  ,04:50PM

Room:  ,CMR F309

Locations:  ,Kigali, Rwanda

Instructors: Gueye, Mukamakuza

Fall 2023

Course number: 04655

Title: Artificial Intelligence for Engineers

Units: 12.0
Course number: 11868

Title: Large Language Model Systems

Units: 12.0

Section: A

Days: MW

Start: 05:00PM

End: 06:20PM

Room: POS A35

Locations: Pittsburgh, Pennsylvania

Instructors: Li

Spring 2024

Course number: 11877

Title: Advanced Topics in Multimodal Machine Learning

Units: VAR

Section: A

Days: TR

Start: 02:00PM

End: 03:20PM

Room: WEH 4709

Locations: Pittsburgh, Pennsylvania

Instructors: Liang, Fried

Spring 2024

Course number: 11891

Title: Neural Code Generation:
Course number: 18789

Title: Deep Generative Modeling

Units: 12.0

Section: A

Days: MW

Start: 02:00PM

End: 03:20PM

Room: HH 1107

Locations: Pittsburgh, Pennsylvania

Instructors: Fanti, Chen

Spring 2024

Course number: 18799

Title: Special Topics in Signal Processing:

Units: 12.0

Section: R, ,RW

Days:  ,MW

Start:  ,12:00PM,10:00AM

End: 11:50AM, ,01:50PM

Room:  ,CMR F309

Locations:  ,Kigali, Rwanda

Instructors: Busogi, Gueye,Vernon

Spring 2024

Course number: 18845
Q: Can I borrow a school instrument? A: There are several Kiltie-owned instruments available for your use. Loans begin at 4:30 p.m. before the first rehearsal.

Q: What do they wear under those kilts? A: Join and you’ll find out!
This year Fringe is planning to roll four different vehicles, built and maintained in the Fringe workshop in the basement of the East Campus Garage, known as the "Froom."

"We're used to saying everything with 'fr' in front of it but when we say something in front of other people, it gets them confused," said Fringe head mechanic Dave Singh, who will graduate in May with a bachelor's degree in mechanical engineering and biomedical engineering.
1946 – PiKA’s Buggy (from the 1947 Thistle). It didn’t win Design Competition, but it had the best aesthetic design. Prelim Heats and Results. The Prelims were run in 3 heats, with 3 teams in each. The rules initially stated that the winner of each heat would compete in the finals, but it seems that the rules changed to be the three fastest times instead, as the Prelim results printed in the May 7, 1946 Tartan indicate that the Finals was just a rematch of Prelim Heat 1. According to the May 7
Electives (Choose Three): - Natural Language Processing (11-411) - Machine Learning for Text and Graph-based Mining (11-441) - Search Engines (11-442) - Speech Processing (11-492) - Machine Learning in Practice (11-344) - Advanced Natural Language Processing (11-711) - Machine Translation and Sequence-to-Sequence Models (11-731) - Multilingual Natural Language Processing (11-737) - Neural Networks for NLP (11-747) - Speech Recognition and Understanding (11-751) - Language and Statistics
In order to  complete the Master of Language Technologies degree, the student must pass 120

or more course units of senior- to-graduate courses, and meet the following criteria:

within those 120 units, at least 72 units of “LTI” courses and 24 units of “SCS” courses,

within those 72 units, 11 -711, 11- 791 (or an equivalent , see below ), and one ``Task

Orientation Focus'' class, and

within those 72 units, at least one of the following:

o an LTI lab course,

o 11-792, or
Language Technologies Institute - Faculty Name: Lei Li Email: leili@andrew.cmu.edu Research Areas: Machine Learning, Machine Translation, Large Language Models, AI Drug Discovery Phone: 412-268-6355


Answer: 