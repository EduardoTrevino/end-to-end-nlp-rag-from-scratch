{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ad8c3aa9004ec588e1ac2f95317320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.nn import DataParallel\n",
    "import numpy as np\n",
    "\n",
    "class MistralEmbedder:\n",
    "    def __init__(self, model_name=\"Salesforce/SFR-Embedding-Mistral\", device='cuda'):\n",
    "#         device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of text documents using the Mistral model.\n",
    "        \n",
    "        Parameters:\n",
    "        - texts (List[str]): A list of texts to embed.\n",
    "        \n",
    "        Returns:\n",
    "        - List of embeddings as numpy arrays.\n",
    "        \"\"\"\n",
    "        # Ensure texts is a list for batch processing\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        \n",
    "        # Generate embeddings and return them as numpy arrays\n",
    "        embeddings = self.model.encode(texts)\n",
    "        embeddings_list = embeddings.tolist() if isinstance(embeddings, np.ndarray) else embeddings\n",
    "        return embeddings_list\n",
    "    def embed_query(self, query):\n",
    "        \"\"\"\n",
    "        Generate an embedding for a single query string using the Mistral model.\n",
    "        \n",
    "        Parameters:\n",
    "        - query (str): The query string to embed.\n",
    "        \n",
    "        Returns:\n",
    "        - A numpy array representing the embedding of the query.\n",
    "        \"\"\"\n",
    "        # Generate the embedding for the query\n",
    "        embedding = self.model.encode(query, convert_to_numpy=True)\n",
    "\n",
    "        # Convert numpy array to list if necessary\n",
    "        embedding_list = embedding.tolist() if isinstance(embedding, np.ndarray) else embedding\n",
    "\n",
    "        # Return the embedding\n",
    "        return embedding_list\n",
    "\n",
    "# Initialize the embedding wrapper\n",
    "mistral_embedder = MistralEmbedder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from llama-2-7b-chat.Q6_K.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q6_K\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 5.15 GiB (6.56 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors:        CPU buffer size =  5272.34 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1024.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    13.02 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   160.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '18'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "\n",
    "n_gpu_layers = 1  # Metal set to 1 is enough.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"llama-2-7b-chat.Q6_K.gguf\",\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    n_ctx=2048,\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma(persist_directory=\"MistralEmbed/\", embedding_function=mistral_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='/0/51/1/10/2/8'), Document(page_content='/0/51/1/10/2/8', metadata={'source': 'Web Scholar PDFs/e01515c6138bc525f7aec30fc85f2adf028d4156.pdf'}), Document(page_content='(cid:51) Takeaway:'), Document(page_content='(cid:51) Takeaway:', metadata={'source': 'Web Scholar PDFs/8aa98fbfb6f1e979dead13ce24075503fe47658e.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is The course 05120?\"\n",
    "docs = vectorstore.similarity_search(query)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 new documents.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def load_pickle(file_path):\n",
    "    \"\"\"Load the contents of a pickle file.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "def find_new_documents(new_data_file, old_data_file):\n",
    "    \"\"\"Find and return documents in the new data file that are not in the old data file.\"\"\"\n",
    "    # Load data from both pickle files\n",
    "    new_data = load_pickle(new_data_file)\n",
    "    old_data = load_pickle(old_data_file)\n",
    "    \n",
    "    # Find documents in new_data that are not in old_data\n",
    "    new_documents = [doc for doc in new_data if doc not in old_data]\n",
    "    \n",
    "    return new_documents\n",
    "\n",
    "# Adjust these file paths to match your pickle file locations\n",
    "new_data_file_path = 'final_data_splits.pkl'\n",
    "old_data_file_path = 'splitDocuments.pkl'\n",
    "\n",
    "# Find the new documents\n",
    "new_documents = find_new_documents(new_data_file_path, old_data_file_path)\n",
    "\n",
    "# Optionally, print the new documents or the number of new documents found\n",
    "print(f\"Found {len(new_documents)} new documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 36384 new documents.\n"
     ]
    }
   ],
   "source": [
    "# Flatten the list of lists into a single list of Document objects\n",
    "new_docs_flat = [doc for sublist in new_documents for doc in sublist]\n",
    "\n",
    "# Now, add these Document objects to your vector store\n",
    "try:\n",
    "    added_document_ids = vectorstore.add_documents(new_docs_flat)\n",
    "    print(f\"Successfully added {len(added_document_ids)} new documents.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error adding new documents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: Type <class 'list'>\n",
      " - Content: [Document(page_content='3 2 0 2\\n\\nl u J\\n\\n0 1\\n\\n] L C . s c [\\n\\n2 v 5 8 1 8 1 . 5 0 3 2 : v i X \n",
      "Document 1: Type <class 'list'>\n",
      " - Content: [Document(page_content='Sweepstakes Slang\\n\\nBuggy: Vehicle being raced and also a nickname for the \n",
      "Document 2: Type <class 'list'>\n",
      " - Content: [Document(page_content='Who founded Carnegie Mellon University?\\n\\nCarnegie Technical Schools was fo\n",
      "Document 3: Type <class 'list'>\n",
      " - Content: [Document(page_content=\"The course 05120, 'Introduction to Human-Computer Interaction,' offers 5 uni\n",
      "Document 4: Type <class 'list'>\n",
      " - Content: [Document(page_content='Course: 05291\\n\\nCourse_Title: Learning Media Design\\n\\nUnits: 12\\n\\nSec: A\\\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first few documents to understand their structure\n",
    "for i, doc in enumerate(new_documents[:5]):  # Adjust the number as needed\n",
    "    print(f\"Document {i}: Type {type(doc)}\")\n",
    "    if isinstance(doc, dict):\n",
    "        print(f\" - Keys: {list(doc.keys())}\")\n",
    "    else:\n",
    "        print(f\" - Content: {str(doc)[:100]}\")  # Print the first 100 characters to get a sense of the content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Create a list of lists, each containing one Document object\n",
    "placeholder_docs_nested = [[Document(page_content=f\"Placeholder text for document {i}\")] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: Type <class 'list'>\n",
      " - Content: [Document(page_content='Placeholder text for document 0')]\n",
      "Document 1: Type <class 'list'>\n",
      " - Content: [Document(page_content='Placeholder text for document 1')]\n",
      "Document 2: Type <class 'list'>\n",
      " - Content: [Document(page_content='Placeholder text for document 2')]\n",
      "Document 3: Type <class 'list'>\n",
      " - Content: [Document(page_content='Placeholder text for document 3')]\n",
      "Document 4: Type <class 'list'>\n",
      " - Content: [Document(page_content='Placeholder text for document 4')]\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(placeholder_docs_nested[:5]):  # Adjust the number as needed\n",
    "    print(f\"Document {i}: Type {type(doc)}\")\n",
    "    if isinstance(doc, dict):\n",
    "        print(f\" - Keys: {list(doc.keys())}\")\n",
    "    else:\n",
    "        print(f\" - Content: {str(doc)[:100]}\")  # Print the first 100 characters to get a sense of the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5 placeholder documents.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    added_document_ids = vectorstore.add_documents(placeholder_docs_flat)\n",
    "    print(f\"Successfully added {len(added_document_ids)} placeholder documents.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error adding placeholder documents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of lists into a single list of Document objects\n",
    "placeholder_docs_flat = [doc for sublist in placeholder_docs_nested for doc in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Assuming new_documents is a list of strings or objects that can be converted to strings\n",
    "new_doc_objects = [Document(page_content=str(doc)) for doc in new_documents]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, you can add these Document objects to your vector store\n",
    "try:\n",
    "    added_document_ids = vectorstore.add_documents(new_doc_objects)\n",
    "    print(f\"Successfully added {len(added_document_ids)} documents.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error adding documents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Assuming `new_documents` is a list of your new document contents as strings\n",
    "# and `vectorstore` is your initialized vector store object\n",
    "\n",
    "# Convert each text string into a Document object\n",
    "docs_to_add = [Document(page_content=text) for text in docs_texts]\n",
    "\n",
    "# Now, add these Document objects to your vector store\n",
    "added_document_ids = vectorstore.add_documents(docs_to_add)\n",
    "\n",
    "print(f\"Added {len(added_document_ids)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "text = \"..... put the text you copy pasted here......\"\n",
    "doc = Document(page_content=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1cf85403-fd3d-4d47-9538-eecd2d964338']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_docs = [doc]\n",
    "vectorstore.add_documents(\n",
    "    new_docs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.get({'ids':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnablePick\n",
    "from langchain_core.prompts.chat import HumanMessagePromptTemplate, PromptTemplate\n",
    "\n",
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "rag_prompt.messages\n",
    "prompt = HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use one sentence maximum and keep the answer CONCISE. Keep the answer CONCISE.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))\n",
    "rag_prompt.messages = [prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use one sentence maximum and keep the answer CONCISE. Keep the answer CONCISE.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]\n"
     ]
    }
   ],
   "source": [
    "print(rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# Chain\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:   0%|          | 0/315 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.26 ms /    38 runs   (    0.35 ms per token,  2865.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10371.75 ms /   493 tokens (   21.04 ms per token,    47.53 tokens per second)\n",
      "llama_print_timings:        eval time =    6017.01 ms /    37 runs   (  162.62 ms per token,     6.15 tokens per second)\n",
      "llama_print_timings:       total time =   16541.93 ms /   530 tokens\n",
      "Answering questions:   0%|          | 1/315 [00:16<1:27:06, 16.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      21.73 ms /    50 runs   (    0.43 ms per token,  2301.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7492.29 ms /   351 tokens (   21.35 ms per token,    46.85 tokens per second)\n",
      "llama_print_timings:        eval time =    7823.05 ms /    49 runs   (  159.65 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   15568.51 ms /   400 tokens\n",
      "Answering questions:   1%|          | 2/315 [00:32<1:24:03, 16.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.05 ms /    37 runs   (    0.35 ms per token,  2834.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10178.19 ms /   437 tokens (   23.29 ms per token,    42.93 tokens per second)\n",
      "llama_print_timings:        eval time =    5811.16 ms /    36 runs   (  161.42 ms per token,     6.19 tokens per second)\n",
      "llama_print_timings:       total time =   16161.90 ms /   473 tokens\n",
      "Answering questions:   1%|          | 3/315 [00:48<1:24:28, 16.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.80 ms /    40 runs   (    0.35 ms per token,  2897.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8832.42 ms /   400 tokens (   22.08 ms per token,    45.29 tokens per second)\n",
      "llama_print_timings:        eval time =    6124.26 ms /    39 runs   (  157.03 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =   15118.94 ms /   439 tokens\n",
      "Answering questions:   1%|▏         | 4/315 [01:04<1:22:06, 15.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      18.56 ms /    54 runs   (    0.34 ms per token,  2909.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6643.32 ms /   276 tokens (   24.07 ms per token,    41.55 tokens per second)\n",
      "llama_print_timings:        eval time =    8359.38 ms /    53 runs   (  157.72 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =   15207.33 ms /   329 tokens\n",
      "Answering questions:   2%|▏         | 5/315 [01:19<1:20:50, 15.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.54 ms /    24 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13640.66 ms /   620 tokens (   22.00 ms per token,    45.45 tokens per second)\n",
      "llama_print_timings:        eval time =    2263.45 ms /    23 runs   (   98.41 ms per token,    10.16 tokens per second)\n",
      "llama_print_timings:       total time =   16025.97 ms /   643 tokens\n",
      "Answering questions:   2%|▏         | 6/315 [01:35<1:21:30, 15.83s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      17.02 ms /    49 runs   (    0.35 ms per token,  2879.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8946.32 ms /   402 tokens (   22.25 ms per token,    44.93 tokens per second)\n",
      "llama_print_timings:        eval time =    6834.46 ms /    48 runs   (  142.38 ms per token,     7.02 tokens per second)\n",
      "llama_print_timings:       total time =   15997.57 ms /   450 tokens\n",
      "Answering questions:   2%|▏         | 7/315 [01:51<1:21:41, 15.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      27.51 ms /    79 runs   (    0.35 ms per token,  2871.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5989.12 ms /   280 tokens (   21.39 ms per token,    46.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12551.46 ms /    78 runs   (  160.92 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =   18891.86 ms /   358 tokens\n",
      "Answering questions:   3%|▎         | 8/315 [02:10<1:26:26, 16.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      29.02 ms /    84 runs   (    0.35 ms per token,  2894.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13905.06 ms /   577 tokens (   24.10 ms per token,    41.50 tokens per second)\n",
      "llama_print_timings:        eval time =    7174.20 ms /    83 runs   (   86.44 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =   21426.18 ms /   660 tokens\n",
      "Answering questions:   3%|▎         | 9/315 [02:32<1:33:32, 18.34s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      15.39 ms /    44 runs   (    0.35 ms per token,  2858.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15080.79 ms /   686 tokens (   21.98 ms per token,    45.49 tokens per second)\n",
      "llama_print_timings:        eval time =    3542.36 ms /    43 runs   (   82.38 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =   18820.07 ms /   729 tokens\n",
      "Answering questions:   3%|▎         | 10/315 [02:51<1:34:08, 18.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.32 ms /    27 runs   (    0.35 ms per token,  2897.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9202.79 ms /   473 tokens (   19.46 ms per token,    51.40 tokens per second)\n",
      "llama_print_timings:        eval time =    2009.54 ms /    26 runs   (   77.29 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =   11325.76 ms /   499 tokens\n",
      "Answering questions:   3%|▎         | 11/315 [03:02<1:22:52, 16.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.67 ms /    34 runs   (    0.34 ms per token,  2912.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5119.02 ms /   192 tokens (   26.66 ms per token,    37.51 tokens per second)\n",
      "llama_print_timings:        eval time =    2567.53 ms /    33 runs   (   77.80 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:       total time =    7818.01 ms /   225 tokens\n",
      "Answering questions:   4%|▍         | 12/315 [03:10<1:09:39, 13.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      15.76 ms /    46 runs   (    0.34 ms per token,  2918.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6678.21 ms /   304 tokens (   21.97 ms per token,    45.52 tokens per second)\n",
      "llama_print_timings:        eval time =    3489.73 ms /    45 runs   (   77.55 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =   10338.85 ms /   349 tokens\n",
      "Answering questions:   4%|▍         | 13/315 [03:20<1:04:18, 12.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      19.12 ms /    56 runs   (    0.34 ms per token,  2929.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7897.51 ms /   353 tokens (   22.37 ms per token,    44.70 tokens per second)\n",
      "llama_print_timings:        eval time =    4278.42 ms /    55 runs   (   77.79 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =   12384.79 ms /   408 tokens\n",
      "Answering questions:   4%|▍         | 14/315 [03:33<1:03:39, 12.69s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.46 ms /    27 runs   (    0.35 ms per token,  2853.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11294.84 ms /   539 tokens (   20.96 ms per token,    47.72 tokens per second)\n",
      "llama_print_timings:        eval time =    2075.24 ms /    26 runs   (   79.82 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =   13475.39 ms /   565 tokens\n",
      "Answering questions:   5%|▍         | 15/315 [03:46<1:04:50, 12.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    27 runs   (    0.34 ms per token,  2904.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16764.66 ms /   752 tokens (   22.29 ms per token,    44.86 tokens per second)\n",
      "llama_print_timings:        eval time =    2074.44 ms /    26 runs   (   79.79 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =   18947.89 ms /   778 tokens\n",
      "Answering questions:   5%|▌         | 16/315 [04:05<1:13:44, 14.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      31.71 ms /    93 runs   (    0.34 ms per token,  2933.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1614.23 ms /    61 tokens (   26.46 ms per token,    37.79 tokens per second)\n",
      "llama_print_timings:        eval time =    6613.37 ms /    92 runs   (   71.88 ms per token,    13.91 tokens per second)\n",
      "llama_print_timings:       total time =    8574.79 ms /   153 tokens\n",
      "Answering questions:   5%|▌         | 17/315 [04:14<1:04:21, 12.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    15 runs   (    0.35 ms per token,  2892.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8283.05 ms /   378 tokens (   21.91 ms per token,    45.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1063.47 ms /    14 runs   (   75.96 ms per token,    13.16 tokens per second)\n",
      "llama_print_timings:       total time =    9405.03 ms /   392 tokens\n",
      "Answering questions:   6%|▌         | 18/315 [04:24<58:59, 11.92s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /    11 runs   (    0.34 ms per token,  2925.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1302.48 ms /    49 tokens (   26.58 ms per token,    37.62 tokens per second)\n",
      "llama_print_timings:        eval time =     697.88 ms /    10 runs   (   69.79 ms per token,    14.33 tokens per second)\n",
      "llama_print_timings:       total time =    2044.37 ms /    59 tokens\n",
      "Answering questions:   6%|▌         | 19/315 [04:26<44:18,  8.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    23 runs   (    0.36 ms per token,  2805.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10607.00 ms /   490 tokens (   21.65 ms per token,    46.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1733.38 ms /    22 runs   (   78.79 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =   12428.88 ms /   512 tokens\n",
      "Answering questions:   6%|▋         | 20/315 [04:39<49:41, 10.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     6 runs   (    0.34 ms per token,  2906.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13321.36 ms /   614 tokens (   21.70 ms per token,    46.09 tokens per second)\n",
      "llama_print_timings:        eval time =     392.07 ms /     5 runs   (   78.41 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =   13744.81 ms /   619 tokens\n",
      "Answering questions:   7%|▋         | 21/315 [04:52<55:03, 11.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.66 ms /    40 runs   (    0.34 ms per token,  2927.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1817.85 ms /    69 tokens (   26.35 ms per token,    37.96 tokens per second)\n",
      "llama_print_timings:        eval time =    2762.50 ms /    39 runs   (   70.83 ms per token,    14.12 tokens per second)\n",
      "llama_print_timings:       total time =    4736.95 ms /   108 tokens\n",
      "Answering questions:   7%|▋         | 22/315 [04:57<45:50,  9.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       5.50 ms /    16 runs   (    0.34 ms per token,  2909.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4735.26 ms /   180 tokens (   26.31 ms per token,    38.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1830.74 ms /    15 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =    6628.88 ms /   195 tokens\n",
      "Answering questions:   7%|▋         | 23/315 [05:04<41:49,  8.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       4.79 ms /    14 runs   (    0.34 ms per token,  2925.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1881.59 ms /    69 tokens (   27.27 ms per token,    36.67 tokens per second)\n",
      "llama_print_timings:        eval time =     998.64 ms /    13 runs   (   76.82 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:       total time =    2931.23 ms /    82 tokens\n",
      "Answering questions:   8%|▊         | 24/315 [05:07<33:35,  6.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    36 runs   (    0.34 ms per token,  2923.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16234.81 ms /   716 tokens (   22.67 ms per token,    44.10 tokens per second)\n",
      "llama_print_timings:        eval time =    2777.80 ms /    35 runs   (   79.37 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =   19155.74 ms /   751 tokens\n",
      "Answering questions:   8%|▊         | 25/315 [05:27<51:21, 10.63s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    17 runs   (    0.34 ms per token,  2901.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7929.34 ms /   353 tokens (   22.46 ms per token,    44.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1242.70 ms /    16 runs   (   77.67 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =    9237.40 ms /   369 tokens\n",
      "Answering questions:   8%|▊         | 26/315 [05:36<49:18, 10.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.87 ms /    26 runs   (    0.50 ms per token,  2019.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8333.32 ms /   375 tokens (   22.22 ms per token,    45.00 tokens per second)\n",
      "llama_print_timings:        eval time =    3471.89 ms /    25 runs   (  138.88 ms per token,     7.20 tokens per second)\n",
      "llama_print_timings:       total time =   11977.73 ms /   400 tokens\n",
      "Answering questions:   9%|▊         | 27/315 [05:48<51:47, 10.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      15.84 ms /    46 runs   (    0.34 ms per token,  2903.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7736.35 ms /   330 tokens (   23.44 ms per token,    42.66 tokens per second)\n",
      "llama_print_timings:        eval time =    3545.75 ms /    45 runs   (   78.79 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =   11464.72 ms /   375 tokens\n",
      "Answering questions:   9%|▉         | 28/315 [05:59<52:43, 11.02s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.41 ms /    30 runs   (    0.35 ms per token,  2882.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10603.69 ms /   515 tokens (   20.59 ms per token,    48.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2250.50 ms /    29 runs   (   77.60 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =   12981.24 ms /   544 tokens\n",
      "Answering questions:   9%|▉         | 29/315 [06:13<55:28, 11.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.69 ms /    31 runs   (    0.34 ms per token,  2900.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7470.90 ms /   310 tokens (   24.10 ms per token,    41.49 tokens per second)\n",
      "llama_print_timings:        eval time =    2560.85 ms /    30 runs   (   85.36 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:       total time =   10171.43 ms /   340 tokens\n",
      "Answering questions:  10%|▉         | 30/315 [06:23<53:21, 11.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      20.91 ms /    48 runs   (    0.44 ms per token,  2295.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6869.11 ms /   289 tokens (   23.77 ms per token,    42.07 tokens per second)\n",
      "llama_print_timings:        eval time =    3573.51 ms /    47 runs   (   76.03 ms per token,    13.15 tokens per second)\n",
      "llama_print_timings:       total time =   10692.51 ms /   336 tokens\n",
      "Answering questions:  10%|▉         | 31/315 [06:34<52:47, 11.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    22 runs   (    0.36 ms per token,  2754.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15332.56 ms /   680 tokens (   22.55 ms per token,    44.35 tokens per second)\n",
      "llama_print_timings:        eval time =    3592.91 ms /    21 runs   (  171.09 ms per token,     5.84 tokens per second)\n",
      "llama_print_timings:       total time =   19056.63 ms /   701 tokens\n",
      "Answering questions:  10%|█         | 32/315 [06:53<1:03:58, 13.56s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      22.31 ms /    53 runs   (    0.42 ms per token,  2375.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9065.10 ms /   404 tokens (   22.44 ms per token,    44.57 tokens per second)\n",
      "llama_print_timings:        eval time =    8484.41 ms /    52 runs   (  163.16 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   17807.15 ms /   456 tokens\n",
      "Answering questions:  10%|█         | 33/315 [07:11<1:10:17, 14.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       5.85 ms /    17 runs   (    0.34 ms per token,  2907.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10728.63 ms /   460 tokens (   23.32 ms per token,    42.88 tokens per second)\n",
      "llama_print_timings:        eval time =    2664.21 ms /    16 runs   (  166.51 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =   13457.52 ms /   476 tokens\n",
      "Answering questions:  11%|█         | 34/315 [07:25<1:08:05, 14.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    26 runs   (    0.34 ms per token,  2908.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12939.00 ms /   592 tokens (   21.86 ms per token,    45.75 tokens per second)\n",
      "llama_print_timings:        eval time =    4127.59 ms /    25 runs   (  165.10 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =   17168.31 ms /   617 tokens\n",
      "Answering questions:  11%|█         | 35/315 [07:42<1:12:07, 15.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /     7 runs   (    0.34 ms per token,  2928.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1927.27 ms /    69 tokens (   27.93 ms per token,    35.80 tokens per second)\n",
      "llama_print_timings:        eval time =     949.38 ms /     6 runs   (  158.23 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =    2901.60 ms /    75 tokens\n",
      "Answering questions:  11%|█▏        | 36/315 [07:46<54:48, 11.79s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.59 ms /    31 runs   (    0.34 ms per token,  2926.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10559.15 ms /   497 tokens (   21.25 ms per token,    47.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4949.97 ms /    30 runs   (  165.00 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =   15622.66 ms /   527 tokens\n",
      "Answering questions:  12%|█▏        | 37/315 [08:01<1:00:04, 12.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /     6 runs   (    0.34 ms per token,  2945.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8065.67 ms /   375 tokens (   21.51 ms per token,    46.49 tokens per second)\n",
      "llama_print_timings:        eval time =     821.21 ms /     5 runs   (  164.24 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =    8908.78 ms /   380 tokens\n",
      "Answering questions:  12%|█▏        | 38/315 [08:10<54:22, 11.78s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      26.52 ms /    77 runs   (    0.34 ms per token,  2903.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9620.79 ms /   451 tokens (   21.33 ms per token,    46.88 tokens per second)\n",
      "llama_print_timings:        eval time =   10440.04 ms /    76 runs   (  137.37 ms per token,     7.28 tokens per second)\n",
      "llama_print_timings:       total time =   20387.41 ms /   527 tokens\n",
      "Answering questions:  12%|█▏        | 39/315 [08:31<1:06:12, 14.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    36 runs   (    0.34 ms per token,  2925.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19747.62 ms /   874 tokens (   22.59 ms per token,    44.26 tokens per second)\n",
      "llama_print_timings:        eval time =    5951.26 ms /    35 runs   (  170.04 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   25837.59 ms /   909 tokens\n",
      "Answering questions:  13%|█▎        | 40/315 [08:57<1:21:52, 17.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    22 runs   (    0.35 ms per token,  2830.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8567.59 ms /   389 tokens (   22.02 ms per token,    45.40 tokens per second)\n",
      "llama_print_timings:        eval time =    3405.37 ms /    21 runs   (  162.16 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:       total time =   12063.02 ms /   410 tokens\n",
      "Answering questions:  13%|█▎        | 41/315 [09:09<1:13:45, 16.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    27 runs   (    0.34 ms per token,  2913.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9915.81 ms /   464 tokens (   21.37 ms per token,    46.79 tokens per second)\n",
      "llama_print_timings:        eval time =    4180.58 ms /    26 runs   (  160.79 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =   14194.06 ms /   490 tokens\n",
      "Answering questions:  13%|█▎        | 42/315 [09:23<1:10:56, 15.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      19.98 ms /    58 runs   (    0.34 ms per token,  2903.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10503.75 ms /   441 tokens (   23.82 ms per token,    41.99 tokens per second)\n",
      "llama_print_timings:        eval time =    9201.53 ms /    57 runs   (  161.43 ms per token,     6.19 tokens per second)\n",
      "llama_print_timings:       total time =   19919.84 ms /   498 tokens\n",
      "Answering questions:  14%|█▎        | 43/315 [09:43<1:16:42, 16.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /    10 runs   (    0.34 ms per token,  2912.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.28 ms /    29 tokens (   29.15 ms per token,    34.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1406.49 ms /     9 runs   (  156.28 ms per token,     6.40 tokens per second)\n",
      "llama_print_timings:       total time =    2287.01 ms /    38 tokens\n",
      "Answering questions:  14%|█▍        | 44/315 [09:46<56:50, 12.58s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    23 runs   (    0.37 ms per token,  2678.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9164.63 ms /   423 tokens (   21.67 ms per token,    46.16 tokens per second)\n",
      "llama_print_timings:        eval time =    3498.41 ms /    22 runs   (  159.02 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   12792.19 ms /   445 tokens\n",
      "Answering questions:  14%|█▍        | 45/315 [09:59<57:01, 12.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.93 ms /    26 runs   (    0.34 ms per token,  2911.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3423.99 ms /   131 tokens (   26.14 ms per token,    38.26 tokens per second)\n",
      "llama_print_timings:        eval time =    3936.35 ms /    25 runs   (  157.45 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =    7455.85 ms /   156 tokens\n",
      "Answering questions:  15%|█▍        | 46/315 [10:06<50:00, 11.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      31.92 ms /    90 runs   (    0.35 ms per token,  2819.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12000.39 ms /   549 tokens (   21.86 ms per token,    45.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11284.68 ms /    89 runs   (  126.79 ms per token,     7.89 tokens per second)\n",
      "llama_print_timings:       total time =   23705.26 ms /   638 tokens\n",
      "Answering questions:  15%|█▍        | 47/315 [10:30<1:06:45, 14.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.02 ms /    45 runs   (    0.36 ms per token,  2808.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     997.28 ms /    36 tokens (   27.70 ms per token,    36.10 tokens per second)\n",
      "llama_print_timings:        eval time =    6347.22 ms /    44 runs   (  144.26 ms per token,     6.93 tokens per second)\n",
      "llama_print_timings:       total time =    7524.67 ms /    80 tokens\n",
      "Answering questions:  15%|█▌        | 48/315 [10:38<56:52, 12.78s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      15.12 ms /    42 runs   (    0.36 ms per token,  2777.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17009.52 ms /   736 tokens (   23.11 ms per token,    43.27 tokens per second)\n",
      "llama_print_timings:        eval time =    3375.96 ms /    41 runs   (   82.34 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =   20580.29 ms /   777 tokens\n",
      "Answering questions:  16%|█▌        | 49/315 [10:58<1:07:13, 15.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    25 runs   (    0.36 ms per token,  2797.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10692.33 ms /   485 tokens (   22.05 ms per token,    45.36 tokens per second)\n",
      "llama_print_timings:        eval time =    2063.73 ms /    24 runs   (   85.99 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =   12863.60 ms /   509 tokens\n",
      "Answering questions:  16%|█▌        | 50/315 [11:11<1:04:03, 14.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    20 runs   (    0.34 ms per token,  2914.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10228.15 ms /   486 tokens (   21.05 ms per token,    47.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1699.54 ms /    19 runs   (   89.45 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =   12006.76 ms /   505 tokens\n",
      "Answering questions:  16%|█▌        | 51/315 [11:24<1:00:40, 13.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /     8 runs   (    0.35 ms per token,  2898.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.19 ms /    40 tokens (   27.80 ms per token,    35.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1050.63 ms /     7 runs   (  150.09 ms per token,     6.66 tokens per second)\n",
      "llama_print_timings:       total time =    2196.76 ms /    47 tokens\n",
      "Answering questions:  17%|█▋        | 52/315 [11:26<45:29, 10.38s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.83 ms /    49 runs   (    0.34 ms per token,  2910.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9974.16 ms /   469 tokens (   21.27 ms per token,    47.02 tokens per second)\n",
      "llama_print_timings:        eval time =    4824.91 ms /    48 runs   (  100.52 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =   14999.27 ms /   517 tokens\n",
      "Answering questions:  17%|█▋        | 53/315 [11:41<51:33, 11.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      25.23 ms /    73 runs   (    0.35 ms per token,  2893.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9504.13 ms /   480 tokens (   19.80 ms per token,    50.50 tokens per second)\n",
      "llama_print_timings:        eval time =    5759.63 ms /    72 runs   (   79.99 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =   15549.99 ms /   552 tokens\n",
      "Answering questions:  17%|█▋        | 54/315 [11:57<56:23, 12.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    35 runs   (    0.34 ms per token,  2923.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15634.76 ms /   686 tokens (   22.79 ms per token,    43.88 tokens per second)\n",
      "llama_print_timings:        eval time =    2776.83 ms /    34 runs   (   81.67 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =   18551.01 ms /   720 tokens\n",
      "Answering questions:  17%|█▋        | 55/315 [12:15<1:03:33, 14.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.91 ms /    39 runs   (    0.43 ms per token,  2306.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8434.08 ms /   351 tokens (   24.03 ms per token,    41.62 tokens per second)\n",
      "llama_print_timings:        eval time =    6275.37 ms /    38 runs   (  165.14 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =   14931.52 ms /   389 tokens\n",
      "Answering questions:  18%|█▊        | 56/315 [12:30<1:03:49, 14.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      17.11 ms /    45 runs   (    0.38 ms per token,  2630.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13852.60 ms /   616 tokens (   22.49 ms per token,    44.47 tokens per second)\n",
      "llama_print_timings:        eval time =    7192.28 ms /    44 runs   (  163.46 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   21237.54 ms /   660 tokens\n",
      "Answering questions:  18%|█▊        | 57/315 [12:52<1:12:06, 16.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    35 runs   (    0.35 ms per token,  2897.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5154.23 ms /   200 tokens (   25.77 ms per token,    38.80 tokens per second)\n",
      "llama_print_timings:        eval time =    5428.99 ms /    34 runs   (  159.68 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   10719.83 ms /   234 tokens\n",
      "Answering questions:  18%|█▊        | 58/315 [13:03<1:04:16, 15.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /     7 runs   (    0.34 ms per token,  2908.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4579.70 ms /   173 tokens (   26.47 ms per token,    37.78 tokens per second)\n",
      "llama_print_timings:        eval time =     953.91 ms /     6 runs   (  158.99 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =    5559.99 ms /   179 tokens\n",
      "Answering questions:  19%|█▊        | 59/315 [13:08<52:03, 12.20s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.60 ms /    28 runs   (    0.34 ms per token,  2915.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6138.11 ms /   247 tokens (   24.85 ms per token,    40.24 tokens per second)\n",
      "llama_print_timings:        eval time =    4319.58 ms /    27 runs   (  159.98 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   10561.32 ms /   274 tokens\n",
      "Answering questions:  19%|█▉        | 60/315 [13:19<50:00, 11.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      18.84 ms /    55 runs   (    0.34 ms per token,  2919.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6887.69 ms /   291 tokens (   23.67 ms per token,    42.25 tokens per second)\n",
      "llama_print_timings:        eval time =    8590.89 ms /    54 runs   (  159.09 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   15679.68 ms /   345 tokens\n",
      "Answering questions:  19%|█▉        | 61/315 [13:35<54:54, 12.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    31 runs   (    0.34 ms per token,  2931.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2437.12 ms /    92 tokens (   26.49 ms per token,    37.75 tokens per second)\n",
      "llama_print_timings:        eval time =    4658.84 ms /    30 runs   (  155.29 ms per token,     6.44 tokens per second)\n",
      "llama_print_timings:       total time =    7207.05 ms /   122 tokens\n",
      "Answering questions:  20%|█▉        | 62/315 [13:42<47:34, 11.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      15.48 ms /    44 runs   (    0.35 ms per token,  2842.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6732.18 ms /   296 tokens (   22.74 ms per token,    43.97 tokens per second)\n",
      "llama_print_timings:        eval time =    6870.50 ms /    43 runs   (  159.78 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   13764.20 ms /   339 tokens\n",
      "Answering questions:  20%|██        | 63/315 [13:56<50:37, 12.05s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    22 runs   (    0.34 ms per token,  2920.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7736.92 ms /   338 tokens (   22.89 ms per token,    43.69 tokens per second)\n",
      "llama_print_timings:        eval time =    3348.92 ms /    21 runs   (  159.47 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   11166.34 ms /   359 tokens\n",
      "Answering questions:  20%|██        | 64/315 [14:07<49:25, 11.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       4.81 ms /    14 runs   (    0.34 ms per token,  2910.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2721.87 ms /   100 tokens (   27.22 ms per token,    36.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2026.11 ms /    13 runs   (  155.85 ms per token,     6.42 tokens per second)\n",
      "llama_print_timings:       total time =    4800.79 ms /   113 tokens\n",
      "Answering questions:  21%|██        | 65/315 [14:12<40:37,  9.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    20 runs   (    0.34 ms per token,  2917.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10710.54 ms /   517 tokens (   20.72 ms per token,    48.27 tokens per second)\n",
      "llama_print_timings:        eval time =    3053.84 ms /    19 runs   (  160.73 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =   13841.53 ms /   536 tokens\n",
      "Answering questions:  21%|██        | 66/315 [14:26<45:40, 11.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.69 ms /    31 runs   (    0.34 ms per token,  2901.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5537.01 ms /   218 tokens (   25.40 ms per token,    39.37 tokens per second)\n",
      "llama_print_timings:        eval time =    4808.94 ms /    30 runs   (  160.30 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   10459.13 ms /   248 tokens\n",
      "Answering questions:  21%|██▏       | 67/315 [14:37<45:03, 10.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    36 runs   (    0.34 ms per token,  2925.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4221.99 ms /   161 tokens (   26.22 ms per token,    38.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5496.01 ms /    35 runs   (  157.03 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =    9848.31 ms /   196 tokens\n",
      "Answering questions:  22%|██▏       | 68/315 [14:47<43:41, 10.61s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      24.39 ms /    71 runs   (    0.34 ms per token,  2911.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9685.62 ms /   445 tokens (   21.77 ms per token,    45.94 tokens per second)\n",
      "llama_print_timings:        eval time =   11146.41 ms /    70 runs   (  159.23 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   21094.38 ms /   515 tokens\n",
      "Answering questions:  22%|██▏       | 69/315 [15:08<56:31, 13.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    27 runs   (    0.34 ms per token,  2900.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18179.23 ms /   788 tokens (   23.07 ms per token,    43.35 tokens per second)\n",
      "llama_print_timings:        eval time =    4192.39 ms /    26 runs   (  161.25 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =   22476.00 ms /   814 tokens\n",
      "Answering questions:  22%|██▏       | 70/315 [15:31<1:07:05, 16.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      67.39 ms /   197 runs   (    0.34 ms per token,  2923.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17450.46 ms /   797 tokens (   21.90 ms per token,    45.67 tokens per second)\n",
      "llama_print_timings:        eval time =   31291.25 ms /   196 runs   (  159.65 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   49509.72 ms /   993 tokens\n",
      "Answering questions:  23%|██▎       | 71/315 [16:20<1:47:21, 26.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    35 runs   (    0.34 ms per token,  2916.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1736.40 ms /    63 tokens (   27.56 ms per token,    36.28 tokens per second)\n",
      "llama_print_timings:        eval time =    5316.36 ms /    34 runs   (  156.36 ms per token,     6.40 tokens per second)\n",
      "llama_print_timings:       total time =    7178.80 ms /    97 tokens\n",
      "Answering questions:  23%|██▎       | 72/315 [16:28<1:23:45, 20.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      22.21 ms /    65 runs   (    0.34 ms per token,  2927.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10988.15 ms /   492 tokens (   22.33 ms per token,    44.78 tokens per second)\n",
      "llama_print_timings:        eval time =   10110.04 ms /    64 runs   (  157.97 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   21343.14 ms /   556 tokens\n",
      "Answering questions:  23%|██▎       | 73/315 [16:49<1:24:19, 20.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    22 runs   (    0.34 ms per token,  2922.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6204.80 ms /   252 tokens (   24.62 ms per token,    40.61 tokens per second)\n",
      "llama_print_timings:        eval time =    3337.54 ms /    21 runs   (  158.93 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =    9621.26 ms /   273 tokens\n",
      "Answering questions:  23%|██▎       | 74/315 [16:59<1:10:29, 17.55s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.96 ms /    29 runs   (    0.34 ms per token,  2910.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6068.90 ms /   233 tokens (   26.05 ms per token,    38.39 tokens per second)\n",
      "llama_print_timings:        eval time =    4465.26 ms /    28 runs   (  159.47 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   10638.58 ms /   261 tokens\n",
      "Answering questions:  24%|██▍       | 75/315 [17:10<1:02:01, 15.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      20.87 ms /    61 runs   (    0.34 ms per token,  2922.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9837.93 ms /   432 tokens (   22.77 ms per token,    43.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9422.90 ms /    60 runs   (  157.05 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =   19485.99 ms /   492 tokens\n",
      "Answering questions:  24%|██▍       | 76/315 [17:29<1:06:37, 16.73s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    20 runs   (    0.34 ms per token,  2901.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16343.12 ms /   715 tokens (   22.86 ms per token,    43.75 tokens per second)\n",
      "llama_print_timings:        eval time =    3036.53 ms /    19 runs   (  159.82 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   19457.42 ms /   734 tokens\n",
      "Answering questions:  24%|██▍       | 77/315 [17:49<1:09:42, 17.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    18 runs   (    0.34 ms per token,  2915.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10554.71 ms /   484 tokens (   21.81 ms per token,    45.86 tokens per second)\n",
      "llama_print_timings:        eval time =    2707.03 ms /    17 runs   (  159.24 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   13328.93 ms /   501 tokens\n",
      "Answering questions:  25%|██▍       | 78/315 [18:02<1:04:29, 16.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    24 runs   (    0.34 ms per token,  2919.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7179.58 ms /   302 tokens (   23.77 ms per token,    42.06 tokens per second)\n",
      "llama_print_timings:        eval time =    3648.22 ms /    23 runs   (  158.62 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:       total time =   10915.05 ms /   325 tokens\n",
      "Answering questions:  25%|██▌       | 79/315 [18:13<57:56, 14.73s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    22 runs   (    0.35 ms per token,  2893.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7314.65 ms /   282 tokens (   25.94 ms per token,    38.55 tokens per second)\n",
      "llama_print_timings:        eval time =    3296.64 ms /    21 runs   (  156.98 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =   10708.56 ms /   303 tokens\n",
      "Answering questions:  25%|██▌       | 80/315 [18:24<53:04, 13.55s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      18.17 ms /    53 runs   (    0.34 ms per token,  2916.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8387.90 ms /   381 tokens (   22.02 ms per token,    45.42 tokens per second)\n",
      "llama_print_timings:        eval time =    8060.69 ms /    52 runs   (  155.01 ms per token,     6.45 tokens per second)\n",
      "llama_print_timings:       total time =   16653.51 ms /   433 tokens\n",
      "Answering questions:  26%|██▌       | 81/315 [18:41<56:35, 14.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      87.42 ms /   256 runs   (    0.34 ms per token,  2928.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5849.78 ms /   230 tokens (   25.43 ms per token,    39.32 tokens per second)\n",
      "llama_print_timings:        eval time =   38824.05 ms /   255 runs   (  152.25 ms per token,     6.57 tokens per second)\n",
      "llama_print_timings:       total time =   45683.06 ms /   485 tokens\n",
      "Answering questions:  26%|██▌       | 82/315 [19:26<1:32:47, 23.89s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.12 ms /    47 runs   (    0.34 ms per token,  2914.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.58 ms /    55 tokens (   27.01 ms per token,    37.02 tokens per second)\n",
      "llama_print_timings:        eval time =    7129.24 ms /    46 runs   (  154.98 ms per token,     6.45 tokens per second)\n",
      "llama_print_timings:       total time =    8785.86 ms /   101 tokens\n",
      "Answering questions:  26%|██▋       | 83/315 [19:35<1:14:58, 19.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    21 runs   (    0.37 ms per token,  2731.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12978.48 ms /   606 tokens (   21.42 ms per token,    46.69 tokens per second)\n",
      "llama_print_timings:        eval time =    3147.24 ms /    20 runs   (  157.36 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =   16215.37 ms /   626 tokens\n",
      "Answering questions:  27%|██▋       | 84/315 [19:52<1:11:05, 18.47s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      20.07 ms /    58 runs   (    0.35 ms per token,  2889.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16879.38 ms /   756 tokens (   22.33 ms per token,    44.79 tokens per second)\n",
      "llama_print_timings:        eval time =    8294.62 ms /    57 runs   (  145.52 ms per token,     6.87 tokens per second)\n",
      "llama_print_timings:       total time =   25416.52 ms /   813 tokens\n",
      "Answering questions:  27%|██▋       | 85/315 [20:17<1:18:54, 20.58s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      38.12 ms /   111 runs   (    0.34 ms per token,  2912.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9521.04 ms /   430 tokens (   22.14 ms per token,    45.16 tokens per second)\n",
      "llama_print_timings:        eval time =   17283.05 ms /   110 runs   (  157.12 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   27233.36 ms /   540 tokens\n",
      "Answering questions:  27%|██▋       | 86/315 [20:44<1:26:17, 22.61s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.60 ms /    26 runs   (    0.52 ms per token,  1912.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6233.51 ms /   245 tokens (   25.44 ms per token,    39.30 tokens per second)\n",
      "llama_print_timings:        eval time =    2424.41 ms /    25 runs   (   96.98 ms per token,    10.31 tokens per second)\n",
      "llama_print_timings:       total time =    8841.53 ms /   270 tokens\n",
      "Answering questions:  28%|██▊       | 87/315 [20:53<1:10:25, 18.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    24 runs   (    0.35 ms per token,  2881.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2682.12 ms /   102 tokens (   26.30 ms per token,    38.03 tokens per second)\n",
      "llama_print_timings:        eval time =    3645.78 ms /    23 runs   (  158.51 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:       total time =    6418.66 ms /   125 tokens\n",
      "Answering questions:  28%|██▊       | 88/315 [21:00<56:29, 14.93s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      21.33 ms /    62 runs   (    0.34 ms per token,  2906.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6959.84 ms /   300 tokens (   23.20 ms per token,    43.10 tokens per second)\n",
      "llama_print_timings:        eval time =    9670.76 ms /    61 runs   (  158.54 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:       total time =   16870.75 ms /   361 tokens\n",
      "Answering questions:  28%|██▊       | 89/315 [21:17<58:39, 15.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      19.37 ms /    53 runs   (    0.37 ms per token,  2736.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9388.12 ms /   431 tokens (   21.78 ms per token,    45.91 tokens per second)\n",
      "llama_print_timings:        eval time =    4290.60 ms /    52 runs   (   82.51 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =   13909.89 ms /   483 tokens\n",
      "Answering questions:  29%|██▊       | 90/315 [21:31<56:39, 15.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      79.71 ms /   231 runs   (    0.35 ms per token,  2897.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16096.52 ms /   728 tokens (   22.11 ms per token,    45.23 tokens per second)\n",
      "llama_print_timings:        eval time =   19132.32 ms /   230 runs   (   83.18 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =   36226.47 ms /   958 tokens\n",
      "Answering questions:  29%|██▉       | 91/315 [22:08<1:20:22, 21.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      14.01 ms /    41 runs   (    0.34 ms per token,  2926.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8068.27 ms /   379 tokens (   21.29 ms per token,    46.97 tokens per second)\n",
      "llama_print_timings:        eval time =    3095.59 ms /    40 runs   (   77.39 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =   11321.94 ms /   419 tokens\n",
      "Answering questions:  29%|██▉       | 92/315 [22:19<1:08:47, 18.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    19 runs   (    0.34 ms per token,  2932.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4463.12 ms /   168 tokens (   26.57 ms per token,    37.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1369.41 ms /    18 runs   (   76.08 ms per token,    13.14 tokens per second)\n",
      "llama_print_timings:       total time =    5902.92 ms /   186 tokens\n",
      "Answering questions:  30%|██▉       | 93/315 [22:25<54:42, 14.78s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    22 runs   (    0.34 ms per token,  2951.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8972.03 ms /   409 tokens (   21.94 ms per token,    45.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1625.29 ms /    21 runs   (   77.39 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =   10680.97 ms /   430 tokens\n",
      "Answering questions:  30%|██▉       | 94/315 [22:36<50:02, 13.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.85 ms /    26 runs   (    0.34 ms per token,  2937.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9760.98 ms /   457 tokens (   21.36 ms per token,    46.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1929.92 ms /    25 runs   (   77.20 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:       total time =   11791.19 ms /   482 tokens\n",
      "Answering questions:  30%|███       | 95/315 [22:48<47:57, 13.08s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /     4 runs   (    1.31 ms per token,   765.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7829.70 ms /   322 tokens (   24.32 ms per token,    41.13 tokens per second)\n",
      "llama_print_timings:        eval time =     533.44 ms /     3 runs   (  177.81 ms per token,     5.62 tokens per second)\n",
      "llama_print_timings:       total time =    8453.46 ms /   325 tokens\n",
      "Answering questions:  30%|███       | 96/315 [22:57<42:52, 11.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      15.19 ms /    41 runs   (    0.37 ms per token,  2699.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16036.70 ms /   713 tokens (   22.49 ms per token,    44.46 tokens per second)\n",
      "llama_print_timings:        eval time =    3930.64 ms /    40 runs   (   98.27 ms per token,    10.18 tokens per second)\n",
      "llama_print_timings:       total time =   20154.84 ms /   753 tokens\n",
      "Answering questions:  31%|███       | 97/315 [23:17<51:57, 14.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    12 runs   (    0.35 ms per token,  2889.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1878.69 ms /    71 tokens (   26.46 ms per token,    37.79 tokens per second)\n",
      "llama_print_timings:        eval time =     794.96 ms /    11 runs   (   72.27 ms per token,    13.84 tokens per second)\n",
      "llama_print_timings:       total time =    2720.68 ms /    82 tokens\n",
      "Answering questions:  31%|███       | 98/315 [23:20<39:16, 10.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      30.30 ms /    87 runs   (    0.35 ms per token,  2871.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3898.92 ms /   150 tokens (   25.99 ms per token,    38.47 tokens per second)\n",
      "llama_print_timings:        eval time =    6273.80 ms /    86 runs   (   72.95 ms per token,    13.71 tokens per second)\n",
      "llama_print_timings:       total time =   10527.83 ms /   236 tokens\n",
      "Answering questions:  31%|███▏      | 99/315 [23:30<38:55, 10.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      14.52 ms /    41 runs   (    0.35 ms per token,  2824.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7018.28 ms /   292 tokens (   24.04 ms per token,    41.61 tokens per second)\n",
      "llama_print_timings:        eval time =    6746.55 ms /    40 runs   (  168.66 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:       total time =   13941.89 ms /   332 tokens\n",
      "Answering questions:  32%|███▏      | 100/315 [23:44<42:17, 11.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     6 runs   (    0.35 ms per token,  2895.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14898.42 ms /   719 tokens (   20.72 ms per token,    48.26 tokens per second)\n",
      "llama_print_timings:        eval time =     881.61 ms /     5 runs   (  176.32 ms per token,     5.67 tokens per second)\n",
      "llama_print_timings:       total time =   15814.37 ms /   724 tokens\n",
      "Answering questions:  32%|███▏      | 101/315 [24:00<46:30, 13.04s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.42 ms /    39 runs   (    0.34 ms per token,  2905.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15042.34 ms /   693 tokens (   21.71 ms per token,    46.07 tokens per second)\n",
      "llama_print_timings:        eval time =    6383.80 ms /    38 runs   (  167.99 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   21577.73 ms /   731 tokens\n",
      "Answering questions:  32%|███▏      | 102/315 [24:22<55:31, 15.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      14.37 ms /    42 runs   (    0.34 ms per token,  2923.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.35 ms /    48 tokens (   28.65 ms per token,    34.90 tokens per second)\n",
      "llama_print_timings:        eval time =    6477.97 ms /    41 runs   (  158.00 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =    8006.82 ms /    89 tokens\n",
      "Answering questions:  33%|███▎      | 103/315 [24:30<47:19, 13.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      24.71 ms /    72 runs   (    0.34 ms per token,  2914.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12307.32 ms /   561 tokens (   21.94 ms per token,    45.58 tokens per second)\n",
      "llama_print_timings:        eval time =   11328.40 ms /    71 runs   (  159.55 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   23906.72 ms /   632 tokens\n",
      "Answering questions:  33%|███▎      | 104/315 [24:54<58:17, 16.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.45 ms /    39 runs   (    0.34 ms per token,  2900.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16704.13 ms /   731 tokens (   22.85 ms per token,    43.76 tokens per second)\n",
      "llama_print_timings:        eval time =    6197.60 ms /    38 runs   (  163.09 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   23047.51 ms /   769 tokens\n",
      "Answering questions:  33%|███▎      | 105/315 [25:18<1:05:05, 18.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.71 ms /    37 runs   (    0.34 ms per token,  2910.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9655.00 ms /   438 tokens (   22.04 ms per token,    45.37 tokens per second)\n",
      "llama_print_timings:        eval time =    5783.11 ms /    36 runs   (  160.64 ms per token,     6.23 tokens per second)\n",
      "llama_print_timings:       total time =   15572.33 ms /   474 tokens\n",
      "Answering questions:  34%|███▎      | 106/315 [25:33<1:01:47, 17.74s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    17 runs   (    0.34 ms per token,  2899.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20557.60 ms /   954 tokens (   21.55 ms per token,    46.41 tokens per second)\n",
      "llama_print_timings:        eval time =    2609.31 ms /    16 runs   (  163.08 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   23233.99 ms /   970 tokens\n",
      "Answering questions:  34%|███▍      | 107/315 [25:57<1:07:19, 19.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.81 ms /    37 runs   (    0.35 ms per token,  2888.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1726.42 ms /    64 tokens (   26.98 ms per token,    37.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4866.68 ms /    36 runs   (  135.19 ms per token,     7.40 tokens per second)\n",
      "llama_print_timings:       total time =    6737.49 ms /   100 tokens\n",
      "Answering questions:  34%|███▍      | 108/315 [26:03<54:00, 15.65s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    19 runs   (    0.35 ms per token,  2889.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7858.87 ms /   353 tokens (   22.26 ms per token,    44.92 tokens per second)\n",
      "llama_print_timings:        eval time =    2801.78 ms /    18 runs   (  155.65 ms per token,     6.42 tokens per second)\n",
      "llama_print_timings:       total time =   10741.86 ms /   371 tokens\n",
      "Answering questions:  35%|███▍      | 109/315 [26:14<48:47, 14.21s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.69 ms /    34 runs   (    0.34 ms per token,  2907.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9240.38 ms /   442 tokens (   20.91 ms per token,    47.83 tokens per second)\n",
      "llama_print_timings:        eval time =    5265.34 ms /    33 runs   (  159.56 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   14630.49 ms /   475 tokens\n",
      "Answering questions:  35%|███▍      | 110/315 [26:29<49:26, 14.47s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      24.11 ms /    70 runs   (    0.34 ms per token,  2903.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15288.68 ms /   674 tokens (   22.68 ms per token,    44.08 tokens per second)\n",
      "llama_print_timings:        eval time =   11087.52 ms /    69 runs   (  160.69 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =   26637.48 ms /   743 tokens\n",
      "Answering questions:  35%|███▌      | 111/315 [26:56<1:01:58, 18.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    21 runs   (    0.34 ms per token,  2901.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16835.09 ms /   703 tokens (   23.95 ms per token,    41.76 tokens per second)\n",
      "llama_print_timings:        eval time =    3275.10 ms /    20 runs   (  163.76 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   20190.61 ms /   723 tokens\n",
      "Answering questions:  36%|███▌      | 112/315 [27:17<1:03:46, 18.85s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.88 ms /    26 runs   (    0.34 ms per token,  2926.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9760.92 ms /   445 tokens (   21.93 ms per token,    45.59 tokens per second)\n",
      "llama_print_timings:        eval time =    4027.39 ms /    25 runs   (  161.10 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =   13881.71 ms /   470 tokens\n",
      "Answering questions:  36%|███▌      | 113/315 [27:31<58:32, 17.39s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    23 runs   (    0.34 ms per token,  2923.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1464.81 ms /    53 tokens (   27.64 ms per token,    36.18 tokens per second)\n",
      "llama_print_timings:        eval time =    3451.66 ms /    22 runs   (  156.89 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =    4996.89 ms /    75 tokens\n",
      "Answering questions:  36%|███▌      | 114/315 [27:36<45:56, 13.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.81 ms /    31 runs   (    0.35 ms per token,  2867.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8753.70 ms /   393 tokens (   22.27 ms per token,    44.90 tokens per second)\n",
      "llama_print_timings:        eval time =    4725.98 ms /    30 runs   (  157.53 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =   13635.36 ms /   423 tokens\n",
      "Answering questions:  37%|███▋      | 115/315 [27:50<45:44, 13.72s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    23 runs   (    0.35 ms per token,  2893.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6947.29 ms /   280 tokens (   24.81 ms per token,    40.30 tokens per second)\n",
      "llama_print_timings:        eval time =    3474.05 ms /    22 runs   (  157.91 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   10513.90 ms /   302 tokens\n",
      "Answering questions:  37%|███▋      | 116/315 [28:00<42:25, 12.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       4.79 ms /    14 runs   (    0.34 ms per token,  2924.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1875.42 ms /    68 tokens (   27.58 ms per token,    36.26 tokens per second)\n",
      "llama_print_timings:        eval time =    2051.70 ms /    13 runs   (  157.82 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =    3978.19 ms /    81 tokens\n",
      "Answering questions:  37%|███▋      | 117/315 [28:04<33:34, 10.17s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      46.19 ms /   134 runs   (    0.34 ms per token,  2901.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17497.22 ms /   752 tokens (   23.27 ms per token,    42.98 tokens per second)\n",
      "llama_print_timings:        eval time =   21459.78 ms /   133 runs   (  161.35 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =   39469.19 ms /   885 tokens\n",
      "Answering questions:  37%|███▋      | 118/315 [28:44<1:02:21, 18.99s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    24 runs   (    0.34 ms per token,  2916.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1557.97 ms /    56 tokens (   27.82 ms per token,    35.94 tokens per second)\n",
      "llama_print_timings:        eval time =    3634.34 ms /    23 runs   (  158.01 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =    5278.28 ms /    79 tokens\n",
      "Answering questions:  38%|███▊      | 119/315 [28:49<48:44, 14.92s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      19.29 ms /    56 runs   (    0.34 ms per token,  2903.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12324.37 ms /   563 tokens (   21.89 ms per token,    45.68 tokens per second)\n",
      "llama_print_timings:        eval time =    8804.89 ms /    55 runs   (  160.09 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   21338.39 ms /   618 tokens\n",
      "Answering questions:  38%|███▊      | 120/315 [29:11<54:55, 16.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    24 runs   (    0.34 ms per token,  2907.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15186.12 ms /   662 tokens (   22.94 ms per token,    43.59 tokens per second)\n",
      "llama_print_timings:        eval time =    3706.18 ms /    23 runs   (  161.14 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =   18985.06 ms /   685 tokens\n",
      "Answering questions:  38%|███▊      | 121/315 [29:30<56:45, 17.56s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      18.51 ms /    54 runs   (    0.34 ms per token,  2917.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6453.11 ms /   274 tokens (   23.55 ms per token,    42.46 tokens per second)\n",
      "llama_print_timings:        eval time =    8477.89 ms /    53 runs   (  159.96 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   15125.85 ms /   327 tokens\n",
      "Answering questions:  39%|███▊      | 122/315 [29:45<54:13, 16.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.64 ms /    31 runs   (    0.34 ms per token,  2914.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1891.18 ms /    68 tokens (   27.81 ms per token,    35.96 tokens per second)\n",
      "llama_print_timings:        eval time =    4709.99 ms /    30 runs   (  157.00 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:       total time =    6711.34 ms /    98 tokens\n",
      "Answering questions:  39%|███▉      | 123/315 [29:52<44:17, 13.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      30.10 ms /    88 runs   (    0.34 ms per token,  2923.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9337.91 ms /   411 tokens (   22.72 ms per token,    44.01 tokens per second)\n",
      "llama_print_timings:        eval time =   13837.99 ms /    87 runs   (  159.06 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   23502.46 ms /   498 tokens\n",
      "Answering questions:  39%|███▉      | 124/315 [30:15<53:22, 16.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.18 ms /    18 runs   (    0.34 ms per token,  2912.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14042.62 ms /   614 tokens (   22.87 ms per token,    43.72 tokens per second)\n",
      "llama_print_timings:        eval time =    2728.59 ms /    17 runs   (  160.51 ms per token,     6.23 tokens per second)\n",
      "llama_print_timings:       total time =   16841.26 ms /   631 tokens\n",
      "Answering questions:  40%|███▉      | 125/315 [30:32<53:15, 16.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    22 runs   (    0.34 ms per token,  2917.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8453.67 ms /   354 tokens (   23.88 ms per token,    41.88 tokens per second)\n",
      "llama_print_timings:        eval time =    3352.21 ms /    21 runs   (  159.63 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   11886.27 ms /   375 tokens\n",
      "Answering questions:  40%|████      | 126/315 [30:44<48:24, 15.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    27 runs   (    0.34 ms per token,  2912.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9378.74 ms /   432 tokens (   21.71 ms per token,    46.06 tokens per second)\n",
      "llama_print_timings:        eval time =    4134.35 ms /    26 runs   (  159.01 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   13612.82 ms /   458 tokens\n",
      "Answering questions:  40%|████      | 127/315 [30:58<46:39, 14.89s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.99 ms /    32 runs   (    0.34 ms per token,  2911.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10687.31 ms /   506 tokens (   21.12 ms per token,    47.35 tokens per second)\n",
      "llama_print_timings:        eval time =    4948.72 ms /    31 runs   (  159.64 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   15759.74 ms /   537 tokens\n",
      "Answering questions:  41%|████      | 128/315 [31:14<47:18, 15.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    22 runs   (    0.34 ms per token,  2938.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6431.73 ms /   272 tokens (   23.65 ms per token,    42.29 tokens per second)\n",
      "llama_print_timings:        eval time =    3349.26 ms /    21 runs   (  159.49 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =    9860.16 ms /   293 tokens\n",
      "Answering questions:  41%|████      | 129/315 [31:24<42:12, 13.61s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    19 runs   (    0.34 ms per token,  2915.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1799.22 ms /    66 tokens (   27.26 ms per token,    36.68 tokens per second)\n",
      "llama_print_timings:        eval time =    2787.07 ms /    18 runs   (  154.84 ms per token,     6.46 tokens per second)\n",
      "llama_print_timings:       total time =    4652.54 ms /    84 tokens\n",
      "Answering questions:  41%|████▏     | 130/315 [31:29<33:46, 10.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     3 runs   (    0.35 ms per token,  2887.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6596.87 ms /   278 tokens (   23.73 ms per token,    42.14 tokens per second)\n",
      "llama_print_timings:        eval time =     318.38 ms /     2 runs   (  159.19 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =    6925.50 ms /   280 tokens\n",
      "Answering questions:  42%|████▏     | 131/315 [31:36<30:00,  9.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.94 ms /    32 runs   (    0.34 ms per token,  2925.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6032.01 ms /   229 tokens (   26.34 ms per token,    37.96 tokens per second)\n",
      "llama_print_timings:        eval time =    4878.49 ms /    31 runs   (  157.37 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =   11025.40 ms /   260 tokens\n",
      "Answering questions:  42%|████▏     | 132/315 [31:47<31:06, 10.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.93 ms /    29 runs   (    0.34 ms per token,  2920.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4211.84 ms /   158 tokens (   26.66 ms per token,    37.51 tokens per second)\n",
      "llama_print_timings:        eval time =    4385.32 ms /    28 runs   (  156.62 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:       total time =    8700.39 ms /   186 tokens\n",
      "Answering questions:  42%|████▏     | 133/315 [31:56<29:42,  9.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    25 runs   (    0.35 ms per token,  2872.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11131.82 ms /   535 tokens (   20.81 ms per token,    48.06 tokens per second)\n",
      "llama_print_timings:        eval time =    3820.88 ms /    24 runs   (  159.20 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   15046.36 ms /   559 tokens\n",
      "Answering questions:  43%|████▎     | 134/315 [32:11<34:23, 11.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      25.82 ms /    70 runs   (    0.37 ms per token,  2711.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16897.40 ms /   742 tokens (   22.77 ms per token,    43.91 tokens per second)\n",
      "llama_print_timings:        eval time =    6194.09 ms /    69 runs   (   89.77 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =   23441.48 ms /   811 tokens\n",
      "Answering questions:  43%|████▎     | 135/315 [32:34<45:07, 15.04s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /     9 runs   (    0.34 ms per token,  2929.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9553.54 ms /   443 tokens (   21.57 ms per token,    46.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1302.38 ms /     8 runs   (  162.80 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   10890.74 ms /   451 tokens\n",
      "Answering questions:  43%|████▎     | 136/315 [32:45<41:17, 13.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      18.86 ms /    44 runs   (    0.43 ms per token,  2332.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5906.41 ms /   238 tokens (   24.82 ms per token,    40.30 tokens per second)\n",
      "llama_print_timings:        eval time =    3609.01 ms /    43 runs   (   83.93 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =    9762.61 ms /   281 tokens\n",
      "Answering questions:  43%|████▎     | 137/315 [32:55<37:34, 12.66s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /     8 runs   (    0.35 ms per token,  2896.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1503.26 ms /    57 tokens (   26.37 ms per token,    37.92 tokens per second)\n",
      "llama_print_timings:        eval time =     512.98 ms /     7 runs   (   73.28 ms per token,    13.65 tokens per second)\n",
      "llama_print_timings:       total time =    2049.26 ms /    64 tokens\n",
      "Answering questions:  44%|████▍     | 138/315 [32:58<28:12,  9.56s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    20 runs   (    0.35 ms per token,  2854.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6802.18 ms /   277 tokens (   24.56 ms per token,    40.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1510.17 ms /    19 runs   (   79.48 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    8397.95 ms /   296 tokens\n",
      "Answering questions:  44%|████▍     | 139/315 [33:06<27:06,  9.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      26.64 ms /    77 runs   (    0.35 ms per token,  2890.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16858.52 ms /   716 tokens (   23.55 ms per token,    42.47 tokens per second)\n",
      "llama_print_timings:        eval time =    8777.18 ms /    76 runs   (  115.49 ms per token,     8.66 tokens per second)\n",
      "llama_print_timings:       total time =   25965.60 ms /   792 tokens\n",
      "Answering questions:  44%|████▍     | 140/315 [33:32<41:40, 14.29s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.91 ms /    29 runs   (    0.34 ms per token,  2926.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7832.40 ms /   380 tokens (   20.61 ms per token,    48.52 tokens per second)\n",
      "llama_print_timings:        eval time =    2269.55 ms /    28 runs   (   81.06 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =   10214.72 ms /   408 tokens\n",
      "Answering questions:  45%|████▍     | 141/315 [33:43<38:03, 13.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      31.49 ms /    92 runs   (    0.34 ms per token,  2921.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11602.64 ms /   538 tokens (   21.57 ms per token,    46.37 tokens per second)\n",
      "llama_print_timings:        eval time =    7199.48 ms /    91 runs   (   79.12 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =   19167.91 ms /   629 tokens\n",
      "Answering questions:  45%|████▌     | 142/315 [34:02<43:09, 14.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.18 ms /    18 runs   (    0.34 ms per token,  2912.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14473.93 ms /   642 tokens (   22.55 ms per token,    44.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1365.37 ms /    17 runs   (   80.32 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =   15911.82 ms /   659 tokens\n",
      "Answering questions:  45%|████▌     | 143/315 [34:18<43:48, 15.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      22.55 ms /    66 runs   (    0.34 ms per token,  2926.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6497.45 ms /   249 tokens (   26.09 ms per token,    38.32 tokens per second)\n",
      "llama_print_timings:        eval time =    4932.02 ms /    65 runs   (   75.88 ms per token,    13.18 tokens per second)\n",
      "llama_print_timings:       total time =   11684.30 ms /   314 tokens\n",
      "Answering questions:  46%|████▌     | 144/315 [34:30<40:33, 14.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.60 ms /    28 runs   (    0.34 ms per token,  2917.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12611.85 ms /   569 tokens (   22.16 ms per token,    45.12 tokens per second)\n",
      "llama_print_timings:        eval time =    2127.47 ms /    27 runs   (   78.80 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =   14851.18 ms /   596 tokens\n",
      "Answering questions:  46%|████▌     | 145/315 [34:45<40:56, 14.45s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      15.03 ms /    44 runs   (    0.34 ms per token,  2928.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8973.20 ms /   403 tokens (   22.27 ms per token,    44.91 tokens per second)\n",
      "llama_print_timings:        eval time =    3278.14 ms /    43 runs   (   76.24 ms per token,    13.12 tokens per second)\n",
      "llama_print_timings:       total time =   12418.97 ms /   446 tokens\n",
      "Answering questions:  46%|████▋     | 146/315 [34:57<39:03, 13.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.62 ms /    34 runs   (    0.34 ms per token,  2926.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13428.13 ms /   597 tokens (   22.49 ms per token,    44.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2606.21 ms /    33 runs   (   78.98 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =   16184.93 ms /   630 tokens\n",
      "Answering questions:  47%|████▋     | 147/315 [35:14<40:51, 14.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.83 ms /    49 runs   (    0.34 ms per token,  2911.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9671.90 ms /   433 tokens (   22.34 ms per token,    44.77 tokens per second)\n",
      "llama_print_timings:        eval time =    3615.65 ms /    48 runs   (   75.33 ms per token,    13.28 tokens per second)\n",
      "llama_print_timings:       total time =   13496.10 ms /   481 tokens\n",
      "Answering questions:  47%|████▋     | 148/315 [35:27<39:47, 14.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.71 ms /    40 runs   (    0.34 ms per token,  2917.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12994.78 ms /   605 tokens (   21.48 ms per token,    46.56 tokens per second)\n",
      "llama_print_timings:        eval time =    3059.60 ms /    39 runs   (   78.45 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =   16212.75 ms /   644 tokens\n",
      "Answering questions:  47%|████▋     | 149/315 [35:43<41:13, 14.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    18 runs   (    0.48 ms per token,  2068.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6850.78 ms /   266 tokens (   25.75 ms per token,    38.83 tokens per second)\n",
      "llama_print_timings:        eval time =    3056.56 ms /    17 runs   (  179.80 ms per token,     5.56 tokens per second)\n",
      "llama_print_timings:       total time =   10032.58 ms /   283 tokens\n",
      "Answering questions:  48%|████▊     | 150/315 [35:54<37:03, 13.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    16 runs   (    0.35 ms per token,  2872.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3103.56 ms /   117 tokens (   26.53 ms per token,    37.70 tokens per second)\n",
      "llama_print_timings:        eval time =    2369.47 ms /    15 runs   (  157.96 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =    5536.81 ms /   132 tokens\n",
      "Answering questions:  48%|████▊     | 151/315 [35:59<30:26, 11.14s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /     8 runs   (    0.34 ms per token,  2918.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8479.59 ms /   386 tokens (   21.97 ms per token,    45.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.24 ms /     7 runs   (  163.61 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =    9659.06 ms /   393 tokens\n",
      "Answering questions:  48%|████▊     | 152/315 [36:09<29:08, 10.73s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.13 ms /    38 runs   (    0.35 ms per token,  2893.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13038.85 ms /   588 tokens (   22.17 ms per token,    45.10 tokens per second)\n",
      "llama_print_timings:        eval time =    2930.60 ms /    37 runs   (   79.21 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =   16138.09 ms /   625 tokens\n",
      "Answering questions:  49%|████▊     | 153/315 [36:25<33:30, 12.41s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    20 runs   (    0.35 ms per token,  2896.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9392.75 ms /   443 tokens (   21.20 ms per token,    47.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1489.05 ms /    19 runs   (   78.37 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =   10970.71 ms /   462 tokens\n",
      "Answering questions:  49%|████▉     | 154/315 [36:36<32:13, 12.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     6 runs   (    0.35 ms per token,  2880.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9350.42 ms /   427 tokens (   21.90 ms per token,    45.67 tokens per second)\n",
      "llama_print_timings:        eval time =     383.54 ms /     5 runs   (   76.71 ms per token,    13.04 tokens per second)\n",
      "llama_print_timings:       total time =    9757.78 ms /   432 tokens\n",
      "Answering questions:  49%|████▉     | 155/315 [36:46<30:17, 11.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.47 ms /    39 runs   (    0.35 ms per token,  2894.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4205.93 ms /   162 tokens (   25.96 ms per token,    38.52 tokens per second)\n",
      "llama_print_timings:        eval time =    2848.34 ms /    38 runs   (   74.96 ms per token,    13.34 tokens per second)\n",
      "llama_print_timings:       total time =    7219.15 ms /   200 tokens\n",
      "Answering questions:  50%|████▉     | 156/315 [36:54<27:02, 10.21s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      14.97 ms /    37 runs   (    0.40 ms per token,  2471.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9972.92 ms /   462 tokens (   21.59 ms per token,    46.33 tokens per second)\n",
      "llama_print_timings:        eval time =    6181.18 ms /    36 runs   (  171.70 ms per token,     5.82 tokens per second)\n",
      "llama_print_timings:       total time =   16345.22 ms /   498 tokens\n",
      "Answering questions:  50%|████▉     | 157/315 [37:10<31:48, 12.08s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      18.52 ms /    54 runs   (    0.34 ms per token,  2916.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19529.42 ms /   872 tokens (   22.40 ms per token,    44.65 tokens per second)\n",
      "llama_print_timings:        eval time =    9066.91 ms /    53 runs   (  171.07 ms per token,     5.85 tokens per second)\n",
      "llama_print_timings:       total time =   28811.07 ms /   925 tokens\n",
      "Answering questions:  50%|█████     | 158/315 [37:39<44:50, 17.14s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.30 ms /    33 runs   (    0.34 ms per token,  2920.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8673.41 ms /   420 tokens (   20.65 ms per token,    48.42 tokens per second)\n",
      "llama_print_timings:        eval time =    5276.51 ms /    32 runs   (  164.89 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =   14073.66 ms /   452 tokens\n",
      "Answering questions:  50%|█████     | 159/315 [37:53<42:15, 16.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.26 ms /    30 runs   (    0.34 ms per token,  2923.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3782.73 ms /   141 tokens (   26.83 ms per token,    37.27 tokens per second)\n",
      "llama_print_timings:        eval time =    4677.98 ms /    29 runs   (  161.31 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =    8570.48 ms /   170 tokens\n",
      "Answering questions:  51%|█████     | 160/315 [38:02<36:06, 13.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      15.69 ms /    46 runs   (    0.34 ms per token,  2931.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7173.02 ms /   292 tokens (   24.57 ms per token,    40.71 tokens per second)\n",
      "llama_print_timings:        eval time =    7358.56 ms /    45 runs   (  163.52 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   14700.55 ms /   337 tokens\n",
      "Answering questions:  51%|█████     | 161/315 [38:17<36:29, 14.22s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.56 ms /    31 runs   (    0.34 ms per token,  2935.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6029.99 ms /   237 tokens (   25.44 ms per token,    39.30 tokens per second)\n",
      "llama_print_timings:        eval time =    4865.63 ms /    30 runs   (  162.19 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:       total time =   11009.08 ms /   267 tokens\n",
      "Answering questions:  51%|█████▏    | 162/315 [38:28<33:55, 13.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.42 ms /    48 runs   (    0.34 ms per token,  2923.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8315.48 ms /   366 tokens (   22.72 ms per token,    44.01 tokens per second)\n",
      "llama_print_timings:        eval time =    7709.11 ms /    47 runs   (  164.02 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:       total time =   16201.76 ms /   413 tokens\n",
      "Answering questions:  52%|█████▏    | 163/315 [38:44<36:01, 14.22s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.66 ms /    18 runs   (    0.54 ms per token,  1862.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16799.70 ms /   720 tokens (   23.33 ms per token,    42.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1470.41 ms /    17 runs   (   86.49 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =   18400.06 ms /   737 tokens\n",
      "Answering questions:  52%|█████▏    | 164/315 [39:03<39:01, 15.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.67 ms /    48 runs   (    0.35 ms per token,  2879.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10801.25 ms /   512 tokens (   21.10 ms per token,    47.40 tokens per second)\n",
      "llama_print_timings:        eval time =    7860.54 ms /    48 runs   (  163.76 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   18864.17 ms /   560 tokens\n",
      "Answering questions:  52%|█████▏    | 165/315 [39:22<41:24, 16.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      15.21 ms /    36 runs   (    0.42 ms per token,  2367.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4233.45 ms /   161 tokens (   26.29 ms per token,    38.03 tokens per second)\n",
      "llama_print_timings:        eval time =    5568.15 ms /    35 runs   (  159.09 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =    9988.69 ms /   196 tokens\n",
      "Answering questions:  53%|█████▎    | 166/315 [39:32<36:21, 14.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      17.49 ms /    51 runs   (    0.34 ms per token,  2915.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10284.00 ms /   439 tokens (   23.43 ms per token,    42.69 tokens per second)\n",
      "llama_print_timings:        eval time =    8056.75 ms /    50 runs   (  161.14 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =   18533.84 ms /   489 tokens\n",
      "Answering questions:  53%|█████▎    | 167/315 [39:51<39:05, 15.85s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    20 runs   (    0.34 ms per token,  2903.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10746.02 ms /   500 tokens (   21.49 ms per token,    46.53 tokens per second)\n",
      "llama_print_timings:        eval time =    3068.97 ms /    19 runs   (  161.52 ms per token,     6.19 tokens per second)\n",
      "llama_print_timings:       total time =   13890.33 ms /   519 tokens\n",
      "Answering questions:  53%|█████▎    | 168/315 [40:05<37:27, 15.29s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.95 ms /    29 runs   (    0.34 ms per token,  2913.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9827.42 ms /   438 tokens (   22.44 ms per token,    44.57 tokens per second)\n",
      "llama_print_timings:        eval time =    4506.83 ms /    28 runs   (  160.96 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =   14445.16 ms /   466 tokens\n",
      "Answering questions:  54%|█████▎    | 169/315 [40:19<36:39, 15.06s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.25 ms /    38 runs   (    0.35 ms per token,  2869.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12540.61 ms /   579 tokens (   21.66 ms per token,    46.17 tokens per second)\n",
      "llama_print_timings:        eval time =    5856.60 ms /    37 runs   (  158.29 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:       total time =   18558.20 ms /   616 tokens\n",
      "Answering questions:  54%|█████▍    | 170/315 [40:38<39:01, 16.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      18.99 ms /    48 runs   (    0.40 ms per token,  2528.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8622.18 ms /   381 tokens (   22.63 ms per token,    44.19 tokens per second)\n",
      "llama_print_timings:        eval time =    7428.59 ms /    47 runs   (  158.06 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   16297.01 ms /   428 tokens\n",
      "Answering questions:  54%|█████▍    | 171/315 [40:54<38:56, 16.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /     3 runs   (    0.35 ms per token,  2835.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10281.64 ms /   501 tokens (   20.52 ms per token,    48.73 tokens per second)\n",
      "llama_print_timings:        eval time =     326.85 ms /     2 runs   (  163.42 ms per token,     6.12 tokens per second)\n",
      "llama_print_timings:       total time =   10620.97 ms /   503 tokens\n",
      "Answering questions:  55%|█████▍    | 172/315 [41:05<34:45, 14.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      23.42 ms /    67 runs   (    0.35 ms per token,  2860.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7597.83 ms /   349 tokens (   21.77 ms per token,    45.93 tokens per second)\n",
      "llama_print_timings:        eval time =   10338.67 ms /    66 runs   (  156.65 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:       total time =   18224.73 ms /   415 tokens\n",
      "Answering questions:  55%|█████▍    | 173/315 [41:23<37:12, 15.72s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.45 ms /    30 runs   (    0.42 ms per token,  2408.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11118.77 ms /   529 tokens (   21.02 ms per token,    47.58 tokens per second)\n",
      "llama_print_timings:        eval time =    4683.11 ms /    29 runs   (  161.49 ms per token,     6.19 tokens per second)\n",
      "llama_print_timings:       total time =   15931.24 ms /   558 tokens\n",
      "Answering questions:  55%|█████▌    | 174/315 [41:39<37:09, 15.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.10 ms /    38 runs   (    0.34 ms per token,  2901.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15595.06 ms /   661 tokens (   23.59 ms per token,    42.39 tokens per second)\n",
      "llama_print_timings:        eval time =    5876.03 ms /    37 runs   (  158.81 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:       total time =   21626.41 ms /   698 tokens\n",
      "Answering questions:  56%|█████▌    | 175/315 [42:01<41:01, 17.58s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /    10 runs   (    0.35 ms per token,  2872.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7277.67 ms /   316 tokens (   23.03 ms per token,    43.42 tokens per second)\n",
      "llama_print_timings:        eval time =     860.33 ms /     9 runs   (   95.59 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =    8192.18 ms /   325 tokens\n",
      "Answering questions:  56%|█████▌    | 176/315 [42:10<34:18, 14.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      18.83 ms /    55 runs   (    0.34 ms per token,  2921.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12306.93 ms /   563 tokens (   21.86 ms per token,    45.75 tokens per second)\n",
      "llama_print_timings:        eval time =    8506.78 ms /    54 runs   (  157.53 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =   21031.60 ms /   617 tokens\n",
      "Answering questions:  56%|█████▌    | 177/315 [42:31<38:26, 16.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /     8 runs   (    0.35 ms per token,  2886.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7543.61 ms /   324 tokens (   23.28 ms per token,    42.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1062.64 ms /     7 runs   (  151.81 ms per token,     6.59 tokens per second)\n",
      "llama_print_timings:       total time =    8642.32 ms /   331 tokens\n",
      "Answering questions:  57%|█████▋    | 178/315 [42:39<32:41, 14.32s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.42 ms /    38 runs   (    0.35 ms per token,  2832.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6309.06 ms /   275 tokens (   22.94 ms per token,    43.59 tokens per second)\n",
      "llama_print_timings:        eval time =    5821.18 ms /    37 runs   (  157.33 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   12275.54 ms /   312 tokens\n",
      "Answering questions:  57%|█████▋    | 179/315 [42:52<31:11, 13.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       5.14 ms /    15 runs   (    0.34 ms per token,  2918.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2482.88 ms /    93 tokens (   26.70 ms per token,    37.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2177.99 ms /    14 runs   (  155.57 ms per token,     6.43 tokens per second)\n",
      "llama_print_timings:       total time =    4720.85 ms /   107 tokens\n",
      "Answering questions:  57%|█████▋    | 180/315 [42:57<25:00, 11.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.84 ms /    22 runs   (    0.45 ms per token,  2235.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9022.97 ms /   392 tokens (   23.02 ms per token,    43.44 tokens per second)\n",
      "llama_print_timings:        eval time =    3256.70 ms /    21 runs   (  155.08 ms per token,     6.45 tokens per second)\n",
      "llama_print_timings:       total time =   12426.01 ms /   413 tokens\n",
      "Answering questions:  57%|█████▋    | 181/315 [43:09<25:46, 11.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    19 runs   (    0.50 ms per token,  2016.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8360.14 ms /   378 tokens (   22.12 ms per token,    45.21 tokens per second)\n",
      "llama_print_timings:        eval time =    2835.39 ms /    18 runs   (  157.52 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =   11300.31 ms /   396 tokens\n",
      "Answering questions:  58%|█████▊    | 182/315 [43:21<25:29, 11.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      58.73 ms /   164 runs   (    0.36 ms per token,  2792.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12701.05 ms /   551 tokens (   23.05 ms per token,    43.38 tokens per second)\n",
      "llama_print_timings:        eval time =   26291.48 ms /   163 runs   (  161.30 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =   39743.77 ms /   714 tokens\n",
      "Answering questions:  58%|█████▊    | 183/315 [44:01<44:00, 20.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.28 ms /    47 runs   (    0.35 ms per token,  2886.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8932.29 ms /   403 tokens (   22.16 ms per token,    45.12 tokens per second)\n",
      "llama_print_timings:        eval time =    4026.37 ms /    46 runs   (   87.53 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =   13154.78 ms /   449 tokens\n",
      "Answering questions:  58%|█████▊    | 184/315 [44:14<39:14, 17.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.90 ms /    29 runs   (    0.34 ms per token,  2930.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6706.66 ms /   282 tokens (   23.78 ms per token,    42.05 tokens per second)\n",
      "llama_print_timings:        eval time =    2278.36 ms /    28 runs   (   81.37 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    9104.59 ms /   310 tokens\n",
      "Answering questions:  59%|█████▊    | 185/315 [44:23<33:14, 15.34s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       5.98 ms /    17 runs   (    0.35 ms per token,  2844.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8329.88 ms /   363 tokens (   22.95 ms per token,    43.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1299.04 ms /    16 runs   (   81.19 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    9698.51 ms /   379 tokens\n",
      "Answering questions:  59%|█████▉    | 186/315 [44:33<29:24, 13.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /     6 runs   (    0.40 ms per token,  2526.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11633.40 ms /   551 tokens (   21.11 ms per token,    47.36 tokens per second)\n",
      "llama_print_timings:        eval time =     816.32 ms /     5 runs   (  163.26 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   12487.70 ms /   556 tokens\n",
      "Answering questions:  59%|█████▉    | 187/315 [44:46<28:31, 13.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      20.79 ms /    59 runs   (    0.35 ms per token,  2837.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8204.24 ms /   350 tokens (   23.44 ms per token,    42.66 tokens per second)\n",
      "llama_print_timings:        eval time =    9298.24 ms /    58 runs   (  160.31 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   17734.90 ms /   408 tokens\n",
      "Answering questions:  60%|█████▉    | 188/315 [45:03<31:08, 14.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.35 ms /    33 runs   (    0.34 ms per token,  2908.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11517.12 ms /   543 tokens (   21.21 ms per token,    47.15 tokens per second)\n",
      "llama_print_timings:        eval time =    5032.34 ms /    32 runs   (  157.26 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   16693.79 ms /   575 tokens\n",
      "Answering questions:  60%|██████    | 189/315 [45:20<32:11, 15.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    24 runs   (    0.34 ms per token,  2899.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8449.75 ms /   375 tokens (   22.53 ms per token,    44.38 tokens per second)\n",
      "llama_print_timings:        eval time =    3666.58 ms /    23 runs   (  159.42 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   12218.72 ms /   398 tokens\n",
      "Answering questions:  60%|██████    | 190/315 [45:32<30:03, 14.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      18.86 ms /    55 runs   (    0.34 ms per token,  2915.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9793.09 ms /   466 tokens (   21.02 ms per token,    47.58 tokens per second)\n",
      "llama_print_timings:        eval time =    8736.34 ms /    54 runs   (  161.78 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =   18739.06 ms /   520 tokens\n",
      "Answering questions:  61%|██████    | 191/315 [45:51<32:33, 15.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    23 runs   (    0.34 ms per token,  2926.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.31 ms /    42 tokens (   28.15 ms per token,    35.52 tokens per second)\n",
      "llama_print_timings:        eval time =    3447.28 ms /    22 runs   (  156.69 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:       total time =    4712.34 ms /    64 tokens\n",
      "Answering questions:  61%|██████    | 192/315 [45:56<25:36, 12.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    14 runs   (    0.34 ms per token,  2906.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8527.38 ms /   398 tokens (   21.43 ms per token,    46.67 tokens per second)\n",
      "llama_print_timings:        eval time =    2110.02 ms /    13 runs   (  162.31 ms per token,     6.16 tokens per second)\n",
      "llama_print_timings:       total time =   10688.45 ms /   411 tokens\n",
      "Answering questions:  61%|██████▏   | 193/315 [46:07<24:21, 11.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    27 runs   (    0.34 ms per token,  2905.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12912.32 ms /   581 tokens (   22.22 ms per token,    45.00 tokens per second)\n",
      "llama_print_timings:        eval time =    4192.10 ms /    26 runs   (  161.23 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =   17207.24 ms /   607 tokens\n",
      "Answering questions:  62%|██████▏   | 194/315 [46:24<27:22, 13.58s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      19.20 ms /    56 runs   (    0.34 ms per token,  2917.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9350.66 ms /   404 tokens (   23.15 ms per token,    43.21 tokens per second)\n",
      "llama_print_timings:        eval time =    8781.76 ms /    55 runs   (  159.67 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   18340.24 ms /   459 tokens\n",
      "Answering questions:  62%|██████▏   | 195/315 [46:43<30:03, 15.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.98 ms /    32 runs   (    0.34 ms per token,  2914.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1749.57 ms /    64 tokens (   27.34 ms per token,    36.58 tokens per second)\n",
      "llama_print_timings:        eval time =    4829.50 ms /    31 runs   (  155.79 ms per token,     6.42 tokens per second)\n",
      "llama_print_timings:       total time =    6695.22 ms /    95 tokens\n",
      "Answering questions:  62%|██████▏   | 196/315 [46:50<24:55, 12.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    22 runs   (    0.34 ms per token,  2927.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6721.30 ms /   272 tokens (   24.71 ms per token,    40.47 tokens per second)\n",
      "llama_print_timings:        eval time =    3360.16 ms /    21 runs   (  160.01 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   10161.25 ms /   293 tokens\n",
      "Answering questions:  63%|██████▎   | 197/315 [47:00<23:20, 11.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.87 ms /    25 runs   (    0.43 ms per token,  2300.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12096.00 ms /   547 tokens (   22.11 ms per token,    45.22 tokens per second)\n",
      "llama_print_timings:        eval time =    2154.53 ms /    24 runs   (   89.77 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =   14417.14 ms /   571 tokens\n",
      "Answering questions:  63%|██████▎   | 198/315 [47:14<24:41, 12.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    22 runs   (    0.34 ms per token,  2901.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11334.50 ms /   553 tokens (   20.50 ms per token,    48.79 tokens per second)\n",
      "llama_print_timings:        eval time =    3379.28 ms /    21 runs   (  160.92 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =   14801.35 ms /   574 tokens\n",
      "Answering questions:  63%|██████▎   | 199/315 [47:29<25:49, 13.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.08 ms /    31 runs   (    0.36 ms per token,  2798.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13029.01 ms /   571 tokens (   22.82 ms per token,    43.83 tokens per second)\n",
      "llama_print_timings:        eval time =    4816.96 ms /    30 runs   (  160.57 ms per token,     6.23 tokens per second)\n",
      "llama_print_timings:       total time =   17987.76 ms /   601 tokens\n",
      "Answering questions:  63%|██████▎   | 200/315 [47:47<28:22, 14.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.41 ms /    31 runs   (    0.43 ms per token,  2312.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16912.95 ms /   724 tokens (   23.36 ms per token,    42.81 tokens per second)\n",
      "llama_print_timings:        eval time =    4932.42 ms /    30 runs   (  164.41 ms per token,     6.08 tokens per second)\n",
      "llama_print_timings:       total time =   22017.33 ms /   754 tokens\n",
      "Answering questions:  64%|██████▍   | 201/315 [48:10<32:17, 17.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      15.96 ms /    46 runs   (    0.35 ms per token,  2882.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5869.09 ms /   234 tokens (   25.08 ms per token,    39.87 tokens per second)\n",
      "llama_print_timings:        eval time =    7166.95 ms /    45 runs   (  159.27 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   13238.65 ms /   279 tokens\n",
      "Answering questions:  64%|██████▍   | 202/315 [48:23<29:59, 15.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.32 ms /    32 runs   (    0.35 ms per token,  2827.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5973.51 ms /   248 tokens (   24.09 ms per token,    41.52 tokens per second)\n",
      "llama_print_timings:        eval time =    4957.87 ms /    31 runs   (  159.93 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   11050.47 ms /   279 tokens\n",
      "Answering questions:  64%|██████▍   | 203/315 [48:34<27:05, 14.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    20 runs   (    0.34 ms per token,  2951.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6394.46 ms /   283 tokens (   22.60 ms per token,    44.26 tokens per second)\n",
      "llama_print_timings:        eval time =    3039.21 ms /    19 runs   (  159.96 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =    9507.33 ms /   302 tokens\n",
      "Answering questions:  65%|██████▍   | 204/315 [48:44<24:07, 13.04s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.03 ms /    38 runs   (    0.34 ms per token,  2917.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7828.76 ms /   345 tokens (   22.69 ms per token,    44.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5840.05 ms /    37 runs   (  157.84 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:       total time =   13809.10 ms /   382 tokens\n",
      "Answering questions:  65%|██████▌   | 205/315 [48:58<24:22, 13.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.24 ms /    31 runs   (    0.43 ms per token,  2341.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11593.76 ms /   502 tokens (   23.10 ms per token,    43.30 tokens per second)\n",
      "llama_print_timings:        eval time =    2975.35 ms /    30 runs   (   99.18 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =   14748.54 ms /   532 tokens\n",
      "Answering questions:  65%|██████▌   | 206/315 [49:13<25:00, 13.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      20.75 ms /    58 runs   (    0.36 ms per token,  2794.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9661.14 ms /   427 tokens (   22.63 ms per token,    44.20 tokens per second)\n",
      "llama_print_timings:        eval time =    8021.35 ms /    57 runs   (  140.73 ms per token,     7.11 tokens per second)\n",
      "llama_print_timings:       total time =   17948.56 ms /   484 tokens\n",
      "Answering questions:  66%|██████▌   | 207/315 [49:31<27:05, 15.05s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.93 ms /    29 runs   (    0.34 ms per token,  2921.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13489.58 ms /   606 tokens (   22.26 ms per token,    44.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4494.35 ms /    28 runs   (  160.51 ms per token,     6.23 tokens per second)\n",
      "llama_print_timings:       total time =   18105.64 ms /   634 tokens\n",
      "Answering questions:  66%|██████▌   | 208/315 [49:49<28:32, 16.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.85 ms /    49 runs   (    0.34 ms per token,  2907.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3924.90 ms /   143 tokens (   27.45 ms per token,    36.43 tokens per second)\n",
      "llama_print_timings:        eval time =    7606.99 ms /    48 runs   (  158.48 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:       total time =   11725.26 ms /   191 tokens\n",
      "Answering questions:  66%|██████▋   | 209/315 [50:01<26:07, 14.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.75 ms /    44 runs   (    0.38 ms per token,  2626.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.17 ms /    41 tokens (   28.13 ms per token,    35.55 tokens per second)\n",
      "llama_print_timings:        eval time =    6764.59 ms /    43 runs   (  157.32 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =    8097.32 ms /    84 tokens\n",
      "Answering questions:  67%|██████▋   | 210/315 [50:09<22:26, 12.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      38.69 ms /   113 runs   (    0.34 ms per token,  2920.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11074.56 ms /   522 tokens (   21.22 ms per token,    47.14 tokens per second)\n",
      "llama_print_timings:        eval time =   17874.79 ms /   112 runs   (  159.60 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =   29388.74 ms /   634 tokens\n",
      "Answering questions:  67%|██████▋   | 211/315 [50:38<30:53, 17.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      23.48 ms /    65 runs   (    0.36 ms per token,  2768.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13366.25 ms /   589 tokens (   22.69 ms per token,    44.07 tokens per second)\n",
      "llama_print_timings:        eval time =    9993.95 ms /    64 runs   (  156.16 ms per token,     6.40 tokens per second)\n",
      "llama_print_timings:       total time =   23640.54 ms /   653 tokens\n",
      "Answering questions:  67%|██████▋   | 212/315 [51:02<33:46, 19.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      21.02 ms /    61 runs   (    0.34 ms per token,  2902.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4274.65 ms /   164 tokens (   26.06 ms per token,    38.37 tokens per second)\n",
      "llama_print_timings:        eval time =    9298.74 ms /    60 runs   (  154.98 ms per token,     6.45 tokens per second)\n",
      "llama_print_timings:       total time =   13832.76 ms /   224 tokens\n",
      "Answering questions:  68%|██████▊   | 213/315 [51:16<30:31, 17.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.71 ms /    40 runs   (    0.34 ms per token,  2916.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10077.73 ms /   461 tokens (   21.86 ms per token,    45.74 tokens per second)\n",
      "llama_print_timings:        eval time =    5932.15 ms /    39 runs   (  152.11 ms per token,     6.57 tokens per second)\n",
      "llama_print_timings:       total time =   16163.60 ms /   500 tokens\n",
      "Answering questions:  68%|██████▊   | 214/315 [51:33<29:23, 17.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    22 runs   (    0.34 ms per token,  2929.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6871.18 ms /   272 tokens (   25.26 ms per token,    39.59 tokens per second)\n",
      "llama_print_timings:        eval time =    3333.22 ms /    21 runs   (  158.72 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:       total time =   10291.20 ms /   293 tokens\n",
      "Answering questions:  68%|██████▊   | 215/315 [51:43<25:34, 15.34s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.62 ms /    31 runs   (    0.34 ms per token,  2920.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14420.72 ms /   634 tokens (   22.75 ms per token,    43.96 tokens per second)\n",
      "llama_print_timings:        eval time =    4866.18 ms /    30 runs   (  162.21 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:       total time =   19411.35 ms /   664 tokens\n",
      "Answering questions:  69%|██████▊   | 216/315 [52:03<27:24, 16.61s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      14.09 ms /    41 runs   (    0.34 ms per token,  2910.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8963.40 ms /   427 tokens (   20.99 ms per token,    47.64 tokens per second)\n",
      "llama_print_timings:        eval time =    6347.64 ms /    40 runs   (  158.69 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:       total time =   15467.23 ms /   467 tokens\n",
      "Answering questions:  69%|██████▉   | 217/315 [52:19<26:44, 16.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      17.83 ms /    49 runs   (    0.36 ms per token,  2747.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11307.01 ms /   498 tokens (   22.70 ms per token,    44.04 tokens per second)\n",
      "llama_print_timings:        eval time =    7679.38 ms /    48 runs   (  159.99 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   19173.63 ms /   546 tokens\n",
      "Answering questions:  69%|██████▉   | 218/315 [52:38<27:52, 17.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    22 runs   (    0.34 ms per token,  2923.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6095.97 ms /   253 tokens (   24.09 ms per token,    41.50 tokens per second)\n",
      "llama_print_timings:        eval time =    3373.64 ms /    21 runs   (  160.65 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:       total time =    9549.70 ms /   274 tokens\n",
      "Answering questions:  70%|██████▉   | 219/315 [52:48<24:01, 15.02s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    21 runs   (    0.34 ms per token,  2932.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.07 ms /    42 tokens (   28.26 ms per token,    35.38 tokens per second)\n",
      "llama_print_timings:        eval time =    3115.01 ms /    20 runs   (  155.75 ms per token,     6.42 tokens per second)\n",
      "llama_print_timings:       total time =    4377.60 ms /    62 tokens\n",
      "Answering questions:  70%|██████▉   | 220/315 [52:52<18:46, 11.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      21.55 ms /    63 runs   (    0.34 ms per token,  2924.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10098.05 ms /   472 tokens (   21.39 ms per token,    46.74 tokens per second)\n",
      "llama_print_timings:        eval time =    9930.69 ms /    62 runs   (  160.17 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   20263.62 ms /   534 tokens\n",
      "Answering questions:  70%|███████   | 221/315 [53:12<22:34, 14.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    22 runs   (    0.34 ms per token,  2934.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6786.56 ms /   278 tokens (   24.41 ms per token,    40.96 tokens per second)\n",
      "llama_print_timings:        eval time =    3365.49 ms /    21 runs   (  160.26 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   10233.12 ms /   299 tokens\n",
      "Answering questions:  70%|███████   | 222/315 [53:23<20:25, 13.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.71 ms /    37 runs   (    0.34 ms per token,  2912.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2671.32 ms /    97 tokens (   27.54 ms per token,    36.31 tokens per second)\n",
      "llama_print_timings:        eval time =    5665.97 ms /    36 runs   (  157.39 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =    8471.21 ms /   133 tokens\n",
      "Answering questions:  71%|███████   | 223/315 [53:31<18:08, 11.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     6 runs   (    0.34 ms per token,  2899.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7762.97 ms /   344 tokens (   22.57 ms per token,    44.31 tokens per second)\n",
      "llama_print_timings:        eval time =     805.88 ms /     5 runs   (  161.18 ms per token,     6.20 tokens per second)\n",
      "llama_print_timings:       total time =    8591.35 ms /   349 tokens\n",
      "Answering questions:  71%|███████   | 224/315 [53:40<16:31, 10.89s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.94 ms /    29 runs   (    0.34 ms per token,  2916.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9117.85 ms /   407 tokens (   22.40 ms per token,    44.64 tokens per second)\n",
      "llama_print_timings:        eval time =    4477.97 ms /    28 runs   (  159.93 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   13703.45 ms /   435 tokens\n",
      "Answering questions:  71%|███████▏  | 225/315 [53:54<17:38, 11.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.40 ms /    33 runs   (    0.35 ms per token,  2894.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10238.92 ms /   488 tokens (   20.98 ms per token,    47.66 tokens per second)\n",
      "llama_print_timings:        eval time =    5075.69 ms /    32 runs   (  158.62 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:       total time =   15458.17 ms /   520 tokens\n",
      "Answering questions:  72%|███████▏  | 226/315 [54:09<19:07, 12.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.47 ms /    39 runs   (    0.35 ms per token,  2894.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6534.25 ms /   275 tokens (   23.76 ms per token,    42.09 tokens per second)\n",
      "llama_print_timings:        eval time =    4337.95 ms /    38 runs   (  114.16 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =   11045.01 ms /   313 tokens\n",
      "Answering questions:  72%|███████▏  | 227/315 [54:21<18:08, 12.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      22.96 ms /    67 runs   (    0.34 ms per token,  2918.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8223.51 ms /   371 tokens (   22.17 ms per token,    45.11 tokens per second)\n",
      "llama_print_timings:        eval time =   10564.78 ms /    66 runs   (  160.07 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   19046.52 ms /   437 tokens\n",
      "Answering questions:  72%|███████▏  | 228/315 [54:40<20:53, 14.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.48 ms /    24 runs   (    0.40 ms per token,  2531.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10924.26 ms /   495 tokens (   22.07 ms per token,    45.31 tokens per second)\n",
      "llama_print_timings:        eval time =    2524.38 ms /    23 runs   (  109.76 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =   13596.68 ms /   518 tokens\n",
      "Answering questions:  73%|███████▎  | 229/315 [54:53<20:20, 14.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      24.52 ms /    66 runs   (    0.37 ms per token,  2691.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13603.09 ms /   610 tokens (   22.30 ms per token,    44.84 tokens per second)\n",
      "llama_print_timings:        eval time =    5555.38 ms /    65 runs   (   85.47 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:       total time =   19482.70 ms /   675 tokens\n",
      "Answering questions:  73%|███████▎  | 230/315 [55:13<22:25, 15.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    34 runs   (    0.35 ms per token,  2883.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.77 ms /    57 tokens (   26.59 ms per token,    37.60 tokens per second)\n",
      "llama_print_timings:        eval time =    2418.71 ms /    33 runs   (   73.29 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:       total time =    4078.39 ms /    90 tokens\n",
      "Answering questions:  73%|███████▎  | 231/315 [55:17<17:15, 12.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      31.13 ms /    90 runs   (    0.35 ms per token,  2891.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6002.50 ms /   263 tokens (   22.82 ms per token,    43.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12227.09 ms /    89 runs   (  137.38 ms per token,     7.28 tokens per second)\n",
      "llama_print_timings:       total time =   18612.47 ms /   352 tokens\n",
      "Answering questions:  74%|███████▎  | 232/315 [55:36<19:42, 14.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.95 ms /    49 runs   (    0.35 ms per token,  2891.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10848.80 ms /   512 tokens (   21.19 ms per token,    47.19 tokens per second)\n",
      "llama_print_timings:        eval time =    4079.17 ms /    49 runs   (   83.25 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =   15126.68 ms /   561 tokens\n",
      "Answering questions:  74%|███████▍  | 233/315 [55:51<19:52, 14.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /     8 runs   (    0.34 ms per token,  2943.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2292.09 ms /    83 tokens (   27.62 ms per token,    36.21 tokens per second)\n",
      "llama_print_timings:        eval time =     522.73 ms /     7 runs   (   74.68 ms per token,    13.39 tokens per second)\n",
      "llama_print_timings:       total time =    2848.39 ms /    90 tokens\n",
      "Answering questions:  74%|███████▍  | 234/315 [55:54<14:57, 11.07s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.23 ms /    33 runs   (    0.34 ms per token,  2939.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6231.65 ms /   254 tokens (   24.53 ms per token,    40.76 tokens per second)\n",
      "llama_print_timings:        eval time =    2576.28 ms /    32 runs   (   80.51 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    8935.57 ms /   286 tokens\n",
      "Answering questions:  75%|███████▍  | 235/315 [56:03<14:01, 10.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /     4 runs   (    0.35 ms per token,  2877.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15439.08 ms /   685 tokens (   22.54 ms per token,    44.37 tokens per second)\n",
      "llama_print_timings:        eval time =     261.48 ms /     3 runs   (   87.16 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =   15719.86 ms /   688 tokens\n",
      "Answering questions:  75%|███████▍  | 236/315 [56:19<15:56, 12.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       5.80 ms /    17 runs   (    0.34 ms per token,  2930.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17144.17 ms /   747 tokens (   22.95 ms per token,    43.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1337.63 ms /    16 runs   (   83.60 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =   18553.63 ms /   763 tokens\n",
      "Answering questions:  75%|███████▌  | 237/315 [56:38<18:17, 14.07s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    18 runs   (    0.34 ms per token,  2939.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17227.26 ms /   783 tokens (   22.00 ms per token,    45.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1420.46 ms /    17 runs   (   83.56 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =   18721.06 ms /   800 tokens\n",
      "Answering questions:  76%|███████▌  | 238/315 [56:57<19:53, 15.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       5.10 ms /    15 runs   (    0.34 ms per token,  2943.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2169.04 ms /    80 tokens (   27.11 ms per token,    36.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1047.37 ms /    14 runs   (   74.81 ms per token,    13.37 tokens per second)\n",
      "llama_print_timings:       total time =    3272.63 ms /    94 tokens\n",
      "Answering questions:  76%|███████▌  | 239/315 [57:00<15:02, 11.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      82.71 ms /   242 runs   (    0.34 ms per token,  2925.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10464.17 ms /   504 tokens (   20.76 ms per token,    48.16 tokens per second)\n",
      "llama_print_timings:        eval time =   18827.97 ms /   241 runs   (   78.12 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =   30273.47 ms /   745 tokens\n",
      "Answering questions:  76%|███████▌  | 240/315 [57:31<21:47, 17.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      14.02 ms /    41 runs   (    0.34 ms per token,  2924.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9062.55 ms /   385 tokens (   23.54 ms per token,    42.48 tokens per second)\n",
      "llama_print_timings:        eval time =    3083.63 ms /    40 runs   (   77.09 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:       total time =   12304.20 ms /   425 tokens\n",
      "Answering questions:  77%|███████▋  | 241/315 [57:43<19:38, 15.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /     8 runs   (    0.34 ms per token,  2930.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5670.23 ms /   210 tokens (   27.00 ms per token,    37.04 tokens per second)\n",
      "llama_print_timings:        eval time =     528.72 ms /     7 runs   (   75.53 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:       total time =    6228.56 ms /   217 tokens\n",
      "Answering questions:  77%|███████▋  | 242/315 [57:49<15:53, 13.05s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    12 runs   (    0.34 ms per token,  2913.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15460.91 ms /   679 tokens (   22.77 ms per token,    43.92 tokens per second)\n",
      "llama_print_timings:        eval time =     878.77 ms /    11 runs   (   79.89 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =   16388.68 ms /   690 tokens\n",
      "Answering questions:  77%|███████▋  | 243/315 [58:06<16:55, 14.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    17 runs   (    0.42 ms per token,  2397.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10722.05 ms /   499 tokens (   21.49 ms per token,    46.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1422.11 ms /    16 runs   (   88.88 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =   12231.87 ms /   515 tokens\n",
      "Answering questions:  77%|███████▋  | 244/315 [58:18<16:03, 13.58s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    23 runs   (    0.37 ms per token,  2713.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15449.00 ms /   654 tokens (   23.62 ms per token,    42.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1787.00 ms /    22 runs   (   81.23 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =   17333.91 ms /   676 tokens\n",
      "Answering questions:  78%|███████▊  | 245/315 [58:36<17:11, 14.74s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.89 ms /    28 runs   (    0.35 ms per token,  2831.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2031.75 ms /    74 tokens (   27.46 ms per token,    36.42 tokens per second)\n",
      "llama_print_timings:        eval time =    2002.91 ms /    27 runs   (   74.18 ms per token,    13.48 tokens per second)\n",
      "llama_print_timings:       total time =    4150.24 ms /   101 tokens\n",
      "Answering questions:  78%|███████▊  | 246/315 [58:40<13:19, 11.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    25 runs   (    0.35 ms per token,  2879.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8898.75 ms /   405 tokens (   21.97 ms per token,    45.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1856.15 ms /    24 runs   (   77.34 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:       total time =   10852.74 ms /   429 tokens\n",
      "Answering questions:  78%|███████▊  | 247/315 [58:51<12:55, 11.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    18 runs   (    0.34 ms per token,  2927.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19180.25 ms /   830 tokens (   23.11 ms per token,    43.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1393.16 ms /    17 runs   (   81.95 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =   20654.16 ms /   847 tokens\n",
      "Answering questions:  79%|███████▊  | 248/315 [59:12<15:53, 14.22s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.37 ms /    39 runs   (    0.34 ms per token,  2916.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11021.05 ms /   523 tokens (   21.07 ms per token,    47.45 tokens per second)\n",
      "llama_print_timings:        eval time =    3016.95 ms /    38 runs   (   79.39 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =   14191.56 ms /   561 tokens\n",
      "Answering questions:  79%|███████▉  | 249/315 [59:26<15:40, 14.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.99 ms /    35 runs   (    0.34 ms per token,  2920.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9377.50 ms /   441 tokens (   21.26 ms per token,    47.03 tokens per second)\n",
      "llama_print_timings:        eval time =    2578.52 ms /    34 runs   (   75.84 ms per token,    13.19 tokens per second)\n",
      "llama_print_timings:       total time =   12109.91 ms /   475 tokens\n",
      "Answering questions:  79%|███████▉  | 250/315 [59:38<14:46, 13.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.66 ms /    18 runs   (    0.54 ms per token,  1862.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10346.13 ms /   500 tokens (   20.69 ms per token,    48.33 tokens per second)\n",
      "llama_print_timings:        eval time =    2208.78 ms /    17 runs   (  129.93 ms per token,     7.70 tokens per second)\n",
      "llama_print_timings:       total time =   12680.24 ms /   517 tokens\n",
      "Answering questions:  80%|███████▉  | 251/315 [59:51<14:16, 13.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /     7 runs   (    0.34 ms per token,  2923.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4649.66 ms /   172 tokens (   27.03 ms per token,    36.99 tokens per second)\n",
      "llama_print_timings:        eval time =     457.95 ms /     6 runs   (   76.33 ms per token,    13.10 tokens per second)\n",
      "llama_print_timings:       total time =    5134.38 ms /   178 tokens\n",
      "Answering questions:  80%|████████  | 252/315 [59:56<11:31, 10.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.32 ms /    33 runs   (    0.34 ms per token,  2914.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10093.00 ms /   480 tokens (   21.03 ms per token,    47.56 tokens per second)\n",
      "llama_print_timings:        eval time =    2534.61 ms /    32 runs   (   79.21 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =   12757.55 ms /   512 tokens\n",
      "Answering questions:  80%|████████  | 253/315 [1:00:09<11:55, 11.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.05 ms /    35 runs   (    0.34 ms per token,  2905.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8313.93 ms /   397 tokens (   20.94 ms per token,    47.75 tokens per second)\n",
      "llama_print_timings:        eval time =    2678.82 ms /    34 runs   (   78.79 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =   11128.93 ms /   431 tokens\n",
      "Answering questions:  81%|████████  | 254/315 [1:00:20<11:38, 11.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.26 ms /    23 runs   (    0.40 ms per token,  2484.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16317.01 ms /   736 tokens (   22.17 ms per token,    45.11 tokens per second)\n",
      "llama_print_timings:        eval time =    3822.79 ms /    22 runs   (  173.76 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =   20279.46 ms /   758 tokens\n",
      "Answering questions:  81%|████████  | 255/315 [1:00:41<14:09, 14.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    34 runs   (    0.35 ms per token,  2869.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11613.96 ms /   536 tokens (   21.67 ms per token,    46.15 tokens per second)\n",
      "llama_print_timings:        eval time =    5663.63 ms /    33 runs   (  171.63 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:       total time =   17431.24 ms /   569 tokens\n",
      "Answering questions:  81%|████████▏ | 256/315 [1:00:58<14:55, 15.17s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.03 ms /    38 runs   (    0.34 ms per token,  2915.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13715.98 ms /   619 tokens (   22.16 ms per token,    45.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5933.51 ms /    37 runs   (  160.37 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   19819.93 ms /   656 tokens\n",
      "Answering questions:  82%|████████▏ | 257/315 [1:01:18<16:02, 16.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.90 ms /    29 runs   (    0.34 ms per token,  2929.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2610.66 ms /    98 tokens (   26.64 ms per token,    37.54 tokens per second)\n",
      "llama_print_timings:        eval time =    4623.93 ms /    28 runs   (  165.14 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =    7347.88 ms /   126 tokens\n",
      "Answering questions:  82%|████████▏ | 258/315 [1:01:26<13:10, 13.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      23.63 ms /    68 runs   (    0.35 ms per token,  2878.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6768.60 ms /   272 tokens (   24.88 ms per token,    40.19 tokens per second)\n",
      "llama_print_timings:        eval time =   10995.47 ms /    67 runs   (  164.11 ms per token,     6.09 tokens per second)\n",
      "llama_print_timings:       total time =   18027.02 ms /   339 tokens\n",
      "Answering questions:  82%|████████▏ | 259/315 [1:01:44<14:07, 15.14s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      46.24 ms /   135 runs   (    0.34 ms per token,  2919.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12478.80 ms /   557 tokens (   22.40 ms per token,    44.64 tokens per second)\n",
      "llama_print_timings:        eval time =   21681.16 ms /   134 runs   (  161.80 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =   34686.95 ms /   691 tokens\n",
      "Answering questions:  83%|████████▎ | 260/315 [1:02:19<19:16, 21.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    21 runs   (    0.34 ms per token,  2917.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2104.55 ms /    77 tokens (   27.33 ms per token,    36.59 tokens per second)\n",
      "llama_print_timings:        eval time =    3126.13 ms /    20 runs   (  156.31 ms per token,     6.40 tokens per second)\n",
      "llama_print_timings:       total time =    5306.63 ms /    97 tokens\n",
      "Answering questions:  83%|████████▎ | 261/315 [1:02:24<14:43, 16.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.21 ms /    25 runs   (    0.45 ms per token,  2230.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10288.19 ms /   492 tokens (   20.91 ms per token,    47.82 tokens per second)\n",
      "llama_print_timings:        eval time =    3558.27 ms /    24 runs   (  148.26 ms per token,     6.74 tokens per second)\n",
      "llama_print_timings:       total time =   13996.78 ms /   516 tokens\n",
      "Answering questions:  83%|████████▎ | 262/315 [1:02:38<13:50, 15.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.76 ms /    28 runs   (    0.35 ms per token,  2868.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14981.06 ms /   663 tokens (   22.60 ms per token,    44.26 tokens per second)\n",
      "llama_print_timings:        eval time =    4847.45 ms /    27 runs   (  179.54 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =   19962.59 ms /   690 tokens\n",
      "Answering questions:  83%|████████▎ | 263/315 [1:02:58<14:44, 17.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    33 runs   (    0.37 ms per token,  2695.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10790.15 ms /   502 tokens (   21.49 ms per token,    46.52 tokens per second)\n",
      "llama_print_timings:        eval time =    2662.58 ms /    32 runs   (   83.21 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =   13620.52 ms /   534 tokens\n",
      "Answering questions:  84%|████████▍ | 264/315 [1:03:12<13:37, 16.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      42.73 ms /   124 runs   (    0.34 ms per token,  2901.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8513.43 ms /   406 tokens (   20.97 ms per token,    47.69 tokens per second)\n",
      "llama_print_timings:        eval time =    9437.29 ms /   123 runs   (   76.73 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:       total time =   18474.12 ms /   529 tokens\n",
      "Answering questions:  84%|████████▍ | 265/315 [1:03:31<13:59, 16.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    15 runs   (    0.34 ms per token,  2938.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4205.94 ms /   162 tokens (   25.96 ms per token,    38.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1068.16 ms /    14 runs   (   76.30 ms per token,    13.11 tokens per second)\n",
      "llama_print_timings:       total time =    5337.42 ms /   176 tokens\n",
      "Answering questions:  84%|████████▍ | 266/315 [1:03:36<10:56, 13.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /     7 runs   (    0.34 ms per token,  2946.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1909.44 ms /    72 tokens (   26.52 ms per token,    37.71 tokens per second)\n",
      "llama_print_timings:        eval time =     444.30 ms /     6 runs   (   74.05 ms per token,    13.50 tokens per second)\n",
      "llama_print_timings:       total time =    2384.89 ms /    78 tokens\n",
      "Answering questions:  85%|████████▍ | 267/315 [1:03:39<08:05, 10.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.24 ms /    27 runs   (    0.34 ms per token,  2923.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6897.38 ms /   292 tokens (   23.62 ms per token,    42.33 tokens per second)\n",
      "llama_print_timings:        eval time =    2072.85 ms /    26 runs   (   79.72 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =    9076.34 ms /   318 tokens\n",
      "Answering questions:  85%|████████▌ | 268/315 [1:03:48<07:43,  9.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.95 ms /    32 runs   (    0.34 ms per token,  2923.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10629.86 ms /   511 tokens (   20.80 ms per token,    48.07 tokens per second)\n",
      "llama_print_timings:        eval time =    2505.32 ms /    31 runs   (   80.82 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =   13261.72 ms /   542 tokens\n",
      "Answering questions:  85%|████████▌ | 269/315 [1:04:01<08:21, 10.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /     4 runs   (    0.34 ms per token,  2952.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4239.13 ms /   155 tokens (   27.35 ms per token,    36.56 tokens per second)\n",
      "llama_print_timings:        eval time =     235.04 ms /     3 runs   (   78.35 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    4489.37 ms /   158 tokens\n",
      "Answering questions:  86%|████████▌ | 270/315 [1:04:06<06:45,  9.02s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.00 ms /    29 runs   (    0.34 ms per token,  2899.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9677.84 ms /   445 tokens (   21.75 ms per token,    45.98 tokens per second)\n",
      "llama_print_timings:        eval time =    2228.24 ms /    28 runs   (   79.58 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =   12028.34 ms /   473 tokens\n",
      "Answering questions:  86%|████████▌ | 271/315 [1:04:18<07:17,  9.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    19 runs   (    0.43 ms per token,  2343.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11364.91 ms /   522 tokens (   21.77 ms per token,    45.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1787.87 ms /    18 runs   (   99.33 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =   13268.27 ms /   540 tokens\n",
      "Answering questions:  86%|████████▋ | 272/315 [1:04:31<07:52, 10.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.68 ms /    40 runs   (    0.34 ms per token,  2924.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9071.18 ms /   400 tokens (   22.68 ms per token,    44.10 tokens per second)\n",
      "llama_print_timings:        eval time =    3050.17 ms /    39 runs   (   78.21 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =   12277.89 ms /   439 tokens\n",
      "Answering questions:  87%|████████▋ | 273/315 [1:04:44<07:58, 11.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.21 ms /    15 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10201.53 ms /   439 tokens (   23.24 ms per token,    43.03 tokens per second)\n",
      "llama_print_timings:        eval time =    2357.47 ms /    14 runs   (  168.39 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   12636.88 ms /   453 tokens\n",
      "Answering questions:  87%|████████▋ | 274/315 [1:04:57<08:04, 11.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.15 ms /    29 runs   (    0.35 ms per token,  2856.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17407.41 ms /   774 tokens (   22.49 ms per token,    44.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2344.05 ms /    28 runs   (   83.72 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =   19894.93 ms /   802 tokens\n",
      "Answering questions:  87%|████████▋ | 275/315 [1:05:17<09:30, 14.27s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    23 runs   (    0.35 ms per token,  2876.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2351.63 ms /    89 tokens (   26.42 ms per token,    37.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1607.83 ms /    22 runs   (   73.08 ms per token,    13.68 tokens per second)\n",
      "llama_print_timings:       total time =    4057.48 ms /   111 tokens\n",
      "Answering questions:  88%|████████▊ | 276/315 [1:05:21<07:18, 11.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    17 runs   (    0.42 ms per token,  2406.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9796.04 ms /   456 tokens (   21.48 ms per token,    46.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1268.39 ms /    16 runs   (   79.27 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =   11156.08 ms /   472 tokens\n",
      "Answering questions:  88%|████████▊ | 277/315 [1:05:32<07:07, 11.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.30 ms /    33 runs   (    0.34 ms per token,  2919.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11552.38 ms /   540 tokens (   21.39 ms per token,    46.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2482.90 ms /    32 runs   (   77.59 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =   14170.58 ms /   572 tokens\n",
      "Answering questions:  88%|████████▊ | 278/315 [1:05:46<07:30, 12.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /     8 runs   (    0.35 ms per token,  2895.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.89 ms /    29 tokens (   26.55 ms per token,    37.67 tokens per second)\n",
      "llama_print_timings:        eval time =     495.19 ms /     7 runs   (   70.74 ms per token,    14.14 tokens per second)\n",
      "llama_print_timings:       total time =    1297.51 ms /    36 tokens\n",
      "Answering questions:  89%|████████▊ | 279/315 [1:05:48<05:22,  8.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    22 runs   (    0.38 ms per token,  2666.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12203.26 ms /   529 tokens (   23.07 ms per token,    43.35 tokens per second)\n",
      "llama_print_timings:        eval time =    3657.87 ms /    21 runs   (  174.18 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   15979.08 ms /   550 tokens\n",
      "Answering questions:  89%|████████▉ | 280/315 [1:06:04<06:28, 11.09s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.72 ms /    48 runs   (    0.35 ms per token,  2870.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18190.92 ms /   793 tokens (   22.94 ms per token,    43.59 tokens per second)\n",
      "llama_print_timings:        eval time =    3904.61 ms /    47 runs   (   83.08 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =   22345.86 ms /   840 tokens\n",
      "Answering questions:  89%|████████▉ | 281/315 [1:06:26<08:13, 14.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.31 ms /    39 runs   (    0.34 ms per token,  2929.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18539.72 ms /   852 tokens (   21.76 ms per token,    45.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6468.76 ms /    38 runs   (  170.23 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =   25182.42 ms /   890 tokens\n",
      "Answering questions:  90%|████████▉ | 282/315 [1:06:52<09:48, 17.83s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.72 ms /    30 runs   (    0.36 ms per token,  2799.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11994.50 ms /   550 tokens (   21.81 ms per token,    45.85 tokens per second)\n",
      "llama_print_timings:        eval time =    3232.98 ms /    29 runs   (  111.48 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =   15379.87 ms /   579 tokens\n",
      "Answering questions:  90%|████████▉ | 283/315 [1:07:07<09:08, 17.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    18 runs   (    0.34 ms per token,  2919.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10936.86 ms /   497 tokens (   22.01 ms per token,    45.44 tokens per second)\n",
      "llama_print_timings:        eval time =    2924.28 ms /    17 runs   (  172.02 ms per token,     5.81 tokens per second)\n",
      "llama_print_timings:       total time =   13943.60 ms /   514 tokens\n",
      "Answering questions:  90%|█████████ | 284/315 [1:07:22<08:22, 16.22s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      13.38 ms /    39 runs   (    0.34 ms per token,  2914.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12507.36 ms /   572 tokens (   21.87 ms per token,    45.73 tokens per second)\n",
      "llama_print_timings:        eval time =    6358.68 ms /    38 runs   (  167.33 ms per token,     5.98 tokens per second)\n",
      "llama_print_timings:       total time =   19017.04 ms /   610 tokens\n",
      "Answering questions:  90%|█████████ | 285/315 [1:07:41<08:32, 17.09s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /    13 runs   (    0.34 ms per token,  2912.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13856.36 ms /   619 tokens (   22.39 ms per token,    44.67 tokens per second)\n",
      "llama_print_timings:        eval time =    2020.46 ms /    12 runs   (  168.37 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   15928.07 ms /   631 tokens\n",
      "Answering questions:  91%|█████████ | 286/315 [1:07:57<08:06, 16.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      23.56 ms /    69 runs   (    0.34 ms per token,  2928.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1258.24 ms /    44 tokens (   28.60 ms per token,    34.97 tokens per second)\n",
      "llama_print_timings:        eval time =   10906.11 ms /    68 runs   (  160.38 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:       total time =   12418.46 ms /   112 tokens\n",
      "Answering questions:  91%|█████████ | 287/315 [1:08:09<07:14, 15.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.60 ms /    28 runs   (    0.34 ms per token,  2916.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10956.35 ms /   512 tokens (   21.40 ms per token,    46.73 tokens per second)\n",
      "llama_print_timings:        eval time =    4457.81 ms /    27 runs   (  165.10 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:       total time =   15519.95 ms /   539 tokens\n",
      "Answering questions:  91%|█████████▏| 288/315 [1:08:25<06:59, 15.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    25 runs   (    0.34 ms per token,  2910.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15864.77 ms /   695 tokens (   22.83 ms per token,    43.81 tokens per second)\n",
      "llama_print_timings:        eval time =    4039.06 ms /    24 runs   (  168.29 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:       total time =   20001.82 ms /   719 tokens\n",
      "Answering questions:  92%|█████████▏| 289/315 [1:08:45<07:19, 16.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      15.64 ms /    46 runs   (    0.34 ms per token,  2941.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4586.33 ms /   179 tokens (   25.62 ms per token,    39.03 tokens per second)\n",
      "llama_print_timings:        eval time =    7249.36 ms /    45 runs   (  161.10 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =   12006.00 ms /   224 tokens\n",
      "Answering questions:  92%|█████████▏| 290/315 [1:08:57<06:26, 15.47s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /     7 runs   (    0.35 ms per token,  2867.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   23529.77 ms /  1040 tokens (   22.62 ms per token,    44.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1015.06 ms /     6 runs   (  169.18 ms per token,     5.91 tokens per second)\n",
      "llama_print_timings:       total time =   24584.83 ms /  1046 tokens\n",
      "Answering questions:  92%|█████████▏| 291/315 [1:09:22<07:17, 18.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      18.09 ms /    46 runs   (    0.39 ms per token,  2543.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10092.87 ms /   465 tokens (   21.71 ms per token,    46.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5939.34 ms /    45 runs   (  131.99 ms per token,     7.58 tokens per second)\n",
      "llama_print_timings:       total time =   16276.76 ms /   510 tokens\n",
      "Answering questions:  93%|█████████▎| 292/315 [1:09:38<06:46, 17.69s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      23.16 ms /    67 runs   (    0.35 ms per token,  2893.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6788.52 ms /   281 tokens (   24.16 ms per token,    41.39 tokens per second)\n",
      "llama_print_timings:        eval time =   10461.84 ms /    66 runs   (  158.51 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:       total time =   17514.07 ms /   347 tokens\n",
      "Answering questions:  93%|█████████▎| 293/315 [1:09:56<06:28, 17.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.36 ms /    30 runs   (    0.35 ms per token,  2894.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9047.22 ms /   409 tokens (   22.12 ms per token,    45.21 tokens per second)\n",
      "llama_print_timings:        eval time =    4605.56 ms /    29 runs   (  158.81 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:       total time =   13767.37 ms /   438 tokens\n",
      "Answering questions:  93%|█████████▎| 294/315 [1:10:10<05:47, 16.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      20.46 ms /    59 runs   (    0.35 ms per token,  2884.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1359.82 ms /    50 tokens (   27.20 ms per token,    36.77 tokens per second)\n",
      "llama_print_timings:        eval time =    9052.40 ms /    58 runs   (  156.08 ms per token,     6.41 tokens per second)\n",
      "llama_print_timings:       total time =   10636.13 ms /   108 tokens\n",
      "Answering questions:  94%|█████████▎| 295/315 [1:10:20<04:55, 14.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      31.30 ms /    79 runs   (    0.40 ms per token,  2524.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8187.21 ms /   381 tokens (   21.49 ms per token,    46.54 tokens per second)\n",
      "llama_print_timings:        eval time =   12365.09 ms /    78 runs   (  158.53 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:       total time =   20959.32 ms /   459 tokens\n",
      "Answering questions:  94%|█████████▍| 296/315 [1:10:42<05:17, 16.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    21 runs   (    0.35 ms per token,  2896.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3396.35 ms /   126 tokens (   26.96 ms per token,    37.10 tokens per second)\n",
      "llama_print_timings:        eval time =    3061.48 ms /    20 runs   (  153.07 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:       total time =    6549.58 ms /   146 tokens\n",
      "Answering questions:  94%|█████████▍| 297/315 [1:10:48<04:06, 13.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      16.15 ms /    47 runs   (    0.34 ms per token,  2910.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9635.04 ms /   434 tokens (   22.20 ms per token,    45.04 tokens per second)\n",
      "llama_print_timings:        eval time =    7364.85 ms /    46 runs   (  160.11 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:       total time =   17176.13 ms /   480 tokens\n",
      "Answering questions:  95%|█████████▍| 298/315 [1:11:06<04:11, 14.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    19 runs   (    0.34 ms per token,  2913.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12712.98 ms /   583 tokens (   21.81 ms per token,    45.86 tokens per second)\n",
      "llama_print_timings:        eval time =    2831.55 ms /    18 runs   (  157.31 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:       total time =   15628.01 ms /   601 tokens\n",
      "Answering questions:  95%|█████████▍| 299/315 [1:11:21<04:01, 15.07s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       8.66 ms /    25 runs   (    0.35 ms per token,  2887.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11053.69 ms /   456 tokens (   24.24 ms per token,    41.25 tokens per second)\n",
      "llama_print_timings:        eval time =    3930.70 ms /    24 runs   (  163.78 ms per token,     6.11 tokens per second)\n",
      "llama_print_timings:       total time =   15128.37 ms /   480 tokens\n",
      "Answering questions:  95%|█████████▌| 300/315 [1:11:37<03:46, 15.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      76.67 ms /   224 runs   (    0.34 ms per token,  2921.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9608.78 ms /   454 tokens (   21.16 ms per token,    47.25 tokens per second)\n",
      "llama_print_timings:        eval time =   36291.31 ms /   223 runs   (  162.74 ms per token,     6.14 tokens per second)\n",
      "llama_print_timings:       total time =   46889.68 ms /   677 tokens\n",
      "Answering questions:  96%|█████████▌| 301/315 [1:12:24<05:45, 24.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      15.32 ms /    45 runs   (    0.34 ms per token,  2937.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2965.48 ms /   110 tokens (   26.96 ms per token,    37.09 tokens per second)\n",
      "llama_print_timings:        eval time =    7062.37 ms /    44 runs   (  160.51 ms per token,     6.23 tokens per second)\n",
      "llama_print_timings:       total time =   10227.54 ms /   154 tokens\n",
      "Answering questions:  96%|█████████▌| 302/315 [1:12:34<04:25, 20.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.20 ms /    30 runs   (    0.34 ms per token,  2940.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6718.71 ms /   276 tokens (   24.34 ms per token,    41.08 tokens per second)\n",
      "llama_print_timings:        eval time =    4694.22 ms /    29 runs   (  161.87 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:       total time =   11529.71 ms /   305 tokens\n",
      "Answering questions:  96%|█████████▌| 303/315 [1:12:46<03:33, 17.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /     9 runs   (    0.34 ms per token,  2928.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1309.03 ms /    47 tokens (   27.85 ms per token,    35.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1260.71 ms /     8 runs   (  157.59 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:       total time =    2601.77 ms /    55 tokens\n",
      "Answering questions:  97%|█████████▋| 304/315 [1:12:48<02:25, 13.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      45.21 ms /   131 runs   (    0.35 ms per token,  2897.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10449.15 ms /   485 tokens (   21.54 ms per token,    46.42 tokens per second)\n",
      "llama_print_timings:        eval time =   20652.72 ms /   130 runs   (  158.87 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:       total time =   31651.43 ms /   615 tokens\n",
      "Answering questions:  97%|█████████▋| 305/315 [1:13:20<03:08, 18.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    24 runs   (    0.50 ms per token,  2010.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11615.20 ms /   511 tokens (   22.73 ms per token,    43.99 tokens per second)\n",
      "llama_print_timings:        eval time =    2012.49 ms /    23 runs   (   87.50 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =   13799.62 ms /   534 tokens\n",
      "Answering questions:  97%|█████████▋| 306/315 [1:13:34<02:36, 17.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.06 ms /    29 runs   (    0.35 ms per token,  2881.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6827.54 ms /   285 tokens (   23.96 ms per token,    41.74 tokens per second)\n",
      "llama_print_timings:        eval time =    4568.21 ms /    28 runs   (  163.15 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =   11506.66 ms /   313 tokens\n",
      "Answering questions:  97%|█████████▋| 307/315 [1:13:46<02:05, 15.63s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      22.53 ms /    65 runs   (    0.35 ms per token,  2884.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9555.42 ms /   433 tokens (   22.07 ms per token,    45.31 tokens per second)\n",
      "llama_print_timings:        eval time =   10278.22 ms /    64 runs   (  160.60 ms per token,     6.23 tokens per second)\n",
      "llama_print_timings:       total time =   20086.46 ms /   497 tokens\n",
      "Answering questions:  98%|█████████▊| 308/315 [1:14:06<01:59, 17.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.79 ms /    29 runs   (    0.44 ms per token,  2268.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5536.28 ms /   211 tokens (   26.24 ms per token,    38.11 tokens per second)\n",
      "llama_print_timings:        eval time =    4511.21 ms /    28 runs   (  161.11 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =   10211.05 ms /   239 tokens\n",
      "Answering questions:  98%|█████████▊| 309/315 [1:14:16<01:29, 15.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /    37 runs   (    0.34 ms per token,  2912.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10593.65 ms /   478 tokens (   22.16 ms per token,    45.12 tokens per second)\n",
      "llama_print_timings:        eval time =    5751.22 ms /    36 runs   (  159.76 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:       total time =   16490.38 ms /   514 tokens\n",
      "Answering questions:  98%|█████████▊| 310/315 [1:14:33<01:17, 15.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      22.12 ms /    64 runs   (    0.35 ms per token,  2893.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1989.14 ms /    73 tokens (   27.25 ms per token,    36.70 tokens per second)\n",
      "llama_print_timings:        eval time =    6231.73 ms /    63 runs   (   98.92 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =    8503.55 ms /   136 tokens\n",
      "Answering questions:  99%|█████████▊| 311/315 [1:14:41<00:53, 13.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       9.88 ms /    28 runs   (    0.35 ms per token,  2833.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2746.16 ms /   104 tokens (   26.41 ms per token,    37.87 tokens per second)\n",
      "llama_print_timings:        eval time =    2245.95 ms /    27 runs   (   83.18 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =    5115.33 ms /   131 tokens\n",
      "Answering questions:  99%|█████████▉| 312/315 [1:14:47<00:32, 10.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /    10 runs   (    0.34 ms per token,  2960.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.45 ms /    40 tokens (   28.46 ms per token,    35.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1436.01 ms /     9 runs   (  159.56 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:       total time =    2614.04 ms /    49 tokens\n",
      "Answering questions:  99%|█████████▉| 313/315 [1:14:49<00:17,  8.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /     7 runs   (    0.34 ms per token,  2904.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19033.78 ms /   851 tokens (   22.37 ms per token,    44.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1008.92 ms /     6 runs   (  168.15 ms per token,     5.95 tokens per second)\n",
      "llama_print_timings:       total time =   20075.29 ms /   857 tokens\n",
      "Answering questions: 100%|█████████▉| 314/315 [1:15:09<00:12, 12.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4891.83 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    27 runs   (    0.40 ms per token,  2489.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9779.95 ms /   451 tokens (   21.69 ms per token,    46.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2286.11 ms /    26 runs   (   87.93 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =   12216.75 ms /   477 tokens\n",
      "Answering questions: 100%|██████████| 315/315 [1:15:22<00:00, 14.36s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Load questions from questions.txt\n",
    "with open(\"SubmissionData/train/questions.txt\", \"r\") as f:\n",
    "    questions = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Output directory for answers\n",
    "output_dir = \"SubmissionData/system_outputs/\"\n",
    "answer_file = os.path.join(output_dir, \"MistralEmbeddingsTrain.txt\")\n",
    "\n",
    "# Run the question-answering loop and save answers\n",
    "answers = []\n",
    "with tqdm(total=len(questions), desc=\"Answering questions\") as progress_bar:\n",
    "    with open(answer_file, \"w\") as f:\n",
    "        for question in questions:\n",
    "            response = qa_chain.invoke(question)\n",
    "            f.write(response.replace(\"\\n\",\"\") + \"\\n\")\n",
    "            answers.append(response)\n",
    "            progress_bar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-rag",
   "language": "python",
   "name": "nlp-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
