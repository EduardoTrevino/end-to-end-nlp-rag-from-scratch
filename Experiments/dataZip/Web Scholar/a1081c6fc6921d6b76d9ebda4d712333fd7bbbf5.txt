Large Language Models for Generative Recommendation: A Survey and
Visionary Discussions
Lei Li1,Yongfeng Zhang2,Dugang Liu3and Li Chen1
1Hong Kong Baptist University, Hong Kong, China
2Rutgers University, New Brunswick, USA
3Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen, China
{csleili, lichen }@comp.hkbu.edu.hk, yongfeng.zhang@rutgers.edu, dugang.ldg@gmail.com
Abstract
Recent years have witnessed the wide adoption of
large language models (LLM) in different fields, es-
pecially natural language processing and computer
vision. Such a trend can also be observed in rec-
ommender systems (RS). However, most of related
work treat LLM as a component of the conven-
tional recommendation pipeline (e.g., as a feature
extractor) which may not be able to fully lever-
age the generative power of LLM. Instead of sep-
arating the recommendation process into multiple
stages such as score computation and re-ranking,
this process can be simplified to one stage with
LLM: directly generating recommendations from
the complete pool of items. This survey reviews the
progress, methods and future directions of LLM-
based generative recommendation by examining
three questions: 1) What generative recommenda-
tion is, 2) Why RS should advance to generative
recommendation, and 3) How to implement LLM-
based generative recommendation for various RS
tasks. We hope that the survey can provide the con-
text and guidance needed to explore this interesting
and emerging topic.
1 Introduction
Over the years, recommender systems (RS) have undoubtedly
made our daily life easier when it comes to finding things
that we are interested in, such as movies, songs, and restau-
rants. In the meantime, the strong capability of large language
models (LLM) in handling various tasks has impressed both
practitioners in the field of artificial intelligence (AI) and the
general public. As a result, it is natural to consider the com-
bination of the two, i.e., RS and LLM [Geng et al. , 2022c ].
Although natural language is an expressive medium, it can
also be vague. For example, when an LLM is deployed for
vehicle identification and scheduling, it would be dangerous
to use vague descriptions (e.g., “a black SUV”) to identify a
vehicle rather than a precise identifier such as vehicle identi-
fication number (VIN) or plate number. Similarly, vagueness
may also be a problem in recommendation scenarios that re-
quire precise and unique identifiers of items, because RS need
to guarantee that recommendations made for users are thingsthat factually exist so as to avoid the hallucination problem
[Azamfirei et al. , 2023 ]. This also explains why an ID is
usually assigned for each user/item in RS. Despite that, the
current understanding of IDs is usually limited to one form.
That is, most RS research considers each ID as a discrete to-
ken associated with an embedding vector. In this survey, we
generalize the definition of ID as follows:
Definition 1 (ID in Recommender Systems) .An ID in rec-
ommender systems is a sequence of tokens that can uniquely
identify an entity, such as a user or an item. An ID can take
various forms, such as a vector embedding, a sequence of nu-
merical tokens, and a sequence of word tokens (including an
item title, a description of the item, or even a complete news
article), as long as it can uniquely identify the entity.
For example, a product in e-commerce platform may be
assigned the ID “item 7391” and be further represented as a
sequence of tokens such as ⟨item⟩⟨⟩⟨73⟩⟨91⟩[Geng et al. ,
2022c; Xu et al. , 2023 ]. Note that the ID may not neces-
sarily be comprised of numerical tokens. As long as it is
a unique identifier for an item, it may be considered as the
item’s ID. For example, the title of the movie “The Lord of
the Rings” can be considered as the ID of the movie. The ID
may even be a sequence of words that do not convey any ex-
plicit meaning, e.g., “ring epic journey fellowship adventure”
[Hua et al. , 2023b ]. Actually, IDs in conventional RS can be
seen as a special case of the above definition, i.e., a sequence
of just one token. Under this definition, IDs resemble token
sequences as in text, and thus naturally fit natural language
environment as well as LLM.
Due to the huge number of items in real-world systems,
traditional RS usually take the multi-stage filtering paradigm
[Covington et al. , 2016 ]– some simple and efficient meth-
ods such as rule-based filtering are used to reduce the number
of candidate items from millions to a few hundred, and then
advanced recommendation algorithms are applied on the re-
maining items to further select a few number of items for rec-
ommendation. As a result, advanced recommendation algo-
rithms are not applied to all items, but only a few hundred of
items.
The generative power of LLM has the potential to reshape
the RS paradigm from multi-stage filtering to single-stage fil-
tering. In the context of generative recommendation, an LLM
itself can be the single and entire recommendation pipeline,
which directly generates the items to recommend, eliminat-arXiv:2309.01157v1  [cs.IR]  3 Sep 2023Recall
Pre-rank
Rank
Rerank
1
23
7 56
48Item Set
......
Generative
RecommendationIndex Set Index SetToken Set  
0
1
20
1
2
1 ... 0 1
0 01 0
1 1 1 2 2 20 2 2 0ID 
MappingTokenized
Sear ch
root
1 0 2
1 0 2 1 0 2 1 0 2
1
1... ...
Traditional   
Recommendation  Generate
...ID Set  
1 2 3 4 5 6 7 8...
1
2
3
4
5
6
7
8
...Figure 1: Pipeline comparison between traditional recommender systems and LLM-based generative recommendation.
ing the need for multi-stage filtering. In other words, ad-
vanced LLM-based recommendation algorithms are implic-
itly applied over all items in the system to decide which items
to recommend. We term such a process generative recom-
mendation and formally define it as follows:
Definition 2 (Generative Recommendation) .A generative
recommender system directly generates recommendations or
recommendation-related content without the need to calcu-
late each candidate’s ranking score one by one for sorting
and ranking.
In a broader sense, this is in line with the trend of general AI
research, which recently has been shifting from discrimina-
tive AI (such as classification and regression) to generative
AI (e.g., ChatGPT1).
With the above definitions, we first answer why RS are de-
veloping towards generative recommendation in Section 2. In
Section 3, we review ID creation approaches that could retain
collaborative information in the LLM environment. Then, we
show how typical recommendation tasks can be performed
on LLM by providing general formulations in Section 4, and
highlight opportunities in the LLM era in Section 5. At last,
we conclude our survey in Section 6.
It should be noted that our survey is different from some
recent surveys on LLM-based recommendation [Liuet al. ,
2023c; Wu et al. , 2023; Fan et al. , 2023; Lin et al. , 2023a;
Chen et al. , 2023 ]from two perspectives: 1) our survey is
organized with generative recommendation as the key focus,
eliminating discriminative recommendation models for clar-
ity; 2) we develop a taxonomy for LLM-based recommen-
dation research with strong inspiration from the recommen-
dation community, instead of following the LLM taxonomy
from the community of natural language processing (NLP).
To sum up, this survey makes the following contributions:
• To the best of our knowledge, this is the first survey that
1https://openai.com/blog/chatgptsystematically summarizes research on LLM-based gen-
erative recommendation. To differentiate this topic from
traditional RS, we have generalized the definition of ID
for generative recommendation.
• This survey is pragmatic as we provide the formulation
for different LLM-based recommendation tasks when
categorizing relevant research, which provides a useful
guideline for future research.
• We discuss important and promising directions to ex-
plore for LLM-based generative recommendation re-
search, which may help broaden the scope of this under-
explored research area.
2 Why Generative Recommendation
To answer why RS are developing towards generative rec-
ommendation, we first discuss problems with discriminative
recommendation. When the amount of items on a recommen-
dation platform is prohibitively large, the ranking score cal-
culation with regard to each item would be computationally
expensive. Therefore, industrial RS usually consist of multi-
ple stages to narrow down the candidate items. At the early
stage, simple models (e.g., logistic regression) or straightfor-
ward filtering strategies (e.g., feature matching) are usually
adopted to filter out less relevant items. Only in the final stage
can the relatively complex and advanced models be utilized.
This naturally causes a gap between academic research and
industrial application. In consequence, although recent rec-
ommendation models are growing more fancy and sophisti-
cated, few have been practically employed in industry.
In the era of LLM, we see a great opportunity that could
potentially bridge this gap. As both academic research and in-
dustry application may share the same backbone LLM, most
research advancements on LLM may benefit its downstream
applications. Regarding recommendation pipeline, the typi-
cal multiple stages could be advanced to one stage for gener-
ative recommendation, i.e., directly generating items to rec-Item ID User ID Related Work
Token Sequence
(e.g., “ 56 78 ”)Token Sequence P5 [Geng et al. , 2022c ], UP5 [Hua et al. , 2023a ], VIP5 [Geng et al. , 2023 ], OpenP5 [Xuet al. , 2023 ], POD [Liet al. , 2023c ], GPTRec [Petrov and
Macdonald, 2023 ],[Huaet al. , 2023b ]
Item Title (e.g.,
“Fast X ”)Interaction History (e.g.,
[“Fast X ”, “Her”, ...])LMRecSys [Zhang et al. , 2021 ], GenRec [Jiet al. , 2023 ], GPT4Rec [Liet al. , 2023a ], TALLRec [Baoet al. , 2023b ], NIR [Wang and Lim, 2023 ],
PALR [Chen, 2023 ], BookGPT [Zhiyuli et al. , 2023 ], PBNR [Liet al. , 2023e ], ReLLa [Linet al. , 2023b ], KnowRec [Colas et al. , 2023 ], BIGRec
[Baoet al. , 2023a ],[Daiet al. , 2023; Liu et al. , 2023a; Hou et al. , 2023b; Li et al. , 2023f; Zhang et al. , 2023b ]
Item Title Metadata (e.g., age) Chat-REC [Gaoet al. , 2023 ],[Zhang et al. , 2023a; He et al. , 2023 ]
Metadata Metadata M6-Rec [Cuiet al. , 2022 ], LLMRec [Liuet al. , 2023b ]
Embedding ID Embedding ID PEPLER [Liet al. , 2023b ]
Table 1: Methods of representing IDs for LLM-based generative recommendation.
ommend. A graphical comparison between the two types of
pipeline is shown in Fig. 1. At each step of recommendation
generation, the LLM can produce a vector that represents the
probability distribution on all possible ID tokens. After a few
steps, the generated tokens can constitute a complete ID that
stands for the target item. This process implicitly enumerates
all candidate items to generate the target item for recommen-
dation, which is different from traditional RS that draw items
from a subset resulted from the previous filtering step.
The key secret of LLM for generative recommendation is
that we can use finite tokens to represent (almost) infinite
items. Suppose that we have 1000 tokens for representing
user or item IDs, which can be numerical tokens, word to-
kens or even out-of-vocabulary (OOV) tokens, and each ID
consists of 10tokens, then we can use these 1000 tokens to
represent as many as 100010= 1030items (i.e., unique IDs),
which is almost an astronomical number and large enough
for most of real-world RS. When applying beam search algo-
rithm for generating item IDs, the probability vector at each
step is bounded by 1000 tokens, making it computationally
possible to directly generate recommendations out of the item
pool.
3 ID Creation Methods
When implementing generative recommendation with LLM,
the input (particularly user and item IDs) should be made into
the right format that is compatible with LLM. Intuitively, one
would consider the metadata of users and items as an alterna-
tive, such as user name and item title. In fact, this type of ID
representation is quite common in related work, as summa-
rized in Table 1. Despite the popularity, it has two problems
[Liet al. , 2023d ]. First, when the IDs are extremely long,
e.g., in the case of item description, it would be computation-
ally expensive to conduct generation. Besides, it would be
difficult to find an exact match in the database for a long ID,
i.e., the hallucination problem [Azamfirei et al. , 2023 ]; and
double-checking the existence of each ID would take us back
to discriminative recommendation since we need to compare
it with each item in the database. Second, although natural
language is a powerful and expressive medium, it can also
be vague in many cases. For example, two different users’
names could be identical. Besides, two irrelevant items could
have very similar titles, such as Apple the fruit and Apple the
company, while two closely related items may have very dif-
ferent titles, such as the classic “beer and diaper” example in
data mining.Therefore, we need concise and unique representations of
IDs in recommendation scenarios to precisely distinguish one
user or item from the others. Associating each ID with an em-
bedding vector is a common practice in traditional RS, but it
would cost a lot of memory to store them, since industry-scale
RS usually involve tons of users and items. In addition, these
IDs are OOV tokens to LLM, and thus are not very compati-
ble with the models.
This is why a new way of representing IDs, i.e., a sequence
of tokens rather than a single embedding, is needed. The key
idea is to use a small amount of tokens to represent an astro-
nomical number of users or items as explained in the previous
section. To make IDs reasonably short, similar users or items
could share more tokens in their ID sequences, while the re-
maining tokens can be used to guarantee their uniqueness. In
the following, we review three typical ID creation approaches
that follow this principle. Most of these ID creation methods
aim to encode the user-user, item-item, or user-item collab-
orative information into the ID representations, which com-
bines the success of collaborative filtering from traditional RS
with the emerging LLM for effective recommendation.
3.1 Singular Value Decomposition
[Petrov and Macdonald, 2023 ]acquire an item’s ID tokens
from its latent factors. Specifically, they first perform trun-
cated singular value decomposition on user-item interaction
data to obtain the item embedding matrix. After a set of oper-
ations, including normalization, noise-adding, quantization,
and offset adjustment, each item’s embedding becomes an ar-
ray of integers, which serves as this item’s ID sequence. In
particular, the noise-adding operation can ensure that there
are no identical item embeddings, and thus make each item
ID unique.
3.2 Product Quantization
[Hou et al. , 2023a ]quantize item embeddings with product
quantization (PQ) [Jegou et al. , 2010 ]to obtain their IDs. For
PQ, there are in total Dvector sets, and each set is comprised
ofMcentroid embeddings. They first encode an item’s tex-
tual description with BERT [Devlin et al. , 2019 ]to get the
item’s embedding vector, which is further divided into Dseg-
ments for quantization. For the i-th embedding segment, its
nearest centroid embedding from the i-th vector set can be
easily found. The index of this centroid embedding then be-
comes the item’s i-th ID token. All these ID tokens together
form the item’s complete ID.Rating Prediction Top-N Recommendation Sequential Recommendation Explainable Recommen-
dationReview
GenerationReview Sum-
marizationConversational
Recommendation
P5[Geng et al. ,
2022c ], BookGPT
[Zhiyuli et al. ,
2023 ], LLMRec
[Liuet al. , 2023b ],
RecMind [Wang
et al. , 2023b ],
[Liuet al. , 2023a;
Daiet al. , 2023 ]P5[Geng et al. , 2022c ], UP5 [Hua et
al., 2023a ], VIP5 [Geng et al. , 2023 ],
OpenP5 [Xuet al. , 2023 ], POD [Li
et al. , 2023c ], GPTRec [Petrov and
Macdonald, 2023 ], LLMRec [Liuet
al., 2023b ], RecMind [Wang et al. ,
2023b ],[Zhang et al. , 2023a; Zhang
et al. , 2023b; Liu et al. , 2023a; Li et
al., 2023f; Dai et al. , 2023 ]P5[Geng et al. , 2022c ], UP5 [Hua et al. ,
2023a ], VIP5 [Geng et al. , 2023 ], OpenP5 [Xu
et al. , 2023 ], POD [Liet al. , 2023c ], GenRec
[Jiet al. , 2023 ], GPTRec [Petrov and Macdon-
ald, 2023 ], LMRecSys [Zhang et al. , 2021 ],
NIR [Wang and Lim, 2023 ], PALR [Chen,
2023 ], LLMRec [Liuet al. , 2023b ], RecMind
[Wang et al. , 2023b ], BIGRec [Bao et al. ,
2023a ],[Hua et al. , 2023b; Liu et al. , 2023a;
Hou et al. , 2023b; Zhang et al. , 2023b ]P5[Geng et al. , 2022c ],
VIP5 [Geng et al. , 2023 ],
POD [Liet al. , 2023c ],
PEPLER [Li et al. ,
2023b ], M6-Rec [Cui et
al., 2022 ], LLMRec [Liu
et al. , 2023b ], RecMind
[Wang et al. , 2023b ],
KnowRec [Colas et al. ,
2023 ],[Liuet al. , 2023a ]- P5 [Geng et
al., 2022c ],
LLMRec [Liu
et al. , 2023b ],
RecMind
[Wang et al. ,
2023b ],[Liu
et al. , 2023a ]M6-Rec [Cui et
al., 2022 ], Re-
cLLM [Friedman
et al. , 2023 ],
Chat-REC [Gao et
al., 2023 ],[Wang
et al. , 2023a;
Lin and
Zhang, 2023;
Heet al. , 2023 ]
Table 2: Seven typical generative recommendation tasks with LLM.
3.3 Collaborative Indexing
[Hua et al. , 2023b ]compose an item ID with nodes on a hi-
erarchical tree. Technically, they first construct an item graph
whose edge weights denote the co-occurring frequency of any
two items in all users’ interaction history. Then, the graph’s
adjacency matrix and Laplacian matrix as well as the latter’s
eigenvectors can be computed. With the eigenvectors, spec-
tral clustering [V on Luxburg, 2007 ]can be applied to group
similar items into the same cluster. By recursively doing so,
large clusters can be further divided into smaller ones. When
the number of nodes in each cluster is smaller than a thresh-
old, these clusters and their sub-clusters naturally constitute a
hierarchical tree whose leaf nodes are the items. After assign-
ing tokens to each node, each item has a unique ID sequence
by following a path from the root node to the leaf node.
In addition to the above three ID creation approaches, [Hua
et al. , 2023b ]discussed other strategies such as sequential in-
dexing based on user interaction history, and semantic index-
ing based on item metadata information, which are effective
approaches to creating item IDs. We omit the details because
they are quite simple and straightforward.
4 How to Do Generative Recommendation
With the above-defined user and item IDs, we now describe
how to perform different generative recommendation tasks
with LLM. A summary of relevant research on each task is
given in Table 2. We can see that there are a few models that
have the ability to perform multiple recommendation tasks,
e.g., P5 [Geng et al. , 2022c ]. To allow LLM to understand
each task, especially those that have the same input data,
we can construct a prompt template [Liuet al. , 2023d ]that
describes the task and then fill the user and item informa-
tion such as their IDs in the prompt. During the inference
stage, all kinds of output (e.g., predicted item IDs) are auto-
regressively generated as natural language generation. In the
following, we introduce the general formulation of each task,
followed by the recent progress. Finally, we discuss how to
evaluate these tasks.
4.1 Rating Prediction
In conventional RS, the rating prediction task is formulated
as follows: given a user uand an item i, a recommenda-
tion model f(u, i)needs to estimate a score ˆru,ithat the
user would rate the item. In the context of LLM, uandi
are no longer embedding IDs, but two sequences of tokens
as defined in Definition 1. The two IDs can be filled in aninstruction prompt p(u, i), e.g., “how would user 1234 rate
item 5678 ”, such that LLM can understand this task. Af-
ter feeding p(u, i)into the LLM, it can generate a numerical
string in the scale of 1 to 5 such as “4.12”, indicating that the
user is likely to interact with the item.
There are some studies [Geng et al. , 2022c ]that tested
LLM with this task, among which many [Zhiyuli et al. , 2023;
Liu et al. , 2023a; Dai et al. , 2023; Liu et al. , 2023b;
Wang et al. , 2023b ]are based on ChatGPT. As users may
not leave an explicit rating for each item with which they in-
teract, the rating prediction task can be less practical for real-
world systems. Instead, implicit feedback, e.g., clicking, is
easier to collect. Thus, how to infer users’ preferences from
such implicit feedback motivates the development of top- N
recommendation task.
4.2 Top- NRecommendation
The top- Nrecommendation task, a.k.a., ranking, aims to se-
lectNitems as recommendations for a given user u. To this
end, traditional RS usually compute a score ˆru,iw.r.t. each
itemiin the item set I. After filtering out those that the
user already interacted with, i.e., Iu, the top candidates can
be selected as recommendations from the remaining items as
Top(u, i) := arg maxN
i∈I/Iuˆru,i.
However, due to the context length limit of LLM, it is im-
possible to feed the model all the items. As a result, the com-
munity has explored two approaches to solve the problem.
One is straightforward recommendation [Xuet al. , 2023;
Geng et al. , 2022c; Zhang et al. , 2023a ], which uses a prompt
that only contains user information (ID or user metadata) and
asks the LLM to directly generate recommendations for this
user. The second is selective recommendation [Geng et al. ,
2022c; Hua et al. , 2023a; Geng et al. , 2023; Li et al. , 2023c;
Petrov and Macdonald, 2023; Zhang et al. , 2023b; Liu et al. ,
2023a; Li et al. , 2023f; Dai et al. , 2023; Liu et al. , 2023b;
Wang et al. , 2023b ], which provides both user information
and a list of candidate items Icin the prompt and asks the
LLM to select items for recommendation out of the candi-
dates. For example, the candidate list may consist of a testing
item and a number of sampled negative items. After filling
the user and candidates in a prompt p(u,Ic), e.g., “select one
item to recommend for user 1234 from the following candi-
dates: item 6783, ..., item 9312, item 2834 ”, the LLM can
generate an item ID, e.g., “9312” as recommendation. When
combined with beam search, the model can produce a number
of item IDs, i.e., a list of Nrecommendations.
Besides generating item IDs, some recent studies [Liet al. ,2023e; Bao et al. , 2023b; Lin et al. , 2023b ]instruct LLM to
answer whether a user is going to interact with a given item by
generating “yes” or “no”. Although the “yes” or “no” answer
is generated by LLM, these methods can be considered as
discriminative recommendation since they need to generate
an answer or a score (e.g., the probability of “yes”) for each
item.
4.3 Sequential Recommendation
The sequential recommendation task goes one step further
than the top- Nrecommendation with the consideration of the
time or order of interaction. Specifically, its objective is to
predict the next item with which a user uis likely to interact
based on his/her past interactions. The items interacted by
the user are chronologically ordered according to their times-
tamps, which can be denoted as Iu. Considering the sequen-
tial nature of such data, researchers usually employ sequential
models to deal with the problem, such as Markov chains, re-
current neural networks (RNN), and Transformer [Vaswani et
al., 2017 ]. Again, we can first fill the user and the item se-
quence in a prompt p(u, Iu), e.g., “given user 1234 ’s interac-
tion history item 3456, ..., item 4567, item 5678 , predict the
next item with which the user will interact”, and then prompt
LLM to generate an item ID as a prediction, e.g., “6789”. To
reduce the inference time, we can cut off the relatively old
items before filling the item sequence in the prompt.
This task is a trending topic, as evidenced by a signif-
icant number of LLM-based models [Geng et al. , 2022c;
Hua et al. , 2023a; Geng et al. , 2023; Xu et al. , 2023; Li et
al., 2023c; Petrov and Macdonald, 2023; Zhang et al. , 2021;
Wang and Lim, 2023; Hua et al. , 2023b; Liu et al. , 2023a;
Zhang et al. , 2023b; Liu et al. , 2023b; Wang et al. , 2023b ].
In particular, [Bao et al. , 2023a ]leverage LLM to gen-
erate candidates for further filtering while [Chen, 2023;
Hou et al. , 2023b; Ji et al. , 2023 ]provide LLM with can-
didate items for recommendation, and [Bao et al. , 2023b;
Linet al. , 2023b ]instruct LLM to answer whether a user is
going to like a specific item.
4.4 Explainable Recommendation
Besides generating recommendations, explanations that allow
users to know the reason behind them are equally important.
There are various methods to explain a recommendation to a
user, such as explicit item features [Zhang et al. , 2014 ]and
visual highlights [Chen et al. , 2019 ]. We refer interested read-
ers to the survey [Zhang et al. , 2020 ]for a comprehensive
examination of explainable recommendations.
A typical LLM-based recommendation explanation task
can be natural language explanation generation. That is,
given a pair of user uand item i, we direct the model to gener-
ate a sentence or paragraph in natural language to explain why
iis recommended for u. Ground-truth explanations can be
mined from user reviews [Liet al. , 2020 ]. As the inputs (i.e.,
uandi) are identical to those for rating prediction, we can
put them in a prompt p(u, i)to inform the LLM that this is an
explanation task, e.g., “explain to user 1234 why item 5678
is recommended.” As a response, the model may generate
an explanation such as “The movie is top-notch.” However,
using IDs alone in the prompt could be unclear as to whichaspects the model should discuss in the explanation. To ad-
dress this problem, we can provide some item features fas
hint words in the prompt, e.g., “acting”. An example prompt
p(u, i, f )for such a scenario could be “write an explanation
foruser 1234 about item 5678 based on the feature acting .”
Then, the LLM may generate an explanation such as “The
acting in this movie is attractive.”
[Geng et al. , 2022c; Geng et al. , 2023; Li et al. , 2023c; Liu
et al. , 2023a; Liu et al. , 2023b; Wang et al. , 2023b ]perform
the explanation generation task as above; [Cuiet al. , 2022 ]
trigger the explanation task with the word “because”; [Liet
al., 2023b ]make use of continuous prompt vectors instead of
discrete prompt templates.
4.5 Review Generation
In addition to explanation generation, the above formulation
can also be adapted to the review generation task, which may
make it easier and more efficient for users to leave a com-
ment after purchasing a product, watching a movie, taking a
ride, etc. The resulting data would in turn facilitate the de-
velopment of recommendation-related research, such as ex-
plainable recommendation and conversational recommenda-
tion. As usual, we can fill a user and his/her interacted item
in a prompt p(u, i), e.g., “generate a review for user 1234
about item 5678 .” Then, the LLM may generate a review
paragraph. For example, “the hotel is located in ...”. How-
ever, we have not noticed any LLM-based recommendation
research on this problem, probably because the formulation
is too similar to explanation generation, except that reviews
are generally longer.
4.6 Review Summarization
Reading a long review can take some time, which users may
not be able to afford sometimes. A highly concise review
summary can help users quickly understand the pros and cons
of an item. Current LLM-based review summarization meth-
ods[Geng et al. , 2022c; Liu et al. , 2023a; Liu et al. , 2023b;
Wang et al. , 2023b ]mainly target how to summarize a user
u’s own review Rfor an item i, and treat the review title or
tip as the summary. In this case, we can construct a prompt
and fill the ternary data in p(u, i, R ), e.g., “summarize the
following review that user 1234 wrote for item 5678 :the ho-
tel is located in ... ”. Then, the LLM may generate a short
summary, e.g., “great location”.
However, it may be unnecessary to summarize a user’s own
review because the user already knows about the reviewed
item. Instead, summarizing the review for another user who
has never interacted with the item can be more useful. Fur-
thermore, it is also meaningful to conduct multi-review sum-
marization that summarizes different users’ opinions towards
the same item. However, the problem lies in creating such
multi-review summary data, since it may take a lot of human
effort to write those summaries.
4.7 Conversational Recommendation
The goal of conversational recommendation is to recommend
a user some items within multiple rounds of conversation
[Jannach et al. , 2021; Sun and Zhang, 2018; Zhang et al. ,
2018 ]. Different from traditional RS which mainly rely onusers’ historical interactions, in a conversational environment
users can freely state their preferences in natural language and
even provide negative feedback, e.g., rejecting a recommen-
dation. However, the research community is still in the pro-
cess of reaching a consensus on how to formulate this task.
[Cuiet al. , 2022; Friedman et al. , 2023; He et al. , 2023 ]
adopt two labels (i.e., “USER” and “SYSTEM”) to mark the
speaker of an utterance before feeding a dialogue session into
the LLM for generating a response. [Gaoet al. , 2023 ]further
employ a prompt constructor to summarize the input informa-
tion, such as the user’s query and historical conversation, but
the technical details are not fully disclosed. [Lin and Zhang,
2023 ]directly chat with ChatGPT, because they aim to es-
tablish principles for conversational recommendation, e.g.,
memory mechanism and repair mechanism, rather than de-
veloping new models. For evaluation, [Wang et al. , 2023a ]
point out the problem of current protocols. Specifically, al-
though ChatGPT’s chatting ability is undeniably impressive,
its performance on existing metrics is not very good because
they overly stress the matching between generated responses
and annotated recommendations or utterances.
4.8 Evaluation Protocols
To evaluate the performance of LLM on these tasks, we
can apply existing metrics. For rating prediction, root mean
square error (RMSE) and mean absolute error (MAE) are
commonly used. For the other two recommendation tasks,
i.e., top- Nrecommendation and sequential recommendation,
we can employ ranking-oriented metrics, such as normal-
ized discounted cumulative gain (NDCG), precision, and re-
call. Besides offline evaluation, online A/B test can also be
adopted since it is able to reflect users’ actual interactions
with recommended items.
As to natural language generation tasks, including expla-
nation generation, review generation, review summarization,
and conversational recommendation, the quality of LLM’s
generation can be estimated with BLEU [Papineni et al. ,
2002 ]in machine translation and ROUGE [Lin, 2004 ]in text
summarization. Both metrics measure the degree of match-
ing between text segments of the generated content and those
of the ground-truth. Some other learning-based metrics can
also be used, e.g., BERTScore [Zhang et al. , 2019 ]. However,
as pointed out in [Wang et al. , 2023a ], it can be problematic
to over-emphasize the matching with annotated data. Also,
there are other aspects beyond text similarity that cannot be
reflected by BLEU or ROUGE. As an early attempt, [Liet al. ,
2020 ]proposed several metrics such as feature coverage ratio
and feature diversity that take into account the characteristics
of explicit elements for the evaluation of explanations, but
they are still rudimentary. Thus, more advanced and standard
metrics need to be developed. In addition to automatic evalu-
ation, we can also conduct human evaluation to measure LLM
on these generation tasks. However, it requires researchers to
properly design the questionnaire and the number of partici-
pants could be limited.
5 Challenges and Opportunities
In this section, we discuss research challenges and opportu-
nities for generative recommendation in the LLM era, espe-cially those significant matters that need urgent care in the
near future.
5.1 Hallucination
Hallucination [Azamfirei et al. , 2023 ]means that the content
generated by an LLM may deviate from the facts. Hallucina-
tion is an important problem in LLM as well as their applica-
tions. In particular, for LLM-based RS, we need to guarantee
that the items recommended to users really exist, otherwise
it may cause user dissatisfaction and frustration, and even
low user adoption of the system in real life. For example, a
user may spend time traveling to a recommended restaurant,
only to find out that such a restaurant does not exist at all.
In high-stake recommendation domains such as drug recom-
mendation, medical treatment recommendation, and financial
investment recommendation, hallucinated recommendations
may cause severe losses for users.
There are two possible approaches to addressing the hal-
lucination problem in LLM-based RS. One is to use meticu-
lously designed item IDs for generation. For example, [Hua
et al. , 2023b ]create item IDs and organize the IDs of all items
into a prefix tree structure, which is also called a trie structure.
As a result, as long as the beam search generation process fol-
lows the root-to-leaf paths in the tree, the generated items will
be guaranteed to be really existing items. The other method is
to apply retrieval-augmentation over the LLM [Mialon et al. ,
2023 ], i.e., conditioning LLM on retrieved items, so that the
recommended items match those in the item database. Fur-
thermore, the two methods, i.e., indexing and retrieval, can
be integrated to address the hallucination problem effectively
and efficiently.
5.2 Bias and Fairness
There can be two types of bias for LLM-based RS, which
arecontent bias andrecommendation bias . The former refers
to the bias that can be directly observed in the generated
content. A typical example is gender bias. [Wang et al. ,
2022a ]find that machine-generated recommendation expla-
nations for male users are usually longer than those for fe-
male users in the game domain. This problem may lie in the
training data that are adapted from user reviews of games. In
addition to recommendation data, LLM trained with a huge
amount of human-generated data may reiterate or even rein-
force the bias hidden in the training data. Taking linguistic
bias as an example, [Zhang et al. , 2021 ]observe that LLM
tend to use generic tokens when generating item titles to make
them look fluent and linguistically sound, but lead to recom-
mendations that are greatly different from users’ preferred
items. When adapted to downstream recommendation tasks,
the bias should be mitigated or even completely removed so
as to prevent the propagation of negative effects and to im-
prove user experience.
Regarding recommendation bias, [Liet al. , 2023f ]report
that ChatGPT is prone to recommend news articles from news
providers that it labeled as popular. [Zhang et al. , 2023a ]
observe that the music recommendations made by ChatGPT
for people with different demographic attributes (e.g., white
v.s. African American) are different. Although the results
look biased, they could also be a type of personalizationsince the music tastes of people under different cultural back-
grounds could differ. Therefore, a question needs to be an-
swered: What is the boundary between bias and personaliza-
tion? [Hua et al. , 2023a ]attempt to make LLM-based rec-
ommendation models fair with respect to sensitive attributes,
such as age, marital status, and occupation, by distilling the
bias into continuous prompts. As the bias and fairness issues
are still open problems, more work should be done, e.g., from
the perspective of fairness definition and bias mitigation for
LLM-based RS.
5.3 Transparency and Explainability
Making recommendations transparent and explainable to
users has always been an important problem for RS and AI
in general [Zhang et al. , 2020 ]. Due to the huge size and
complexity of LLM, explaining LLM-based recommenda-
tions has posed new challenges to the community. There
are two types of explainability for LLM-based RS. One is
to generate reasonable natural language explanations for rec-
ommended items, while the other is to really dive into the
model and try to explain the internal working mechanism of
LLM. While researchers have explored the first type of ex-
plainability for a while [Liet al. , 2021; Geng et al. , 2022c;
Geng et al. , 2023; Li et al. , 2023c; Liu et al. , 2023a;
Liuet al. , 2023b; Wang et al. , 2023b; Cui et al. , 2022; Li
et al. , 2023b; Colas et al. , 2023 ], the second type of explain-
ability has been largely unexplored. One possible method is
to align the LLM such as its prompts with an explicit knowl-
edge base such as a knowledge graph [Geng et al. , 2022b;
Yeet al. , 2023 ], so that the model’s decision making pro-
cess is aligned with explicit paths in the knowledge graph for
explanation. However, the direction is generally very prelim-
inary and requires innovative methods and brave new ideas
from the community.
5.4 Controllability
Controllability is an important problem for LLM, since we
usually cannot precisely control the output of LLM. The
lack of controllability may cause serious problems. For
example, LLM may generate harassing content, fake con-
tent, or content that deviates from basic moral standards.
For RS, the controllability issue is more complicated due
to the various recommendation tasks or scenarios that re-
quire controllability [Tanet al. , 2023; Wang et al. , 2022b;
Schafer et al. , 2002; Parra and Brusilovsky, 2015 ]. For ex-
ample, users may want to control the feature that an ex-
planation talks about [Liet al. , 2021; Li et al. , 2023b;
Geng et al. , 2022c ], i.e., if a user cares about the “price”
of a restaurant, then the explanation should talk about its
price, while if the user is concerned about “distance”, then
the explanation should discuss the distance. Users may also
want to control the features of recommended items, such as
price level, color, and brand [Tanet al. , 2023 ]. For exam-
ple, the user may hope that LLM only recommend items that
fall within a certain price range. Although these features can
be included in the prompt to trigger LLM’s generation, the
recommendations provided by LLM may still fail to meet
the user’s requirements. Current research on the controllabil-
ity of LLM-based recommendation mainly focuses on con-trolling the explanations [Liet al. , 2021; Li et al. , 2023b;
Geng et al. , 2022c ], while more research is urgently needed
on controlling recommendations generated by LLM.
5.5 Inference Efficiency
As LLM contain a huge amount of parameters and RS are
a latency-sensitive application, the efficiency of LLM-based
recommendation models is vital. The training efficiency can
be improved by either option tuning [Cuiet al. , 2022 ]or
adapter tuning [Geng et al. , 2023 ]. To reduce LLM’s train-
ing time, [Liet al. , 2023c ]propose a task-alternative training
strategy to deal with multiple recommendation tasks. Since
the training efficiency of LLM can be improved in an of-
fline environment and usually an LLM does not have to be
retrained too frequently, it is not as important as the inference
efficiency problem. [Cuiet al. , 2022 ]pre-compute the first
few layers of an LLM and cache the results to improve its in-
ference efficiency. However, this strategy may only be appli-
cable to a specific LLM architecture that represents users and
items with metadata. [Liet al. , 2023c ]observe that LLM’s in-
ference time can be slightly reduced when the discrete prompt
is removed. In summary, there is still much room to further
improve the inference efficiency of LLM-based recommen-
dation models.
5.6 Multimodal Recommendation
In addition to text, data of other modalities can also be lever-
aged by LLM, as long as they can be represented as a se-
quence of tokens that can be integrated into textual sentences.
[Geng et al. , 2023 ]incorporate item images into an LLM to
improve its performance on recommendation tasks. Regard-
ing image generation, [Geng et al. , 2022a ]generate visual ex-
planations for recommendations based on a vision-language
model, and [Cuiet al. , 2022 ]synthesize images for product
design. In addition to images, videos and audios can also be
generated in an auto-regressive way [Rubenstein et al. , 2023;
Yanet al. , 2021 ], which makes LLM-based multimodal rec-
ommendation a promising direction. Furthermore, when
there is no available item that caters to a user’s interest in
the item repository, the system can directly create new items.
Meanwhile, model designers should guarantee the authentic-
ity of machine-generated content to prevent users from hav-
ing negative experiences, e.g., a picture of Hawaiian attrac-
tion captioned South Korea.
5.7 Cold-start Recommendation
As LLM have learned world knowledge during the pre-
training stage, they are able to perform recommendation tasks
even if they are not fine-tuned on recommendation-specific
datasets. A typical example is ChatGPT, which can be in-
structed to perform various recommendation tasks as dis-
cussed in the previous section [Liuet al. , 2023a ]. The under-
lying reason is that users’ preferences and items’ attributes
can be expressed in natural language. As a result, LLM-
based recommendation models have the potential to mitigate
the well-known cold-start problem in recommendation when
there is limited or even no interaction regarding new users
or new items. Although the interaction data is insufficient,
we may still make use of their metadata for recommendation,such as user demographic information and item description
information.
6 Conclusions
In this survey, we have reviewed the recent progress of LLM-
based generative recommendation and provided a general for-
mulation for each generative recommendation task according
to relevant research. To encourage researchers to explore this
promising direction, we have elaborated on its advantages
compared to traditional RS, generalized the definition of IDs,
and summarized various ID creation methods. We have also
pointed out several future prospects that might be worth in-
depth exploration. We anticipate a future where LLM and RS
would be nicely integrated to create personalized services of
high quality for users in a variety of situations.
References
[Azamfirei et al. , 2023 ]Razvan Azamfirei, Sapna R Kud-
chadkar, and James Fackler. Large language models and
the perils of their hallucinations. Critical Care , 27(1):1–2,
2023.
[Baoet al. , 2023a ]Keqin Bao, Jizhi Zhang, Wenjie Wang,
Yang Zhang, Zhengyi Yang, Yancheng Luo, Fuli Feng, Xi-
angnaan He, and Qi Tian. A bi-step grounding paradigm
for large language models in recommendation systems.
arXiv preprint arXiv:2308.08434 , 2023.
[Baoet al. , 2023b ]Keqin Bao, Jizhi Zhang, Yang Zhang,
Wenjie Wang, Fuli Feng, and Xiangnan He. Tallrec: An
effective and efficient tuning framework to align large
language model with recommendation. arXiv preprint
arXiv:2305.00447 , 2023.
[Chen et al. , 2019 ]Xu Chen, Hanxiong Chen, Hongteng Xu,
Yongfeng Zhang, Yixin Cao, Zheng Qin, and Hongyuan
Zha. Personalized fashion recommendation with visual
explanations based on multimodal attention network: To-
wards visually explainable recommendation. In Proceed-
ings of the 42nd International ACM SIGIR Conference
on Research and Development in Information Retrieval ,
pages 765–774, 2019.
[Chen et al. , 2023 ]Jin Chen, Zheng Liu, Xu Huang, Chen-
wang Wu, Qi Liu, Gangwei Jiang, Yuanhao Pu, Yux-
uan Lei, Xiaolong Chen, Xingmei Wang, et al. When
large language models meet personalization: Perspec-
tives of challenges and opportunities. arXiv preprint
arXiv:2307.16376 , 2023.
[Chen, 2023 ]Zheng Chen. Palr: Personalization aware llms
for recommendation. In Gen-IR@SIGIR 2023: The First
Workshop on Generative Information Retrieval , 2023.
[Colas et al. , 2023 ]Anthony Colas, Jun Araki, Zhengyu
Zhou, Bingqing Wang, and Zhe Feng. Knowledge-
grounded natural language recommendation explanation.
arXiv preprint arXiv:2308.15813 , 2023.
[Covington et al. , 2016 ]Paul Covington, Jay Adams, and
Emre Sargin. Deep neural networks for youtube recom-
mendations. In Proceedings of the 10th ACM conference
on recommender systems , pages 191–198, 2016.[Cuiet al. , 2022 ]Zeyu Cui, Jianxin Ma, Chang Zhou, Jin-
gren Zhou, and Hongxia Yang. M6-rec: Generative pre-
trained language models are open-ended recommender
systems. arXiv preprint arXiv:2205.08084 , 2022.
[Daiet al. , 2023 ]Sunhao Dai, Ninglu Shao, Haiyuan Zhao,
Weijie Yu, Zihua Si, Chen Xu, Zhongxiang Sun, Xiao
Zhang, and Jun Xu. Uncovering chatgpt’s capabilities in
recommender systems. In Proceedings of the 17th ACM
Conference on Recommender Systems , 2023.
[Devlin et al. , 2019 ]Jacob Devlin, Ming-Wei Chang, Ken-
ton Lee, and Kristina Toutanova. Bert: Pre-training of
deep bidirectional transformers for language understand-
ing. In 2019 Annual Conference of the North American
Chapter of the Association for Computational Linguistics ,
2019.
[Fanet al. , 2023 ]Wenqi Fan, Zihuai Zhao, Jiatong Li, Yun-
qing Liu, Xiaowei Mei, Yiqi Wang, Jiliang Tang, and Qing
Li. Recommender systems in the era of large language
models (llms). arXiv preprint arXiv:2307.02046 , 2023.
[Friedman et al. , 2023 ]Luke Friedman, Sameer Ahuja,
David Allen, Terry Tan, Hakim Sidahmed, Changbo Long,
Jun Xie, Gabriel Schubiner, Ajay Patel, Harsh Lara, et al.
Leveraging large language models in conversational rec-
ommender systems. arXiv preprint arXiv:2305.07961 ,
2023.
[Gaoet al. , 2023 ]Yunfan Gao, Tao Sheng, Youlin Xiang,
Yun Xiong, Haofen Wang, and Jiawei Zhang. Chat-
rec: Towards interactive and explainable llms-augmented
recommender system. arXiv preprint arXiv:2303.14524 ,
2023.
[Geng et al. , 2022a ]Shijie Geng, Zuohui Fu, Yingqiang Ge,
Lei Li, Gerard De Melo, and Yongfeng Zhang. Improving
personalized explanation generation through visualization.
InProceedings of the 60th Annual Meeting of the Associ-
ation for Computational Linguistics (Volume 1: Long Pa-
pers) , pages 244–255, 2022.
[Geng et al. , 2022b ]Shijie Geng, Zuohui Fu, Juntao Tan,
Yingqiang Ge, Gerard De Melo, and Yongfeng Zhang.
Path language modeling over knowledge graphsfor ex-
plainable recommendation. In Proceedings of the ACM
Web Conference 2022 , pages 946–955, 2022.
[Geng et al. , 2022c ]Shijie Geng, Shuchang Liu, Zuohui Fu,
Yingqiang Ge, and Yongfeng Zhang. Recommendation as
language processing (rlp): A unified pretrain, personalized
prompt & predict paradigm (p5). In Sixteenth ACM Con-
ference on Recommender Systems , 2022.
[Geng et al. , 2023 ]Shijie Geng, Juntao Tan, Shuchang Liu,
Zuohui Fu, and Yongfeng Zhang. Vip5: Towards mul-
timodal foundation models for recommendation. arXiv
preprint arXiv:2305.14302 , 2023.
[Heet al. , 2023 ]Zhankui He, Zhouhang Xie, Rahul
Jha, Harald Steck, Dawen Liang, Yesu Feng, Bod-
hisattwa Prasad Majumder, Nathan Kallus, and Julian
McAuley. Large language models as zero-shot conversa-
tional recommenders. In Proceedings of the 32nd ACMInternational Conference on Information & Knowledge
Management , 2023.
[Hou et al. , 2023a ]Yupeng Hou, Zhankui He, Julian
McAuley, and Wayne Xin Zhao. Learning vector-
quantized item representation for transferable sequential
recommenders. In Proceedings of the ACM Web Confer-
ence 2023 , pages 1162–1171, 2023.
[Hou et al. , 2023b ]Yupeng Hou, Junjie Zhang, Zihan
Lin, Hongyu Lu, Ruobing Xie, Julian McAuley, and
Wayne Xin Zhao. Large language models are zero-
shot rankers for recommender systems. arXiv preprint
arXiv:2305.08845 , 2023.
[Huaet al. , 2023a ]Wenyue Hua, Yingqiang Ge, Shuyuan
Xu, Jianchao Ji, and Yongfeng Zhang. Up5: Unbi-
ased foundation model for fairness-aware recommenda-
tion. arXiv preprint arXiv:2305.12090 , 2023.
[Huaet al. , 2023b ]Wenyue Hua, Shuyuan Xu, Yingqiang
Ge, and Yongfeng Zhang. How to index item ids
for recommendation foundation models. arXiv preprint
arXiv:2305.06569 , 2023.
[Jannach et al. , 2021 ]Dietmar Jannach, Ahtsham Manzoor,
Wanling Cai, and Li Chen. A survey on conversational
recommender systems. ACM Computing Surveys (CSUR) ,
54(5):1–36, 2021.
[Jegou et al. , 2010 ]Herve Jegou, Matthijs Douze, and
Cordelia Schmid. Product quantization for nearest neigh-
bor search. IEEE transactions on pattern analysis and ma-
chine intelligence , 33(1):117–128, 2010.
[Jiet al. , 2023 ]Jianchao Ji, Zelong Li, Shuyuan Xu, Wenyue
Hua, Yingqiang Ge, Juntao Tan, and Yongfeng Zhang.
Genrec: Large language model for generative recommen-
dation. arXiv preprint arXiv:2307.00457 , 2023.
[Liet al. , 2020 ]Lei Li, Yongfeng Zhang, and Li Chen. Gen-
erate neural template explanations for recommendation. In
Proceedings of the 29th ACM International Conference on
Information & Knowledge Management , pages 755–764,
2020.
[Liet al. , 2021 ]Lei Li, Yongfeng Zhang, and Li Chen. Per-
sonalized transformer for explainable recommendation. In
Proceedings of the 59th Annual Meeting of the Association
for Computational Linguistics , pages 4947–4957, 2021.
[Liet al. , 2023a ]Jinming Li, Wentao Zhang, Tian Wang,
Guanglei Xiong, Alan Lu, and Gerard Medioni. Gpt4rec:
A generative framework for personalized recommenda-
tion and user interests interpretation. arXiv preprint
arXiv:2304.03879 , 2023.
[Liet al. , 2023b ]Lei Li, Yongfeng Zhang, and Li Chen. Per-
sonalized prompt learning for explainable recommenda-
tion. ACM Transactions on Information Systems , 41(4):1–
26, 2023.
[Liet al. , 2023c ]Lei Li, Yongfeng Zhang, and Li Chen.
Prompt distillation for efficient llm-based recommenda-
tion. In Proceedings of the 32nd ACM International Con-
ference on Information & Knowledge Management , 2023.[Liet al. , 2023d ]Ruyu Li, Wenhao Deng, Yu Cheng, Zheng
Yuan, Jiaqi Zhang, and Fajie Yuan. Exploring the upper
limits of text-based collaborative filtering using large lan-
guage models: Discoveries and insights. arXiv preprint
arXiv:2305.11700 , 2023.
[Liet al. , 2023e ]Xinyi Li, Yongfeng Zhang, and Edward C
Malthouse. Pbnr: Prompt-based news recommender sys-
tem. arXiv preprint arXiv:2304.07862 , 2023.
[Liet al. , 2023f ]Xinyi Li, Yongfeng Zhang, and Edward C
Malthouse. A preliminary study of chatgpt on news
recommendation: Personalization, provider fairness, fake
news. arXiv preprint arXiv:2306.10702 , 2023.
[Lin and Zhang, 2023 ]Guo Lin and Yongfeng Zhang.
Sparks of artificial general recommender (agr): Early ex-
periments with chatgpt. Algorithms , 2023.
[Linet al. , 2023a ]Jianghao Lin, Xinyi Dai, Yunjia Xi, Wei-
wen Liu, Bo Chen, Xiangyang Li, Chenxu Zhu, Huifeng
Guo, Yong Yu, Ruiming Tang, et al. How can recom-
mender systems benefit from large language models: A
survey. arXiv preprint arXiv:2306.05817 , 2023.
[Linet al. , 2023b ]Jianghao Lin, Rong Shan, Chenxu Zhu,
Kounianhua Du, Bo Chen, Shigang Quan, Ruiming Tang,
Yong Yu, and Weinan Zhang. Rella: Retrieval-enhanced
large language models for lifelong sequential behav-
ior comprehension in recommendation. arXiv preprint
arXiv:2308.11131 , 2023.
[Lin, 2004 ]Chin-Yew Lin. Rouge: A package for automatic
evaluation of summaries. In Text summarization branches
out, pages 74–81, 2004.
[Liuet al. , 2023a ]Junling Liu, Chao Liu, Renjie Lv, Kang
Zhou, and Yan Zhang. Is chatgpt a good recommender?
a preliminary study. arXiv preprint arXiv:2304.10149 ,
2023.
[Liuet al. , 2023b ]Junling Liu, Chao Liu, Peilin Zhou,
Qichen Ye, Dading Chong, Kang Zhou, Yueqi Xie, Yuwei
Cao, Shoujin Wang, Chenyu You, et al. Llmrec: Bench-
marking large language models on recommendation task.
arXiv preprint arXiv:2308.12241 , 2023.
[Liuet al. , 2023c ]Peng Liu, Lemei Zhang, and Jon Atle
Gulla. Pre-train, prompt and recommendation: A
comprehensive survey of language modelling paradigm
adaptations in recommender systems. arXiv preprint
arXiv:2302.03735 , 2023.
[Liuet al. , 2023d ]Pengfei Liu, Weizhe Yuan, Jinlan Fu,
Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig.
Pre-train, prompt, and predict: A systematic survey of
prompting methods in natural language processing. ACM
Computing Surveys , 55(9):1–35, 2023.
[Mialon et al. , 2023 ]Gr´egoire Mialon, Roberto Dess `ı, Maria
Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta
Raileanu, Baptiste Rozi `ere, Timo Schick, Jane Dwivedi-
Yu, Asli Celikyilmaz, et al. Augmented language models:
a survey. arXiv preprint arXiv:2302.07842 , 2023.[Papineni et al. , 2002 ]Kishore Papineni, Salim Roukos,
Todd Ward, and Wei-Jing Zhu. Bleu: a method for au-
tomatic evaluation of machine translation. In Proceedings
of the 40th annual meeting of the Association for Compu-
tational Linguistics , pages 311–318, 2002.
[Parra and Brusilovsky, 2015 ]Denis Parra and Peter
Brusilovsky. User-controllable personalization: A
case study with setfusion. International Journal of
Human-Computer Studies , 78:43–67, 2015.
[Petrov and Macdonald, 2023 ]Aleksandr V Petrov and
Craig Macdonald. Generative sequential recommendation
with gptrec. In Gen-IR@SIGIR 2023: The First Workshop
on Generative Information Retrieval , 2023.
[Rubenstein et al. , 2023 ]Paul K Rubenstein, Chulayuth
Asawaroengchai, Duc Dung Nguyen, Ankur Bapna, Zal ´an
Borsos, F ´elix de Chaumont Quitry, Peter Chen, Dalia El
Badawy, Wei Han, Eugene Kharitonov, et al. Audiopalm:
A large language model that can speak and listen. arXiv
preprint arXiv:2306.12925 , 2023.
[Schafer et al. , 2002 ]J Ben Schafer, Joseph A Konstan,
and John Riedl. Meta-recommendation systems: user-
controlled integration of diverse recommendations. In Pro-
ceedings of the eleventh international conference on Infor-
mation and knowledge management , pages 43–51, 2002.
[Sun and Zhang, 2018 ]Yueming Sun and Yi Zhang. Conver-
sational recommender system. In The 41st international
acm sigir conference on research & development in infor-
mation retrieval , pages 235–244, 2018.
[Tanet al. , 2023 ]Juntao Tan, Yingqiang Ge, Yan Zhu, Yin-
glong Xia, Jiebo Luo, Jianchao Ji, and Yongfeng Zhang.
User-controllable recommendation via counterfactual ret-
rospective and prospective explanations. ECAI , 2023.
[Vaswani et al. , 2017 ]Ashish Vaswani, Noam Shazeer, Niki
Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Łukasz Kaiser, and Illia Polosukhin. Attention is all you
need. In Advances in neural information processing sys-
tems, 2017.
[V on Luxburg, 2007 ]Ulrike V on Luxburg. A tutorial on
spectral clustering. Statistics and computing , 17:395–416,
2007.
[Wang and Lim, 2023 ]Lei Wang and Ee-Peng Lim. Zero-
shot next-item recommendation using large pretrained lan-
guage models. arXiv preprint arXiv:2304.03153 , 2023.
[Wang et al. , 2022a ]Nan Wang, Shaoliang Nie, Qifan Wang,
Yi-Chia Wang, Maziar Sanjabi, Jingzhou Liu, Hamed
Firooz, and Hongning Wang. Coffee: Counterfactual fair-
ness for personalized text generation in explainable rec-
ommendation. arXiv preprint arXiv:2210.15500 , 2022.
[Wang et al. , 2022b ]Wenjie Wang, Fuli Feng, Liqiang Nie,
and Tat-Seng Chua. User-controllable recommendation
against filter bubbles. In Proceedings of the 45th Inter-
national ACM SIGIR Conference on Research and Devel-
opment in Information Retrieval , pages 1251–1261, 2022.
[Wang et al. , 2023a ]Xiaolei Wang, Xinyu Tang, Wayne Xin
Zhao, Jingyuan Wang, and Ji-Rong Wen. Rethinking theevaluation for conversational recommendation in the era of
large language models. arXiv preprint arXiv:2305.13112 ,
2023.
[Wang et al. , 2023b ]Yancheng Wang, Ziyan Jiang, Zheng
Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan,
Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang. Rec-
mind: Large language model powered agent for recom-
mendation. arXiv preprint arXiv:2308.14296 , 2023.
[Wuet al. , 2023 ]Likang Wu, Zhi Zheng, Zhaopeng Qiu,
Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen
Zhu, Hengshu Zhu, Qi Liu, et al. A survey on large
language models for recommendation. arXiv preprint
arXiv:2305.19860 , 2023.
[Xuet al. , 2023 ]Shuyuan Xu, Wenyue Hua, and Yongfeng
Zhang. Openp5: Benchmarking foundation models for
recommendation. arXiv preprint arXiv:2306.11134 , 2023.
[Yanet al. , 2021 ]Wilson Yan, Yunzhi Zhang, Pieter Abbeel,
and Aravind Srinivas. Videogpt: Video genera-
tion using vq-vae and transformers. arXiv preprint
arXiv:2104.10157 , 2021.
[Yeet al. , 2023 ]Ruosong Ye, Caiqi Zhang, Runhui Wang,
Shuyuan Xu, and Yongfeng Zhang. Natural language is
all a graph needs. arXiv preprint arXiv:2308.07134 , 2023.
[Zhang et al. , 2014 ]Yongfeng Zhang, Guokun Lai, Min
Zhang, Yi Zhang, Yiqun Liu, and Shaoping Ma. Explicit
factor models for explainable recommendation based on
phrase-level sentiment analysis. In Proceedings of the 37th
international ACM SIGIR conference on Research & de-
velopment in information retrieval , pages 83–92, 2014.
[Zhang et al. , 2018 ]Yongfeng Zhang, Xu Chen, Qingyao
Ai, Liu Yang, and W Bruce Croft. Towards conversational
search and recommendation: System ask, user respond. In
Proceedings of the 27th acm international conference on
information and knowledge management , pages 177–186,
2018.
[Zhang et al. , 2019 ]Tianyi Zhang, Varsha Kishore, Felix
Wu, Kilian Q Weinberger, and Yoav Artzi. Bertscore:
Evaluating text generation with bert. arXiv preprint
arXiv:1904.09675 , 2019.
[Zhang et al. , 2020 ]Yongfeng Zhang, Xu Chen, et al. Ex-
plainable recommendation: A survey and new perspec-
tives. Foundations and Trends® in Information Retrieval ,
14(1):1–101, 2020.
[Zhang et al. , 2021 ]Yuhui Zhang, Hao Ding, Zeren Shui,
Yifei Ma, James Zou, Anoop Deoras, and Hao Wang. Lan-
guage models as recommender systems: Evaluations and
limitations. In NeurIPS 2021 Workshop ICBINB , 2021.
[Zhang et al. , 2023a ]Jizhi Zhang, Keqin Bao, Yang Zhang,
Wenjie Wang, Fuli Feng, and Xiangnan He. Is chat-
gpt fair for recommendation? evaluating fairness in
large language model recommendation. arXiv preprint
arXiv:2305.07609 , 2023.
[Zhang et al. , 2023b ]Junjie Zhang, Ruobing Xie, Yupeng
Hou, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. Rec-
ommendation as instruction following: A large languagemodel empowered recommendation approach. arXiv
preprint arXiv:2305.07001 , 2023.
[Zhiyuli et al. , 2023 ]Aakas Zhiyuli, Yanfang Chen, Xuan
Zhang, and Xun Liang. Bookgpt: A general framework
for book recommendation empowered by large language
model. arXiv preprint arXiv:2305.15673 , 2023.