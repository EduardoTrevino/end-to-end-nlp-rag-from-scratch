{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade --quiet  langchain langchain-community langchainhub gpt4all chromadb \n",
    "# !pip3 install sentence-transformers\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "\n",
    "with open('final_final.pkl','rb') as f: \n",
    "  all_splits = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDB(persistantName, embeddingFunction):\n",
    "    for i in all_splits:\n",
    "        vectorstore = Chroma.from_documents(documents=i, embedding=embeddingFunction, persist_directory=persistantName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT4AllEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createDB(\"all-MiniLM-L6-v2\", GPT4AllEmbeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "createDB(\"all-MiniLM-L6-v2\", embedding_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model_name = \"Salesforce/SFR-Embedding-Mistral\"\n",
    "# model_kwargs = {\"device\": \"cuda\"}\n",
    "# embedding_function = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "\n",
    "# import chromadb.utils.embedding_functions as embedding_functions\n",
    "# huggingface_ef = embedding_functions.HuggingFaceEmbeddingFunction(\n",
    "#     model_name=\"BAAI/llm-embedder\"\n",
    "# )\n",
    "\n",
    "model_name = \"BAAI/llm-embedder\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "\n",
    "createDB(\"llm-embedder\", embedding_function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
