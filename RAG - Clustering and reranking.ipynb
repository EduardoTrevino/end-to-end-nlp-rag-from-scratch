{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.embeddings import JinaEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "\n",
    "with open('splitDocuments.pkl','rb') as f: \n",
    "  all_splits = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\"Academic\": [0],\n",
    "          \"LTI\": [7, 8, 9],\n",
    "          \"Calendar\": [3],\n",
    "          \"Facts\": [1, 2, 4, 5, 6, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "for i in groups:\n",
    "    for j in groups[i]:\n",
    "        vectorstore = Chroma.from_documents(documents=all_splits[j], embedding=embedding_function, persist_directory=\"{}DB/\".format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.retrievers import BaseRetriever, RetrieverLike, RetrieverOutputLike\n",
    "from langchain_core.language_models import BaseLLM\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "class CustomRetriever(BaseRetriever):\n",
    "  \n",
    "\n",
    "    # vectorstore = Chroma(persist_directory=\"llm-embedder\", embedding_function=embeddings)\n",
    "    # model = SentenceTransformer('BAAI/bge-reranker-base')\n",
    "\n",
    "    vectorstore : List[RetrieverLike]\n",
    "    model : transformers.models.bert.modeling_bert.BertModel\n",
    "    tokenizer : transformers.models.bert.tokenization_bert_fast.BertTokenizerFast\n",
    "\n",
    "    def maxsim(self, query_embedding, document_embedding):\n",
    "        expanded_query = query_embedding.unsqueeze(2)\n",
    "        expanded_doc = document_embedding.unsqueeze(1)\n",
    "    \n",
    "        sim_matrix = torch.nn.functional.cosine_similarity(expanded_query, expanded_doc, dim=-1)\n",
    "        max_sim_scores, _ = torch.max(sim_matrix, dim=2)    \n",
    "        avg_max_sim = torch.mean(max_sim_scores, dim=1)\n",
    "        return avg_max_sim\n",
    "    \n",
    "    def flatten_extend(self, matrix):\n",
    "        flat_list = []\n",
    "        for row in matrix:\n",
    "            flat_list.extend(row)\n",
    "        return flat_list\n",
    "\n",
    "    def _get_relevant_documents(self, query: str, *, run_manager: CallbackManagerForRetrieverRun) -> List[Document]:\n",
    "\n",
    "        all_docs = []\n",
    "        for i in self.vectorstore:\n",
    "            all_docs.append(i.get_relevant_documents(query, k=3))\n",
    "\n",
    "        all_docs = self.flatten_extend(all_docs)\n",
    "\n",
    "        query_encoding = self.tokenizer(query, return_tensors='pt')\n",
    "        query_embedding = self.model(**query_encoding).last_hidden_state.mean(dim=1)\n",
    "\n",
    "        scores = []\n",
    "        for document in all_docs:\n",
    "            document_encoding = self.tokenizer(document.page_content, return_tensors='pt', truncation=True, max_length=512)\n",
    "            document_embedding = self.model(**document_encoding).last_hidden_state\n",
    "        \n",
    "            score = self.maxsim(query_embedding.unsqueeze(0), document_embedding)\n",
    "            scores.append(score.item())\n",
    "\n",
    "        print(scores)\n",
    "        return [x for _, x in sorted(zip(scores, all_docs), reverse=True)]\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "model = AutoModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "vectorstores = []\n",
    "for i in groups:\n",
    "    store = Chroma(persist_directory=\"{}DB\".format(i), embedding_function=embedding_function)\n",
    "    vectorstores.append(store.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customRetriever = CustomRetriever(vectorstore=vectorstores, model=model , tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customRetriever.get_relevant_documents('When will the classes begin in the Fall 2024 semester')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
