{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragatouille import RAGPretrainedModel\n",
    "\n",
    "RAG = RAGPretrainedModel.from_pretrained(\"../Data/.ragatouille/colbert/none/2024-03/06/12.27.36/checkpoints/colbert/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Base directory containing your folders\n",
    "base_dir = \"../Data\"\n",
    "\n",
    "# Folders containing your data\n",
    "folders = [\"About Scottie\", \"Buggy News\", \"history_of_cmu\", \"history_of_scs\", \"Kiltie Band\", \"lti_faculty\", \"lti_programs\", \"Tartan Facts\"]\n",
    "\n",
    "# Initialize empty list to hold all document texts\n",
    "collection = []\n",
    "# Optionally, prepare a list for document IDs if you wish to use custom IDs\n",
    "# document_ids = []\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    \n",
    "    # Iterate over each text file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\") and filename != \"annotation.txt\":\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                # Read the document content and add it to the collection\n",
    "                document_text = file.read()\n",
    "                collection.append(document_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(collection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: ninja: command not found\n"
     ]
    }
   ],
   "source": [
    "print(os.system(\"ninja --version\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[K     |████████████████████████████████| 307 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: ninja\n",
      "\u001b[33m  WARNING: The script ninja is installed in '/home/trevea/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed ninja-1.11.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: ninja: command not found\n"
     ]
    }
   ],
   "source": [
    "os.environ['PATH'] += os.pathsep + '~/miniconda3/envs/nlp-rag/bin/ninja'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Mar 07, 09:38:29] #> Note: Output directory .ragatouille/colbert/indexes/colbertv2.0_cmu_lti_finetunev1.0 already exists\n",
      "\n",
      "\n",
      "[Mar 07, 09:38:29] #> Will delete 1 files already at .ragatouille/colbert/indexes/colbertv2.0_cmu_lti_finetunev1.0 in 20 seconds...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "nranks = 4 \t num_gpus = 4 \t device=0\n",
      "[Mar 07, 09:38:53] [0] \t\t #> Encoding 42 passages..\n",
      "nranks = 4 \t num_gpus = 4 \t device=1\n",
      "[Mar 07, 09:38:53] [1] \t\t #> Encoding 42 passages..\n",
      "nranks = 4 \t num_gpus = 4 \t device=2\n",
      "[Mar 07, 09:38:53] [2] \t\t #> Encoding 42 passages..\n",
      "nranks = 4 \t num_gpus = 4 \t device=3\n",
      "[Mar 07, 09:38:53] [3] \t\t #> Encoding 40 passages..\n",
      "[Mar 07, 09:38:56] [3] \t\t avg_doclen_est = 121.12440490722656 \t len(local_sample) = 40\n",
      "[Mar 07, 09:38:56] [2] \t\t avg_doclen_est = 121.12440490722656 \t len(local_sample) = 42\n",
      "[Mar 07, 09:38:56] [1] \t\t avg_doclen_est = 121.12440490722656 \t len(local_sample) = 42\n",
      "[Mar 07, 09:38:56] [0] \t\t avg_doclen_est = 121.12440490722656 \t len(local_sample) = 42\n",
      "[Mar 07, 09:38:56] [0] \t\t Creating 2,048 partitions.\n",
      "[Mar 07, 09:38:56] [0] \t\t *Estimated* 20,106 embeddings.\n",
      "[Mar 07, 09:38:56] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/colbertv2.0_cmu_lti_finetunev1.0/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 19097 points to 2048 centroids: please provide at least 79872 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 19097 points in 128D to 2048 clusters, redo 1 times, 20 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 19 (0.17 s, search 0.15 s): objective=3317.33 imbalance=1.510 nsplit=0       \n",
      "[Mar 07, 09:38:58] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/trevea/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/infra/launcher.py\", line 134, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 33, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 68, in run\n",
      "    self.train(shared_lists) # Trains centroids from selected passages\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 237, in train\n",
      "    bucket_cutoffs, bucket_weights, avg_residual = self._compute_avg_residual(centroids, heldout)\n",
      "                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 315, in _compute_avg_residual\n",
      "    compressor = ResidualCodec(config=self.config, centroids=centroids, avg_residual=None)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/codecs/residual.py\", line 24, in __init__\n",
      "    ResidualCodec.try_load_torch_extensions(self.use_gpu)\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/codecs/residual.py\", line 103, in try_load_torch_extensions\n",
      "    decompress_residuals_cpp = load(\n",
      "                               ^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1306, in load\n",
      "    return _jit_compile(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1710, in _jit_compile\n",
      "    _write_ninja_file_and_build_library(\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1793, in _write_ninja_file_and_build_library\n",
      "    verify_ninja_availability()\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1842, in verify_ninja_availability\n",
      "    raise RuntimeError(\"Ninja is required to load C++ extensions\")\n",
      "RuntimeError: Ninja is required to load C++ extensions\n",
      "[rank3]:[E ProcessGroupNCCL.cpp:523] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600170 milliseconds before timing out.\n",
      "[rank3]:[E ProcessGroupNCCL.cpp:537] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "[rank3]:[E ProcessGroupNCCL.cpp:543] To avoid data inconsistency, we are taking the entire process down.\n",
      "[rank3]:[E ProcessGroupNCCL.cpp:1182] [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600170 milliseconds before timing out.\n",
      "Exception raised from checkTimeout at /opt/conda/conda-bld/pytorch_1708025845206/work/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f6e7b2d9d87 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libc10.so)\n",
      "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7f6e7c49e4d6 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7f6e7c4a1a2d in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7f6e7c4a2629 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0xdbbf4 (0x7f6ec7d6ebf4 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/../../../.././libstdc++.so.6)\n",
      "frame #5: <unknown function> + 0x81ca (0x7f6ed0cb51ca in /lib64/libpthread.so.0)\n",
      "frame #6: clone + 0x43 (0x7f6ed0197e73 in /lib64/libc.so.6)\n",
      "\n",
      "[rank2]:[E ProcessGroupNCCL.cpp:523] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600175 milliseconds before timing out.\n",
      "[rank1]:[E ProcessGroupNCCL.cpp:523] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600176 milliseconds before timing out.\n",
      "[rank2]:[E ProcessGroupNCCL.cpp:537] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "[rank2]:[E ProcessGroupNCCL.cpp:543] To avoid data inconsistency, we are taking the entire process down.\n",
      "[rank2]:[E ProcessGroupNCCL.cpp:1182] [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600175 milliseconds before timing out.\n",
      "Exception raised from checkTimeout at /opt/conda/conda-bld/pytorch_1708025845206/work/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f1ca1006d87 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libc10.so)\n",
      "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7f1ca21cb4d6 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7f1ca21cea2d in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7f1ca21cf629 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0xdbbf4 (0x7f1ceda9bbf4 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/../../../.././libstdc++.so.6)\n",
      "frame #5: <unknown function> + 0x81ca (0x7f1cf69e21ca in /lib64/libpthread.so.0)\n",
      "frame #6: clone + 0x43 (0x7f1cf5ec4e73 in /lib64/libc.so.6)\n",
      "\n",
      "[rank1]:[E ProcessGroupNCCL.cpp:537] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "[rank1]:[E ProcessGroupNCCL.cpp:543] To avoid data inconsistency, we are taking the entire process down.\n",
      "[rank1]:[E ProcessGroupNCCL.cpp:1182] [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600176 milliseconds before timing out.\n",
      "Exception raised from checkTimeout at /opt/conda/conda-bld/pytorch_1708025845206/work/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:525 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fac5175ad87 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libc10.so)\n",
      "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e6 (0x7fac5291f4d6 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x19d (0x7fac52922a2d in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x119 (0x7fac52923629 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0xdbbf4 (0x7fac9e1efbf4 in /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/lib/../../../.././libstdc++.so.6)\n",
      "frame #5: <unknown function> + 0x81ca (0x7faca71361ca in /lib64/libpthread.so.0)\n",
      "frame #6: clone + 0x43 (0x7faca6618e73 in /lib64/libc.so.6)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMKL_THREADING_LAYER\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGNU\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolbertv2.0_cmu_lti_finetunev1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m index_path \u001b[38;5;241m=\u001b[39m \u001b[43mRAG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;43;03m#     document_ids=document_ids,  # Include this only if you prepared document IDs\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True to overwrite existing index of the same name\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_document_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m180\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust based on your document length distribution\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True if documents should be split into shorter segments\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/ragatouille/RAGPretrainedModel.py:210\u001b[0m, in \u001b[0;36mRAGPretrainedModel.index\u001b[0;34m(self, collection, document_ids, document_metadatas, index_name, overwrite_index, max_document_length, split_documents, document_splitter_fn, preprocessing_fn, bsize)\u001b[0m\n\u001b[1;32m    201\u001b[0m     document_splitter_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    202\u001b[0m collection, pid_docid_map, docid_metadata_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_corpus(\n\u001b[1;32m    203\u001b[0m     collection,\n\u001b[1;32m    204\u001b[0m     document_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     max_document_length,\n\u001b[1;32m    209\u001b[0m )\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpid_docid_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpid_docid_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocid_metadata_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocid_metadata_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_document_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_document_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/ragatouille/models/colbert.py:368\u001b[0m, in \u001b[0;36mColBERT.index\u001b[0;34m(self, collection, pid_docid_map, docid_metadata_map, index_name, max_document_length, overwrite, bsize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexer \u001b[38;5;241m=\u001b[39m Indexer(\n\u001b[1;32m    363\u001b[0m     checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint,\n\u001b[1;32m    364\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    365\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    366\u001b[0m )\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexer\u001b[38;5;241m.\u001b[39mconfigure(avoid_fork_if_possible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 368\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m    373\u001b[0m     Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mroot)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mexperiment)\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_name\n\u001b[1;32m    377\u001b[0m )\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m    379\u001b[0m     Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mroot) \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mexperiment) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexer.py:80\u001b[0m, in \u001b[0;36mIndexer.index\u001b[0;34m(self, name, collection, overwrite)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merase()\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_does_not_exist \u001b[38;5;129;01mor\u001b[39;00m overwrite \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreuse\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexer.py:98\u001b[0m, in \u001b[0;36mIndexer.__launch\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m     95\u001b[0m shared_queues \u001b[38;5;241m=\u001b[39m [manager\u001b[38;5;241m.\u001b[39mQueue(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnranks)]\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Encodes collection into index using the CollectionIndexer class\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m \u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_queues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/infra/launcher.py:72\u001b[0m, in \u001b[0;36mLauncher.launch\u001b[0;34m(self, custom_config, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m print_memory_stats(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAIN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# TODO: If the processes crash upon join, raise an exception and don't block on .get() below!\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([\u001b[43mreturn_value_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m all_procs])\n\u001b[1;32m     73\u001b[0m return_values \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m rank, val \u001b[38;5;129;01min\u001b[39;00m return_values]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_all:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/connection.py:430\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 430\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/connection.py:395\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "os.environ['COLBERT_LOAD_TORCH_EXTENSION_VERBOSE'] = 'True'\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "index_name = \"colbertv2.0_cmu_lti_finetunev1.0\"\n",
    "index_path = RAG.index(\n",
    "    collection=collection,\n",
    "#     document_ids=document_ids,  # Include this only if you prepared document IDs\n",
    "    index_name=index_name,\n",
    "    overwrite_index=True,  # Set to True to overwrite existing index of the same name\n",
    "    max_document_length=180,  # Adjust based on your document length distribution\n",
    "    split_documents=True,  # Set to True if documents should be split into shorter segments\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-rag",
   "language": "python",
   "name": "nlp-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
