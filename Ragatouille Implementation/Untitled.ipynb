{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragatouille import RAGPretrainedModel\n",
    "\n",
    "RAG = RAGPretrainedModel.from_pretrained(\"../Data/.ragatouille/colbert/none/2024-03/06/12.27.36/checkpoints/colbert/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Base directory containing your folders\n",
    "base_dir = \"../Data\"\n",
    "\n",
    "# Folders containing your data\n",
    "folders = [\"About Scottie\", \"Buggy News\", \"history_of_cmu\", \"history_of_scs\", \"Kiltie Band\", \"lti_faculty\", \"lti_programs\", \"Tartan Facts\"]\n",
    "\n",
    "# Initialize empty list to hold all document texts\n",
    "collection = []\n",
    "# Optionally, prepare a list for document IDs if you wish to use custom IDs\n",
    "# document_ids = []\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    \n",
    "    # Iterate over each text file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\") and filename != \"annotation.txt\":\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                # Read the document content and add it to the collection\n",
    "                document_text = file.read()\n",
    "                collection.append(document_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(collection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: ninja: command not found\n"
     ]
    }
   ],
   "source": [
    "# print(os.system(\"ninja --version\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[K     |████████████████████████████████| 307 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: ninja\n",
      "\u001b[33m  WARNING: The script ninja is installed in '/home/trevea/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed ninja-1.11.1.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['PATH'] += os.pathsep + '~/miniconda3/envs/nlp-rag/bin/ninja'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: ninja: command not found\n"
     ]
    }
   ],
   "source": [
    "# print(os.system(\"ninja --version\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/trevea/miniconda3/envs/nlp-rag/bin/python\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ninja version: 1.10.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import subprocess\n",
    "\n",
    "# ninja_path = '~/miniconda3/envs/nlp-rag/bin/ninja'\n",
    "\n",
    "# try:\n",
    "#     result = subprocess.check_output(f'{ninja_path} --version', shell=True)\n",
    "#     print(\"Ninja version:\", result.decode('utf-8'))\n",
    "# except Exception as e:\n",
    "#     print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH environment variable:\n",
      "/apps/local/anaconda/3.7/bin:/apps/local/anaconda/3.7/condabin:/home/trevea/Cmake_3.25.1/cmake-3.25.1-linux-x86_64/bin:/home/trevea/.cargo/bin:/apps/local/conda/mambaforge/bin:/usr/local/cuda-11.1/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin\n",
      "\n",
      "PATH split into lines:\n",
      "/apps/local/anaconda/3.7/bin\n",
      "/apps/local/anaconda/3.7/condabin\n",
      "/home/trevea/Cmake_3.25.1/cmake-3.25.1-linux-x86_64/bin\n",
      "/home/trevea/.cargo/bin\n",
      "/apps/local/conda/mambaforge/bin\n",
      "/usr/local/cuda-11.1/bin\n",
      "/usr/local/bin\n",
      "/usr/bin\n",
      "/usr/local/sbin\n",
      "/usr/sbin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Get the PATH environment variable\n",
    "# path_variable = os.environ.get('PATH')\n",
    "\n",
    "# # Print the PATH variable\n",
    "# print(\"PATH environment variable:\")\n",
    "# print(path_variable)\n",
    "\n",
    "# # To make it more readable, you can split it into separate lines\n",
    "# print(\"\\nPATH split into lines:\")\n",
    "# for path in path_variable.split(os.pathsep):\n",
    "#     print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PATH split into lines after modification:\n",
      "/home/trevea/miniconda3/envs/nlp-rag/bin\n",
      "/apps/local/anaconda/3.7/bin\n",
      "/apps/local/anaconda/3.7/condabin\n",
      "/home/trevea/Cmake_3.25.1/cmake-3.25.1-linux-x86_64/bin\n",
      "/home/trevea/.cargo/bin\n",
      "/apps/local/conda/mambaforge/bin\n",
      "/usr/local/cuda-11.1/bin\n",
      "/usr/local/bin\n",
      "/usr/bin\n",
      "/usr/local/sbin\n",
      "/usr/sbin\n"
     ]
    }
   ],
   "source": [
    "# Assuming ninja_path is the directory containing Ninja\n",
    "ninja_path = '/home/trevea/miniconda3/envs/nlp-rag/bin'  # Use full path\n",
    "\n",
    "# Append this directory to the PATH variable\n",
    "os.environ['PATH'] = ninja_path + os.pathsep + os.environ['PATH']\n",
    "\n",
    "# Verify the change\n",
    "print(\"\\nPATH split into lines after modification:\")\n",
    "for path in os.environ.get('PATH').split(os.pathsep):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PATH split into lines after removal:\n",
      "/home/trevea/miniconda3/envs/nlp-rag/bin\n",
      "/apps/local/anaconda/3.7/bin\n",
      "/apps/local/anaconda/3.7/condabin\n",
      "/home/trevea/Cmake_3.25.1/cmake-3.25.1-linux-x86_64/bin\n",
      "/home/trevea/.cargo/bin\n",
      "/apps/local/conda/mambaforge/bin\n",
      "/usr/local/cuda-11.1/bin\n",
      "/usr/local/bin\n",
      "/usr/bin\n",
      "/usr/local/sbin\n",
      "/usr/sbin\n"
     ]
    }
   ],
   "source": [
    "# # Get the current PATH\n",
    "# path_variable = os.environ.get('PATH')\n",
    "\n",
    "# # Split the PATH into a list for easier manipulation\n",
    "# path_list = path_variable.split(os.pathsep)\n",
    "\n",
    "# # The incorrect path to remove (use the full expanded path if necessary)\n",
    "# incorrect_path = '~/miniconda3/envs/nlp-rag/bin/ninja'  # This might need to be expanded to the absolute path\n",
    "\n",
    "# # Ensure the incorrect path is expanded properly (especially important for '~')\n",
    "# home_directory = os.path.expanduser('~')\n",
    "# incorrect_path_expanded = incorrect_path.replace('~', home_directory)\n",
    "\n",
    "# # Remove the incorrect path from the list, if it exists\n",
    "# # This step is necessary as the path in the environment variable may not contain the '~' expanded\n",
    "# path_list = [p for p in path_list if p != incorrect_path and p != incorrect_path_expanded]\n",
    "\n",
    "# # Join the list back into a string to update the PATH variable\n",
    "# new_path_variable = os.pathsep.join(path_list)\n",
    "\n",
    "# # Set the updated PATH back into the environment\n",
    "# os.environ['PATH'] = new_path_variable\n",
    "\n",
    "# # Verify the change\n",
    "# print(\"\\nPATH split into lines after removal:\")\n",
    "# for path in os.environ.get('PATH').split(os.pathsep):\n",
    "#     print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(os.system(\"ninja --version\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Mar 07, 10:37:43] #> Note: Output directory .ragatouille/colbert/indexes/colbertv2.0_cmu_lti_finetunev1.0 already exists\n",
      "\n",
      "\n",
      "[Mar 07, 10:37:43] #> Will delete 1 files already at .ragatouille/colbert/indexes/colbertv2.0_cmu_lti_finetunev1.0 in 20 seconds...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "nranks = 4 \t num_gpus = 4 \t device=3\n",
      "[Mar 07, 10:38:08] [3] \t\t #> Encoding 40 passages..\n",
      "nranks = 4 \t num_gpus = 4 \t device=1\n",
      "[Mar 07, 10:38:08] [1] \t\t #> Encoding 42 passages..\n",
      "nranks = 4 \t num_gpus = 4 \t device=2\n",
      "[Mar 07, 10:38:08] [2] \t\t #> Encoding 42 passages..\n",
      "nranks = 4 \t num_gpus = 4 \t device=0\n",
      "[Mar 07, 10:38:08] [0] \t\t #> Encoding 42 passages..\n",
      "[Mar 07, 10:38:11] [0] \t\t avg_doclen_est = 121.12440490722656 \t len(local_sample) = 42\n",
      "[Mar 07, 10:38:11] [3] \t\t avg_doclen_est = 121.12440490722656 \t len(local_sample) = 40\n",
      "[Mar 07, 10:38:11] [2] \t\t avg_doclen_est = 121.12440490722656 \t len(local_sample) = 42\n",
      "[Mar 07, 10:38:11] [1] \t\t avg_doclen_est = 121.12440490722656 \t len(local_sample) = 42\n",
      "[Mar 07, 10:38:11] [0] \t\t Creating 2,048 partitions.\n",
      "[Mar 07, 10:38:11] [0] \t\t *Estimated* 20,106 embeddings.\n",
      "[Mar 07, 10:38:11] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/colbertv2.0_cmu_lti_finetunev1.0/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 19097 points to 2048 centroids: please provide at least 79872 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 19097 points in 128D to 2048 clusters, redo 1 times, 20 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 19 (0.16 s, search 0.15 s): objective=3317.33 imbalance=1.510 nsplit=0       \n",
      "[Mar 07, 10:38:13] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/trevea/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/trevea/.cache/torch_extensions/py312_cu121/decompress_residuals_cpp/build.ninja...\n",
      "Building extension module decompress_residuals_cpp...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] /usr/local/cuda-11.1/bin/nvcc --generate-dependencies-with-compile --dependency-output decompress_residuals.cuda.o.d -DTORCH_EXTENSION_NAME=decompress_residuals_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include -isystem /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/TH -isystem /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/THC -isystem /usr/local/cuda-11.1/include -isystem /home/trevea/miniconda3/envs/nlp-rag/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -std=c++17 -c /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/codecs/decompress_residuals.cu -o decompress_residuals.cuda.o \n",
      "\u001b[31mFAILED: \u001b[0mdecompress_residuals.cuda.o \n",
      "/usr/local/cuda-11.1/bin/nvcc --generate-dependencies-with-compile --dependency-output decompress_residuals.cuda.o.d -DTORCH_EXTENSION_NAME=decompress_residuals_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include -isystem /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/TH -isystem /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/THC -isystem /usr/local/cuda-11.1/include -isystem /home/trevea/miniconda3/envs/nlp-rag/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -std=c++17 -c /home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/codecs/decompress_residuals.cu -o decompress_residuals.cuda.o \n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h(91): error: no suitable user-defined conversion from \"torch::jit::Operator::UnparsedFunctionSchema\" to \"std::variant<c10::FunctionSchema, torch::jit::Operator::UnparsedFunctionSchema>\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h(92): error: no suitable user-defined conversion from \"torch::jit::Operation\" to \"std::variant<torch::jit::Operation, torch::jit::OperationCreator>\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h(95): error: no suitable user-defined conversion from \"const torch::enumtype::kZeros\" to \"torch::nn::detail::conv_padding_mode_t\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h(210): error: no suitable constructor exists to convert from \"int\" to \"std::variant<torch::ExpandingArray<1UL, int64_t>, torch::enumtype::kValid, torch::enumtype::kSame>\"\n",
      "          detected during:\n",
      "            implicit generation of \"torch::nn::functional::ConvFuncOptions<D>::ConvFuncOptions() [with D=1UL]\" \n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/conv.h(59): here\n",
      "            instantiation of class \"torch::nn::functional::ConvFuncOptions<D> [with D=1UL]\" \n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/conv.h(59): here\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h(210): error: no suitable constructor exists to convert from \"int\" to \"std::variant<torch::ExpandingArray<2UL, int64_t>, torch::enumtype::kValid, torch::enumtype::kSame>\"\n",
      "          detected during:\n",
      "            implicit generation of \"torch::nn::functional::ConvFuncOptions<D>::ConvFuncOptions() [with D=2UL]\" \n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/conv.h(105): here\n",
      "            instantiation of class \"torch::nn::functional::ConvFuncOptions<D> [with D=2UL]\" \n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/conv.h(105): here\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/conv.h(210): error: no suitable constructor exists to convert from \"int\" to \"std::variant<torch::ExpandingArray<3UL, int64_t>, torch::enumtype::kValid, torch::enumtype::kSame>\"\n",
      "          detected during:\n",
      "            implicit generation of \"torch::nn::functional::ConvFuncOptions<D>::ConvFuncOptions() [with D=3UL]\" \n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/conv.h(151): here\n",
      "            instantiation of class \"torch::nn::functional::ConvFuncOptions<D> [with D=3UL]\" \n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/conv.h(151): here\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/embedding.h(134): error: no suitable user-defined conversion from \"const torch::enumtype::kMean\" to \"torch::nn::EmbeddingBagMode\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/loss.h(24): error: no suitable user-defined conversion from \"const torch::enumtype::kMean\" to \"torch::nn::L1LossOptions::reduction_t\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/loss.h(68): error: no suitable user-defined conversion from \"const torch::enumtype::kMean\" to \"torch::nn::KLDivLossOptions::reduction_t\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/padding.h(210): error: no suitable user-defined conversion from \"const torch::enumtype::kConstant\" to \"torch::nn::functional::PadFuncOptions::mode_t\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/upsampling.h(37): error: no suitable user-defined conversion from \"const torch::enumtype::kNearest\" to \"torch::nn::UpsampleOptions::mode_t\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/upsampling.h(75): error: no suitable user-defined conversion from \"const torch::enumtype::kNearest\" to \"torch::nn::functional::InterpolateFuncOptions::mode_t\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/vision.h(27): error: no suitable user-defined conversion from \"const torch::enumtype::kBilinear\" to \"torch::nn::functional::GridSampleFuncOptions::mode_t\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/vision.h(29): error: no suitable user-defined conversion from \"const torch::enumtype::kZeros\" to \"torch::nn::functional::GridSampleFuncOptions::padding_mode_t\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/init.h(88): error: no suitable user-defined conversion from \"const torch::enumtype::kFanIn\" to \"torch::nn::init::FanModeType\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/init.h(89): error: no suitable user-defined conversion from \"const torch::enumtype::kLeakyReLU\" to \"torch::nn::init::NonlinearityType\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/rnn.h(75): error: no suitable user-defined conversion from \"const torch::enumtype::kTanh\" to \"torch::nn::RNNOptions::nonlinearity_t\" exists\n",
      "\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/options/transformerlayer.h(39): error: no suitable user-defined conversion from \"const torch::enumtype::kReLU\" to \"torch::nn::activation_t\" exists\n",
      "\n",
      "18 errors detected in the compilation of \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/codecs/decompress_residuals.cu\".\n",
      "ninja: build stopped: subcommand failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 2096, in _run_ninja_build\n",
      "    subprocess.run(\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/subprocess.py\", line 571, in run\n",
      "    raise CalledProcessError(retcode, process.args,\n",
      "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/infra/launcher.py\", line 134, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 33, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 68, in run\n",
      "    self.train(shared_lists) # Trains centroids from selected passages\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 237, in train\n",
      "    bucket_cutoffs, bucket_weights, avg_residual = self._compute_avg_residual(centroids, heldout)\n",
      "                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 315, in _compute_avg_residual\n",
      "    compressor = ResidualCodec(config=self.config, centroids=centroids, avg_residual=None)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/codecs/residual.py\", line 24, in __init__\n",
      "    ResidualCodec.try_load_torch_extensions(self.use_gpu)\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/codecs/residual.py\", line 103, in try_load_torch_extensions\n",
      "    decompress_residuals_cpp = load(\n",
      "                               ^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1306, in load\n",
      "    return _jit_compile(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1710, in _jit_compile\n",
      "    _write_ninja_file_and_build_library(\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1823, in _write_ninja_file_and_build_library\n",
      "    _run_ninja_build(\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 2112, in _run_ninja_build\n",
      "    raise RuntimeError(message) from e\n",
      "RuntimeError: Error building extension 'decompress_residuals_cpp'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMKL_THREADING_LAYER\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGNU\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolbertv2.0_cmu_lti_finetunev1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m index_path \u001b[38;5;241m=\u001b[39m \u001b[43mRAG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;43;03m#     document_ids=document_ids,  # Include this only if you prepared document IDs\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True to overwrite existing index of the same name\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_document_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m180\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust based on your document length distribution\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True if documents should be split into shorter segments\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/ragatouille/RAGPretrainedModel.py:210\u001b[0m, in \u001b[0;36mRAGPretrainedModel.index\u001b[0;34m(self, collection, document_ids, document_metadatas, index_name, overwrite_index, max_document_length, split_documents, document_splitter_fn, preprocessing_fn, bsize)\u001b[0m\n\u001b[1;32m    201\u001b[0m     document_splitter_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    202\u001b[0m collection, pid_docid_map, docid_metadata_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_corpus(\n\u001b[1;32m    203\u001b[0m     collection,\n\u001b[1;32m    204\u001b[0m     document_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     max_document_length,\n\u001b[1;32m    209\u001b[0m )\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpid_docid_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpid_docid_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocid_metadata_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocid_metadata_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_document_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_document_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/ragatouille/models/colbert.py:368\u001b[0m, in \u001b[0;36mColBERT.index\u001b[0;34m(self, collection, pid_docid_map, docid_metadata_map, index_name, max_document_length, overwrite, bsize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexer \u001b[38;5;241m=\u001b[39m Indexer(\n\u001b[1;32m    363\u001b[0m     checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint,\n\u001b[1;32m    364\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    365\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    366\u001b[0m )\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexer\u001b[38;5;241m.\u001b[39mconfigure(avoid_fork_if_possible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 368\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m    373\u001b[0m     Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mroot)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mexperiment)\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_name\n\u001b[1;32m    377\u001b[0m )\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m    379\u001b[0m     Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mroot) \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mexperiment) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexer.py:80\u001b[0m, in \u001b[0;36mIndexer.index\u001b[0;34m(self, name, collection, overwrite)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merase()\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_does_not_exist \u001b[38;5;129;01mor\u001b[39;00m overwrite \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreuse\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexer.py:98\u001b[0m, in \u001b[0;36mIndexer.__launch\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m     95\u001b[0m shared_queues \u001b[38;5;241m=\u001b[39m [manager\u001b[38;5;241m.\u001b[39mQueue(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnranks)]\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Encodes collection into index using the CollectionIndexer class\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m \u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_queues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/infra/launcher.py:72\u001b[0m, in \u001b[0;36mLauncher.launch\u001b[0;34m(self, custom_config, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m print_memory_stats(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAIN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# TODO: If the processes crash upon join, raise an exception and don't block on .get() below!\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([\u001b[43mreturn_value_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m all_procs])\n\u001b[1;32m     73\u001b[0m return_values \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m rank, val \u001b[38;5;129;01min\u001b[39;00m return_values]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_all:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/connection.py:430\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 430\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/connection.py:395\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "os.environ['COLBERT_LOAD_TORCH_EXTENSION_VERBOSE'] = 'True'\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "index_name = \"colbertv2.0_cmu_lti_finetunev1.0\"\n",
    "index_path = RAG.index(\n",
    "    collection=collection,\n",
    "#     document_ids=document_ids,  # Include this only if you prepared document IDs\n",
    "    index_name=index_name,\n",
    "    overwrite_index=True,  # Set to True to overwrite existing index of the same name\n",
    "    max_document_length=180,  # Adjust based on your document length distribution\n",
    "    split_documents=True,  # Set to True if documents should be split into shorter segments\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-rag",
   "language": "python",
   "name": "nlp-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
