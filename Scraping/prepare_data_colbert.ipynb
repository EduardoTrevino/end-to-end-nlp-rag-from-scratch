{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peparing triplet data for ColBERT/Ragatouille fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from ragatouille import RAGTrainer\n",
    "from ragatouille import RAGPretrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RAGTrainer\n",
    "# RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "trainer = RAGTrainer(model_name=\"colbertv2.0_cmu_lti_finetunev2.0\", pretrained_model_name=\"colbert-ir/colbertv2.0\", n_usable_gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store all documents\n",
    "all_documents = []\n",
    "# List to store raw data in the required format\n",
    "raw_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in [\"courses\", \"../academic_calendars\", \"../program_handbooks\", \"../Web Scholar PDFs\", \"../fall23\"]:\n",
    "    folder_path = Path(folder)\n",
    "    # Read and store documents\n",
    "    for doc_file in folder_path.glob(\"*.txt\"):\n",
    "        if doc_file.name != \"annotation.txt\":\n",
    "            with open(doc_file, 'r', encoding='utf-8') as file:\n",
    "                all_documents.append(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The course 10301, 'Introduction to Machine Learning,' offers 12 units in section A, meeting on Mondays, Wednesdays, and Fridays from 11:00 AM to 12:20 PM in Pittsburgh, Pennsylvania, at TEP 1403, with an in-person expectation, taught by Matthew Gormley, Henry Chai, and Hoda Heidari.\\nThe course 10315, 'Introduction to Machine Learning (SCS Majors),' provides 12 units in section Lec 1, convening on Mondays and Wednesdays from 12:30 PM to 01:50 PM in Pittsburgh, Pennsylvania, at SH 105, under an in-person expectation, instructed by Patrick Virtue.\\nThe course 10335, 'Art and Machine Learning,' awards 12 units in section A, scheduled for Mondays and Wednesdays from 7:00 PM to 8:20 PM in Pittsburgh, Pennsylvania, at TEP 1403, featuring an in-person expectation, taught by Eunsu Kang.\\nThe course 10403, 'Deep Reinforcement Learning & Control,' offers 12 units in section A, gathering on Mondays, Wednesdays, and Fridays from 12:30 PM to 01:50 PM in Pittsburgh, Pennsylvania, at GHC 4215, with an in-person expectation, instructed by Katerina Fragkiadaki.\\nThe course 10405, 'Machine Learning with Large Datasets (Undergraduate),' provides 12 units in section A, meeting on Mondays, Wednesdays, and Fridays from 3:30 PM to 4:50 PM in Pittsburgh, Pennsylvania, at DH 2210, under an in-person expectation, taught by Ameet Talwalkar and Geoffrey Gordon.\\nThe course 10422, 'Foundations of Learning, Game Theory, and Their Connections,' awards 12 units in section A, convening on Mondays and Wednesdays from 9:30 AM to 10:50 AM in Pittsburgh, Pennsylvania, at GHC 4211, with an in-person expectation, instructed by Maria Balcan.\\nThe course 10423, 'Generative AI,' offers 12 units in section A, gathering on Mondays, Wednesdays, and Fridays from 3:30 PM to 4:50 PM in Pittsburgh, Pennsylvania, at GHC 4401, featuring an in-person expectation, taught by Matthew Gormley, Yuanzhi Li, and Zachary Lipton.\\nThe course 10500, 'Senior Research Project,' provides 6 or 12 units in section A, with schedule, days, and location to be announced (TBA), set in Pittsburgh, Pennsylvania, at DNM, promising an in-person expectation, supervised by Matthew Gormley.\\nThe course 10520, 'Independent Study,' offers variable units in section A, with details such as schedule and location to be announced (TBA), located in Pittsburgh, Pennsylvania, at DNM, featuring an in-person expectation, guided by Matthew Gormley.\\nThe course 10601, 'Introduction to Machine Learning (Master's),' awards 12 units in section A, scheduled for Mondays, Wednesdays, and Fridays from 11:00 AM to 12:20 PM in Pittsburgh, Pennsylvania, at TEP 1403, under an in-person expectation, instructed by Matthew Gormley, Henry Chai, and Hoda Heidari.\\nThe course 10605, 'Machine Learning with Large Datasets,' provides 12 units in section A, meeting on Mondays, Wednesdays, and Fridays from 3:30 PM to 4:50 PM in Pittsburgh, Pennsylvania, at DH 2210, with an in-person expectation, taught by Ameet Talwalkar and Geoffrey Gordon.\\nThe course 10615, 'Art and Machine Learning,' offers 12 units in section A, gathering on Mondays and Wednesdays from 7:00 PM to 8:20 PM in Pittsburgh, Pennsylvania, at TEP 1403, featuring an in-person expectation, led by Eunsu Kang.\\nThe course 10620, 'Independent Study: Research,' awards 6 or 12 units in section A, with schedule, days, and location to be announced (TBA), set in Pittsburgh, Pennsylvania, at DNM, promising an in-person expectation, supervised by Nihar Shah.\\nThe course 10623, 'Generative AI,' provides 12 units in section A, convening on Mondays, Wednesdays, and Fridays from 3:30 PM to 4:50 PM in Pittsburgh, Pennsylvania, at GHC 4401, under an in-person expectation, instructed by Matthew Gormley, Yuanzhi Li, and Zachary Lipton.\\nThe course 10635, 'Practicum,' offers variable units in section I, with details such as schedule and location to be announced (TBA), located in Pittsburgh, Pennsylvania, at DNM, featuring an in-person expectation, guided by Nihar Shah.\\nThe course 10301, 'Introduction to Machine Learning,' offers 12 units in section A, meeting on Mondays, Wednesdays, and Fridays from 11:00 AM to 12:20 PM in Pittsburgh, Pennsylvania, at TEP 1403, with an in-person expectation, taught by Matthew Gormley, Henry Chai, and Hoda Heidari.\\nThe course 10315, 'Introduction to Machine Learning (SCS Majors),' provides 12 units in section Lec 1, convening on Mondays and Wednesdays from 12:30 PM to 01:50 PM in Pittsburgh, Pennsylvania, at SH 105, under an in-person expectation, instructed by Patrick Virtue.\\nThe course 10335, 'Art and Machine Learning,' awards 12 units in section A, scheduled for Mondays and Wednesdays from 7:00 PM to 8:20 PM in Pittsburgh, Pennsylvania, at TEP 1403, featuring an in-person expectation, taught by Eunsu Kang.\\nThe course 10403, 'Deep Reinforcement Learning & Control,' offers 12 units in section A, gathering on Mondays, Wednesdays, and Fridays from 12:30 PM to 01:50 PM in Pittsburgh, Pennsylvania, at GHC 4215, with an in-person expectation, instructed by Katerina Fragkiadaki.\\nThe course 10405, 'Machine Learning with Large Datasets (Undergraduate),' provides 12 units in section A, meeting on Mondays, Wednesdays, and Fridays from 3:30 PM to 4:50 PM in Pittsburgh, Pennsylvania, at DH 2210, under an in-person expectation, taught by Ameet Talwalkar and Geoffrey Gordon.\\nThe course 10422, 'Foundations of Learning, Game Theory, and Their Connections,' awards 12 units in section A, convening on Mondays and Wednesdays from 9:30 AM to 10:50 AM in Pittsburgh, Pennsylvania, at GHC 4211, with an in-person expectation, instructed by Maria Balcan.\\nThe course 10423, 'Generative AI,' offers 12 units in section A, gathering on Mondays, Wednesdays, and Fridays from 3:30 PM to 4:50 PM in Pittsburgh, Pennsylvania, at GHC 4401, featuring an in-person expectation, taught by Matthew Gormley, Yuanzhi Li, and Zachary Lipton.\\nThe course 10500, 'Senior Research Project,' provides 6 or 12 units in section A, with schedule, days, and location to be announced (TBA), set in Pittsburgh, Pennsylvania, at DNM, promising an in-person expectation, supervised by Matthew Gormley.\\nThe course 10520, 'Independent Study,' offers variable units in section A, with details such as schedule and location to be announced (TBA), located in Pittsburgh, Pennsylvania, at DNM, featuring an in-person expectation, guided by Matthew Gormley.\\nThe course 10601, 'Introduction to Machine Learning (Master's),' awards 12 units in section A, scheduled for Mondays, Wednesdays, and Fridays from 11:00 AM to 12:20 PM in Pittsburgh, Pennsylvania, at TEP 1403, under an in-person expectation, instructed by Matthew Gormley, Henry Chai, and Hoda Heidari.\\nThe course 10605, 'Machine Learning with Large Datasets,' provides 12 units in section A, meeting on Mondays, Wednesdays, and Fridays from 3:30 PM to 4:50 PM in Pittsburgh, Pennsylvania, at DH 2210, with an in-person expectation, taught by Ameet Talwalkar and Geoffrey Gordon.\\nThe course 10615, 'Art and Machine Learning,' offers 12 units in section A, gathering on Mondays and Wednesdays from 7:00 PM to 8:20 PM in Pittsburgh, Pennsylvania, at TEP 1403, featuring an in-person expectation, led by Eunsu Kang.\\nThe course 10620, 'Independent Study: Research,' awards 6 or 12 units in section A, with schedule, days, and location to be announced (TBA), set in Pittsburgh, Pennsylvania, at DNM, promising an in-person expectation, supervised by Nihar Shah.\\nThe course 10623, 'Generative AI,' provides 12 units in section A, convening on Mondays, Wednesdays, and Fridays from 3:30 PM to 4:50 PM in Pittsburgh, Pennsylvania, at GHC 4401, under an in-person expectation, instructed by Matthew Gormley, Yuanzhi Li, and Zachary Lipton.\\nThe course 10635, 'Practicum,' offers variable units in section I, with details such as schedule and location to be announced (TBA), located in Pittsburgh, Pennsylvania, at DNM, featuring an in-person expectation, guided by Nihar Shah.\\nThe course 10697, 'Reading and Research,' offers 1 to 48 units in section A, with schedule, days, and location to be announced (TBA), set in Pittsburgh, Pennsylvania, at DNM, promising an in-person expectation, supervised by Nihar Shah.\\nThe course 10701, 'Introduction to Machine Learning (PhD),' provides 12 units in section A, meeting on Mondays, Wednesdays, and Fridays from 9:30 AM to 10:50 AM in Pittsburgh, Pennsylvania, at TEP 1403, under an in-person expectation, taught by Henry Chai.\\nThe course 10707, 'Advanced Deep Learning,' offers 12 units in section A, convening on Mondays, Wednesdays, and Fridays from 9:30 AM to 10:50 AM in Pittsburgh, Pennsylvania, at DH 2302, with an in-person expectation, instructed by Ruslan Salakhutdinov.\\nThe course 10708, 'Probabilistic Graphical Models,' awards 12 units in section A, scheduled for Mondays, Wednesdays, and Fridays from 2:00 PM to 3:20 PM in Pittsburgh, Pennsylvania, at DH 2210, featuring an in-person expectation, taught by Andrej Risteski and Albert Gu.\\nThe course 10716, 'Advanced Machine Learning: Theory and Methods,' provides 12 units in section A, gathering on Tuesdays and Thursdays from 3:30 PM to 4:50 PM in Pittsburgh, Pennsylvania, at POS 151, under an in-person expectation, instructed by Pradeep Ravikumar.\\nThe course 10718, 'Machine Learning in Practice,' offers 12 units in section A, meeting on Tuesdays and Thursdays from 9:30 AM to 10:50 AM in Pittsburgh, Pennsylvania, at GHC 4307, with an in-person expectation, taught by Virginia Smith.\\nThe course 10725, 'Convex Optimization,' awards 12 units in section A, convening on Tuesdays and Thursdays from 2:00 PM to 3:20 PM in Pittsburgh, Pennsylvania, at TEP 1403, featuring an in-person expectation, instructed by Barnabas Poczos.\\nThe course 10733, 'Representation and Generation in Neuroscience and AI,' provides 12 units in section A, scheduled for Mondays and Wednesdays from 3:30 PM to 4:50 PM in Pittsburgh, Pennsylvania, at GHC 4102, under an in-person expectation, taught by Leila Wehbe.\\nThe course 10735, 'Responsible AI,' offers 12 units in section A, gathering on Tuesdays and Thursdays from 11:00 AM to 12:20 PM in Pittsburgh, Pennsylvania, at POS 151, featuring an in-person expectation, led by Hoda Heidari and Alex London.\\nThe course 10880, 'Game Theoretic Probability, Statistics and Learning,' awards 12 units in section A, meeting on Tuesdays and Thursdays from 3:30 PM to 4:50 PM in Pittsburgh, Pennsylvania, at DH 1211, with an in-person expectation, instructed by Aaditya Ramdas.\\nThe course 10920, 'Graduate Reading and Research,' provides 12 to 48 units in section A, with schedule, days, and location to be announced (TBA), located in Pittsburgh, Pennsylvania, at DNM, promising an in-person expectation, supervised by Tom Mitchell.\\nThe course 10930, 'Dissertation Research,' offers 5 to 48 units in section A, with details such as schedule and location to be announced (TBA), set in Pittsburgh, Pennsylvania, at DNM, featuring an in-person expectation, guided by Tom Mitchell.\\nThe course 10935, 'Practicum,' awards 3 to 48 units in section A, convening with schedule, days, and location to be announced (TBA), located in Pittsburgh, Pennsylvania, at DNM, under an in-person expectation, supervised by Tom Mitchell.\\nThe course 10940, 'Independent Study,' provides 1 to 48 units in section A, scheduled with days and location to be announced (TBA), set in Pittsburgh, Pennsylvania, at DNM, featuring an in-person expectation, instructed by Tom Mitchell.\"]\n"
     ]
    }
   ],
   "source": [
    "print(all_documents[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each folder and read documents and annotations\n",
    "for folder in [\"About Scottie\", \"Buggy News\", \"history_of_cmu\", \"history_of_scs\", \"Kiltie Band\", \"lti_faculty\", \"lti_programs\", \"Tartan Facts\"]:\n",
    "    folder_path = Path(folder)\n",
    "    # Read and store documents\n",
    "    for doc_file in folder_path.glob(\"*.txt\"):\n",
    "        if doc_file.name != \"annotation.txt\":\n",
    "            with open(doc_file, 'r', encoding='utf-8') as file:\n",
    "                all_documents.append(file.read())\n",
    "\n",
    "    # Read annotations and prepare raw data\n",
    "    annotation_path = folder_path / \"annotation.txt\"\n",
    "    with open(annotation_path, 'r', encoding='utf-8') as file:\n",
    "        annotations = file.read().split(\"\\n\\n\")  # Assuming each Q/A/D/T block is separated by two newlines\n",
    "#         raw_data = [(lines[0].replace(\"Q: \", \"\"), lines[1].replace(\"A: \", \"\")) for block in annotations for lines in [block.strip().split(\"\\n\")] if len(lines) == 4]\n",
    "        for block in annotations:\n",
    "            lines = block.split(\"\\n\")\n",
    "#             print(len(lines))\n",
    "            if len(lines) == 4:  # Ensure it's a full block\n",
    "                question = lines[0].replace(\"Q: \", \"\")\n",
    "                answer = lines[1].replace(\"A: \", \"\")\n",
    "                raw_data.append((question, answer))\n",
    "\n",
    "# #                 question = lines[0][3:]  # Remove \"Q: \"\n",
    "# #                 print(question)\n",
    "# #                 answer = lines[1][3:]  # Remove \"A: \"\n",
    "# #                 print(answer)\n",
    "# #                 doc_ref = lines[2][3:]  # Remove \"D: \"\n",
    "\n",
    "#                 question = lines[0].replace(\"Q: \", \"\")\n",
    "#                 answer = lines[1].replace(\"A: \", \"\")\n",
    "#                 print(f\"Appending: {question} | {answer}\")\n",
    "#                 # Here you could use the doc_ref to link the question-answer pair with the specific document content if needed\n",
    "#                 # For simplicity, we'll just use the question and answer for now\n",
    "#                 raw_data.append((question, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('When was The Kiltie Band founded?', 'The Kiltie Band was founded in 1908.'), ('Who founded Carnegie Mellon University and what type of pet did he keep?', 'Andrew Carnegie founded Carnegie Mellon University and had a Scottish terrier.'), ('When did Carnegie Mellon officially start the process to select a mascot?', 'The mascot selection process at Carnegie Mellon began in November 2006.'), ('Who co-chaired the Mascot Identity Task Force at Carnegie Mellon?', 'Susan Bassett and Jennifer Church co-chaired the Mascot Identity Task Force.'), ('How did the Carnegie Mellon community participate in the mascot selection process?', 'The community participated in the mascot choice through surveys and a Town Hall.'), ('What percentage of students voted for the Scottish terrier as the mascot in the 2007 survey?', '78% of 2,370 students voted for the Scottish terrier as the mascot in 2007.'), ('What misconception did approximately 25 percent of surveyed alumni have about the Scottish terrier?', '25% of surveyed alumni mistakenly believed the Scottish terrier was already the mascot.'), ('Which company did Carnegie Mellon partner with to develop the graphics for the mascot?', 'Carnegie Mellon collaborated with SME Branding for mascot graphics.'), ('When did the official mascot of Carnegie Mellon debut?', 'The mascot debuted at the home football game on Nov. 10, 2007.'), (\"What does the graphic of Carnegie Mellon's official mascot feature?\", 'The mascot graphic features a Scottish terrier with a plaid scarf in a shield.'), ('When was the official Scotty costume unveiled?', 'The Scotty costume was revealed at the 2008 Spring Carnival.'), (\"What breed is Carnegie Mellon University's mascot?\", \"The university's mascot is a Scottish terrier.\"), ('What was the role of focus groups in the mascot selection process?', 'Focus groups with students and alumni helped select the mascot image.'), ('What are some of the temperament traits of the Scottish Terrier breed?', 'The Scottish Terrier is known for its keen, alert, intelligence, and determined temperament.'), (\"Why was the Scottish Terrier chosen as Carnegie Mellon University's mascot?\", \"It was chosen as the mascot for embodying CMU's traits like strength, agility, and determination.\")]\n"
     ]
    }
   ],
   "source": [
    "# print(annotation_path)\n",
    "print(raw_data[:15])\n",
    "# print(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Hard Negative SimpleMiner dense embedding model BAAI/bge-small-en-v1.5...\n",
      "Building hard negative index for 380 documents...\n",
      "All documents embedded, now adding to index...\n",
      "save_index set to False, skipping saving hard negative index\n",
      "Hard negative index generated\n",
      "Training data prepared and stored at: ./colbertv2data/\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "data_out_path = trainer.prepare_training_data(raw_data=raw_data, all_documents=all_documents, data_out_path=\"./colbertv2data/\")\n",
    "print(f\"Training data prepared and stored at: {data_out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the MKL_THREADING_LAYER environment variable\n",
    "os.environ['MKL_SERVICE_FORCE_INTE'] = '1'\n",
    "\n",
    "# Now you can import numpy and other libraries\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already up-to-date: numpy in /home/trevea/.local/lib/python3.7/site-packages (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "nranks = 4 \t num_gpus = 4 \t device=2\n",
      "Using config.bsize = 8 (per process) and config.accumsteps = 1\n",
      "[Mar 16, 21:15:48] #> Loading the queries from colbertv2data/queries.train.colbert.tsv ...\n",
      "[Mar 16, 21:15:48] #> Got 328 queries. All QIDs are unique.\n",
      "\n",
      "[Mar 16, 21:15:48] #> Loading collection...\n",
      "0M nranks = 4 \t num_gpus = 4 \t device=1\n",
      "Using config.bsize = 8 (per process) and config.accumsteps = 1\n",
      "[Mar 16, 21:15:48] #> Loading the queries from colbertv2data/queries.train.colbert.tsv ...\n",
      "[Mar 16, 21:15:48] #> Got 328 queries. All QIDs are unique.\n",
      "\n",
      "[Mar 16, 21:15:48] #> Loading collection...\n",
      "0M nranks = 4 \t num_gpus = 4 \t device=3\n",
      "Using config.bsize = 8 (per process) and config.accumsteps = 1\n",
      "[Mar 16, 21:15:48] #> Loading the queries from colbertv2data/queries.train.colbert.tsv ...\n",
      "[Mar 16, 21:15:48] #> Got 328 queries. All QIDs are unique.\n",
      "\n",
      "[Mar 16, 21:15:48] #> Loading collection...\n",
      "0M nranks = 4 \t num_gpus = 4 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"index_bsize\": 64,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 20,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 32,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 5e-6,\n",
      "    \"maxsteps\": 500000,\n",
      "    \"save_every\": 10,\n",
      "    \"warmup\": 10,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": \"colbertv2.0_cmu_lti_finetunev2.0\",\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 256,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"colbert-ir\\/colbertv2.0\",\n",
      "    \"triples\": \"colbertv2data\\/triples.train.colbert.jsonl\",\n",
      "    \"collection\": \"colbertv2data\\/corpus.train.colbert.tsv\",\n",
      "    \"queries\": \"colbertv2data\\/queries.train.colbert.tsv\",\n",
      "    \"index_name\": null,\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \".ragatouille\\/\",\n",
      "    \"experiment\": \"colbert\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-03\\/16\\/21.14.40\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 4,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 4,\n",
      "    \"avoid_fork_if_possible\": false\n",
      "}\n",
      "Using config.bsize = 8 (per process) and config.accumsteps = 1\n",
      "[Mar 16, 21:15:48] #> Loading the queries from colbertv2data/queries.train.colbert.tsv ...\n",
      "[Mar 16, 21:15:48] #> Got 328 queries. All QIDs are unique.\n",
      "\n",
      "[Mar 16, 21:15:48] #> Loading collection...\n",
      "0M "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> LR will use 10 warmup steps and linear decay over 500000 steps.\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who co-chaired the Mascot Identity Task Force at Carnegie Mellon?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2522,  1011, 12282,  1996, 13314,  4767,  4708,\n",
      "         2486,  2012, 11298, 22181,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "\t\t\t\t 0.7071167230606079 1.472010850906372\n",
      "#>>>    17.93 13.41 \t\t|\t\t 4.52\n",
      "[Mar 16, 21:15:56] 0 2.1791276931762695\n",
      "\t\t\t\t 0.015664443373680115 0.39106568694114685\n",
      "#>>>    19.01 10.37 \t\t|\t\t 8.640000000000002\n",
      "[Mar 16, 21:15:57] 1 2.177355295598507\n",
      "\t\t\t\t 0.6828833222389221 1.952773928642273\n",
      "#>>>    19.88 14.71 \t\t|\t\t 5.169999999999998\n",
      "[Mar 16, 21:15:57] 2 2.1778135976133943\n",
      "\t\t\t\t 0.48245370388031006 1.1752110719680786\n",
      "#>>>    18.09 11.37 \t\t|\t\t 6.720000000000001\n",
      "[Mar 16, 21:15:57] 3 2.1772934487916293\n",
      "\t\t\t\t 0.3404005169868469 0.7346277236938477\n",
      "#>>>    18.38 11.32 \t\t|\t\t 7.059999999999999\n",
      "[Mar 16, 21:15:57] 4 2.1761911835239136\n",
      "\t\t\t\t 1.0145255327224731 1.4570797681808472\n",
      "#>>>    17.02 12.99 \t\t|\t\t 4.029999999999999\n",
      "[Mar 16, 21:15:57] 5 2.176486597641293\n",
      "\t\t\t\t 0.07464785128831863 0.2617340385913849\n",
      "#>>>    19.18 12.39 \t\t|\t\t 6.789999999999999\n",
      "[Mar 16, 21:15:57] 6 2.174646492926081\n",
      "\t\t\t\t 0.3186742663383484 1.598601222038269\n",
      "#>>>    17.69 12.49 \t\t|\t\t 5.200000000000001\n",
      "[Mar 16, 21:15:57] 7 2.174389121861927\n",
      "\t\t\t\t 1.9754693508148193 1.9946988821029663\n",
      "#>>>    12.38 12.13 \t\t|\t\t 0.25\n",
      "[Mar 16, 21:15:57] 8 2.1761849008537735\n",
      "\t\t\t\t 2.7800824642181396 1.51702880859375\n",
      "#>>>    15.37 15.55 \t\t|\t\t -0.1800000000000015\n",
      "[Mar 16, 21:15:57] 9 2.1783058274641505\n",
      "\t\t\t\t 0.06475556641817093 1.2670130729675293\n",
      "#>>>    20.1 12.77 \t\t|\t\t 7.330000000000002\n",
      "[Mar 16, 21:15:57] 10 2.1774592902686214\n",
      "\t\t\t\t 1.6763579845428467 2.83425235748291\n",
      "#>>>    16.39 12.86 \t\t|\t\t 3.530000000000001\n",
      "[Mar 16, 21:15:58] 11 2.179792441558797\n",
      "\t\t\t\t 0.024105049669742584 0.5274296402931213\n",
      "#>>>    19.37 11.61 \t\t|\t\t 7.760000000000002\n",
      "[Mar 16, 21:15:58] 12 2.1781641838295527\n",
      "\t\t\t\t 1.3618183135986328 1.8384675979614258\n",
      "#>>>    15.63 11.8 \t\t|\t\t 3.83\n",
      "[Mar 16, 21:15:58] 13 2.179186305557283\n",
      "\t\t\t\t 2.193624258041382 2.512465000152588\n",
      "#>>>    13.32 12.57 \t\t|\t\t 0.75\n",
      "[Mar 16, 21:15:58] 14 2.181713208271501\n",
      "\t\t\t\t 0.9059346914291382 1.5903061628341675\n",
      "#>>>    18.55 14.4 \t\t|\t\t 4.15\n",
      "[Mar 16, 21:15:58] 15 2.1820277359174933\n",
      "\t\t\t\t 1.7115416526794434 1.9479098320007324\n",
      "#>>>    18.04 12.02 \t\t|\t\t 6.02\n",
      "[Mar 16, 21:15:58] 16 2.183505159666256\n",
      "\t\t\t\t 0.37512484192848206 0.2546404302120209\n",
      "#>>>    18.69 12.7 \t\t|\t\t 5.990000000000002\n",
      "[Mar 16, 21:15:58] 17 2.18195141977873\n",
      "\t\t\t\t 0.4107673168182373 1.1955363750457764\n",
      "#>>>    17.21 11.19 \t\t|\t\t 6.020000000000001\n",
      "[Mar 16, 21:15:58] 18 2.1813757720508153\n",
      "\t\t\t\t 0.8699451684951782 1.7525328397750854\n",
      "#>>>    16.36 11.68 \t\t|\t\t 4.68\n",
      "[Mar 16, 21:15:58] 19 2.1818168742870347\n",
      "\t\t\t\t 0.4945365786552429 0.5479140877723694\n",
      "#>>>    20.51 15.22 \t\t|\t\t 5.290000000000001\n",
      "[Mar 16, 21:15:59] 20 2.1806775080791754\n",
      "\t\t\t\t 0.019786100834608078 0.9417812824249268\n",
      "#>>>    15.83 9.43 \t\t|\t\t 6.4\n",
      "[Mar 16, 21:15:59] 21 2.1794583979729825\n",
      "\t\t\t\t 1.49244225025177 0.3837464153766632\n",
      "#>>>    19.32 11.22 \t\t|\t\t 8.1\n",
      "[Mar 16, 21:15:59] 22 2.179155128210836\n",
      "\t\t\t\t 1.7292118072509766 2.553194284439087\n",
      "#>>>    13.99 11.95 \t\t|\t\t 2.040000000000001\n",
      "[Mar 16, 21:15:59] 23 2.1812583789358966\n",
      "\t\t\t\t 1.1574435234069824 0.6912578344345093\n",
      "#>>>    19.16 12.41 \t\t|\t\t 6.75\n",
      "[Mar 16, 21:15:59] 24 2.180925821914802\n",
      "\t\t\t\t 0.12216844409704208 0.35352423787117004\n",
      "#>>>    18.9 10.54 \t\t|\t\t 8.36\n",
      "[Mar 16, 21:15:59] 25 2.1792205887823064\n",
      "\t\t\t\t 0.0035623563453555107 0.5092859268188477\n",
      "#>>>    20.4 12.2 \t\t|\t\t 8.2\n",
      "[Mar 16, 21:15:59] 26 2.1775542164515427\n",
      "\t\t\t\t 0.1336260586977005 0.22501076757907867\n",
      "#>>>    19.78 14.09 \t\t|\t\t 5.690000000000001\n",
      "[Mar 16, 21:15:59] 27 2.175735299061368\n",
      "\t\t\t\t 0.04257307946681976 0.8455954790115356\n",
      "#>>>    19.44 9.31 \t\t|\t\t 10.13\n",
      "[Mar 16, 21:15:59] 28 2.174447732335686\n",
      "\t\t\t\t 0.027618899941444397 1.0628461837768555\n",
      "#>>>    20.14 11.87 \t\t|\t\t 8.270000000000001\n",
      "[Mar 16, 21:16:00] 29 2.1733637496721676\n",
      "\t\t\t\t 0.08776264637708664 0.2044984996318817\n",
      "#>>>    20.3 13.34 \t\t|\t\t 6.960000000000001\n",
      "[Mar 16, 21:16:00] 30 2.171482647075955\n",
      "\t\t\t\t 2.0383174419403076 1.1920756101608276\n",
      "#>>>    15.78 12.76 \t\t|\t\t 3.0199999999999996\n",
      "[Mar 16, 21:16:00] 31 2.1725415573617712\n",
      "\t\t\t\t 0.8372628688812256 0.6109284162521362\n",
      "#>>>    18.3 11.35 \t\t|\t\t 6.950000000000001\n",
      "[Mar 16, 21:16:00] 32 2.1718172070895427\n",
      "\t\t\t\t 1.103489875793457 0.9859675168991089\n",
      "#>>>    15.25 10.02 \t\t|\t\t 5.23\n",
      "[Mar 16, 21:16:00] 33 2.171734847394355\n",
      "\t\t\t\t 0.3719594180583954 0.11287720501422882\n",
      "#>>>    19.61 11.69 \t\t|\t\t 7.92\n",
      "[Mar 16, 21:16:00] 34 2.1700479491849345\n",
      "\t\t\t\t 0.06434937566518784 0.7140849828720093\n",
      "#>>>    17.74 12.16 \t\t|\t\t 5.579999999999998\n",
      "[Mar 16, 21:16:00] 35 2.168656335571935\n",
      "\t\t\t\t 0.24025112390518188 0.24286708235740662\n",
      "#>>>    18.79 11.18 \t\t|\t\t 7.609999999999999\n",
      "[Mar 16, 21:16:00] 36 2.1669707974426258\n",
      "\t\t\t\t 0.7254287004470825 1.435215711593628\n",
      "#>>>    18.4 12.5 \t\t|\t\t 5.899999999999999\n",
      "[Mar 16, 21:16:00] 37 2.166964471176433\n",
      "\t\t\t\t 1.4925498962402344 1.3936768770217896\n",
      "#>>>    17.27 12.38 \t\t|\t\t 4.889999999999999\n",
      "[Mar 16, 21:16:01] 38 2.167683733359309\n",
      "\t\t\t\t 0.5536744594573975 0.3062003254890442\n",
      "#>>>    20.49 10.75 \t\t|\t\t 9.739999999999998\n",
      "[Mar 16, 21:16:01] 39 2.166375924410896\n",
      "\t\t\t\t 0.24959862232208252 0.22042275965213776\n",
      "#>>>    17.63 10.61 \t\t|\t\t 7.02\n",
      "[Mar 16, 21:16:01] 40 2.164679569853558\n",
      "\t\t\t\t 0.04797251895070076 0.5267298221588135\n",
      "#>>>    20.2 12.82 \t\t|\t\t 7.379999999999999\n",
      "[Mar 16, 21:16:01] 41 2.1630895926061875\n",
      "\t\t\t\t 0.7111374735832214 0.8591779470443726\n",
      "#>>>    17.33 12.52 \t\t|\t\t 4.809999999999999\n",
      "[Mar 16, 21:16:01] 42 2.1624968183746045\n",
      "\t\t\t\t 0.001262559788301587 0.10178644210100174\n",
      "#>>>    22.02 12.49 \t\t|\t\t 9.53\n",
      "[Mar 16, 21:16:01] 43 2.160437370558818\n",
      "\t\t\t\t 0.14781071245670319 0.8215031027793884\n",
      "#>>>    18.25 8.64 \t\t|\t\t 9.61\n",
      "[Mar 16, 21:16:01] 44 2.159246246988594\n",
      "\t\t\t\t 1.0448119640350342 0.5893073678016663\n",
      "#>>>    18.58 9.79 \t\t|\t\t 8.79\n",
      "[Mar 16, 21:16:01] 45 2.158721120013838\n",
      "\t\t\t\t 0.35699790716171265 0.779264509677887\n",
      "#>>>    16.51 12.33 \t\t|\t\t 4.1800000000000015\n",
      "[Mar 16, 21:16:01] 46 2.1576986613106635\n",
      "\t\t\t\t 0.6170027256011963 0.8848015069961548\n",
      "#>>>    18.58 10.83 \t\t|\t\t 7.749999999999998\n",
      "[Mar 16, 21:16:01] 47 2.15704276688195\n",
      "\t\t\t\t 0.05984353646636009 0.07136071473360062\n",
      "#>>>    20.72 12.54 \t\t|\t\t 8.18\n",
      "[Mar 16, 21:16:02] 48 2.1550169283625427\n",
      "\t\t\t\t 1.0367724895477295 1.4466062784194946\n",
      "#>>>    19.06 14.47 \t\t|\t\t 4.589999999999998\n",
      "[Mar 16, 21:16:02] 49 2.155345290321357\n",
      "\t\t\t\t 0.003973667975515127 0.3926287293434143\n",
      "#>>>    20.66 12.46 \t\t|\t\t 8.2\n",
      "[Mar 16, 21:16:02] 50 2.1535865474232323\n",
      "\t\t\t\t 0.020307177677750587 0.23576565086841583\n",
      "#>>>    19.05 11.82 \t\t|\t\t 7.23\n",
      "[Mar 16, 21:16:02] 51 2.151689033695042\n",
      "\t\t\t\t 0.6670012474060059 0.8752227425575256\n",
      "#>>>    19.78 12.67 \t\t|\t\t 7.110000000000001\n",
      "[Mar 16, 21:16:02] 52 2.151079568591706\n",
      "\t\t\t\t 0.6181235909461975 1.0882980823516846\n",
      "#>>>    15.68 12.28 \t\t|\t\t 3.4000000000000004\n",
      "[Mar 16, 21:16:02] 53 2.1506349106368075\n",
      "\t\t\t\t 0.018907273188233376 0.07022007554769516\n",
      "#>>>    20.26 13.82 \t\t|\t\t 6.440000000000001\n",
      "[Mar 16, 21:16:02] 54 2.148573403073044\n",
      "\t\t\t\t 0.3056012690067291 0.43601512908935547\n",
      "#>>>    18.12 13.06 \t\t|\t\t 5.0600000000000005\n",
      "[Mar 16, 21:16:02] 55 2.147166446038265\n",
      "\t\t\t\t 0.9391872882843018 1.1658544540405273\n",
      "#>>>    16.86 11.19 \t\t|\t\t 5.67\n",
      "[Mar 16, 21:16:02] 56 2.1471243213345517\n",
      "\t\t\t\t 0.04226098582148552 1.3240187168121338\n",
      "#>>>    17.35 9.89 \t\t|\t\t 7.460000000000001\n",
      "[Mar 16, 21:16:02] 57 2.146343476734477\n",
      "\t\t\t\t 0.00401958916336298 0.04001973196864128\n",
      "#>>>    17.89 7.4 \t\t|\t\t 10.49\n",
      "[Mar 16, 21:16:02] 58 2.1442411725779436\n",
      "\t\t\t\t 1.251672892976785e-05 0.03989999368786812\n",
      "#>>>    20.42 7.32 \t\t|\t\t 13.100000000000001\n",
      "[Mar 16, 21:16:03] 59 2.142136843916029\n",
      "\t\t\t\t 0.03315954655408859 0.7008629441261292\n",
      "#>>>    18.8 10.22 \t\t|\t\t 8.58\n",
      "[Mar 16, 21:16:03] 60 2.140728729570244\n",
      "\t\t\t\t 0.14507606625556946 0.26848527789115906\n",
      "#>>>    16.83 10.42 \t\t|\t\t 6.409999999999998\n",
      "[Mar 16, 21:16:03] 61 2.1390015621848204\n",
      "\t\t\t\t 0.00998216588050127 0.0031129370909184217\n",
      "#>>>    20.69 9.68 \t\t|\t\t 11.010000000000002\n",
      "[Mar 16, 21:16:03] 62 2.13687565572584\n",
      "\t\t\t\t 0.3882540166378021 0.19705259799957275\n",
      "#>>>    17.25 11.06 \t\t|\t\t 6.1899999999999995\n",
      "[Mar 16, 21:16:03] 63 2.135324086714554\n",
      "\t\t\t\t 0.42201292514801025 1.0155067443847656\n",
      "#>>>    14.52 10.53 \t\t|\t\t 3.99\n",
      "[Mar 16, 21:16:03] 64 2.1346262822973725\n",
      "\t\t\t\t 0.29229700565338135 0.43154066801071167\n",
      "#>>>    16.53 10.38 \t\t|\t\t 6.15\n",
      "[Mar 16, 21:16:03] 65 2.133215493688739\n",
      "\t\t\t\t 0.08067021518945694 0.6705237627029419\n",
      "#>>>    19.69 14.24 \t\t|\t\t 5.450000000000001\n",
      "[Mar 16, 21:16:03] 66 2.1318334721952943\n",
      "\t\t\t\t 0.4937681555747986 0.6601715087890625\n",
      "#>>>    19.01 11.02 \t\t|\t\t 7.990000000000002\n",
      "[Mar 16, 21:16:04] 67 2.1308555784470675\n",
      "\t\t\t\t 0.02698836289346218 0.045550283044576645\n",
      "#>>>    18.83 11.1 \t\t|\t\t 7.729999999999999\n",
      "[Mar 16, 21:16:04] 68 2.128797261512696\n",
      "\t\t\t\t 0.43448126316070557 0.0514625683426857\n",
      "#>>>    17.75 10.44 \t\t|\t\t 7.3100000000000005\n",
      "[Mar 16, 21:16:04] 69 2.1271544080752363\n",
      "\t\t\t\t 0.147542342543602 0.03389783203601837\n",
      "#>>>    19.51 10.99 \t\t|\t\t 8.520000000000001\n",
      "[Mar 16, 21:16:04] 70 2.1252086938417403\n",
      "\t\t\t\t 0.010168701410293579 0.3542404770851135\n",
      "#>>>    19.59 12.56 \t\t|\t\t 7.029999999999999\n",
      "[Mar 16, 21:16:04] 71 2.123447894326394\n",
      "\t\t\t\t 0.19528251886367798 0.12399084120988846\n",
      "#>>>    19.6 12.41 \t\t|\t\t 7.190000000000001\n",
      "[Mar 16, 21:16:04] 72 2.1216437197846902\n",
      "\t\t\t\t 0.005265446379780769 0.010077634826302528\n",
      "#>>>    20.03 11.22 \t\t|\t\t 8.81\n",
      "[Mar 16, 21:16:04] 73 2.1195374191461114\n",
      "\t\t\t\t 0.009967939928174019 0.017702100798487663\n",
      "#>>>    19.79 10.55 \t\t|\t\t 9.239999999999998\n",
      "[Mar 16, 21:16:04] 74 2.117445551767692\n",
      "\t\t\t\t 0.002904841909185052 0.014073442667722702\n",
      "#>>>    18.93 9.65 \t\t|\t\t 9.28\n",
      "[Mar 16, 21:16:04] 75 2.1153450845002686\n",
      "\t\t\t\t 0.01654403656721115 0.2575172483921051\n",
      "#>>>    19.22 10.57 \t\t|\t\t 8.649999999999999\n",
      "[Mar 16, 21:16:05] 76 2.113503800708178\n",
      "\t\t\t\t 0.00012186149979243055 0.0071309953927993774\n",
      "#>>>    19.33 8.09 \t\t|\t\t 11.239999999999998\n",
      "[Mar 16, 21:16:05] 77 2.111397549764559\n",
      "\t\t\t\t 0.023085054010152817 0.2960013747215271\n",
      "#>>>    19.54 12.03 \t\t|\t\t 7.51\n",
      "[Mar 16, 21:16:05] 78 2.1096052386472515\n",
      "\t\t\t\t 0.00011030055611627176 0.002272631274536252\n",
      "#>>>    20.28 10.12 \t\t|\t\t 10.160000000000002\n",
      "[Mar 16, 21:16:05] 79 2.1074980163403696\n",
      "\t\t\t\t 0.0009242850937880576 0.2933768630027771\n",
      "#>>>    18.8 9.89 \t\t|\t\t 8.91\n",
      "[Mar 16, 21:16:05] 80 2.1056848194762585\n",
      "\t\t\t\t 0.03795737773180008 1.315339207649231\n",
      "#>>>    14.92 8.87 \t\t|\t\t 6.050000000000001\n",
      "[Mar 16, 21:16:05] 81 2.1049324312943174\n",
      "\t\t\t\t 0.0035905074328184128 0.21532592177391052\n",
      "#>>>    20.4 12.54 \t\t|\t\t 7.859999999999999\n",
      "[Mar 16, 21:16:05] 82 2.1030464152940924\n",
      "\t\t\t\t 0.05299347639083862 0.2112114280462265\n",
      "#>>>    19.22 10.97 \t\t|\t\t 8.249999999999998\n",
      "[Mar 16, 21:16:05] 83 2.1012075737981366\n",
      "\t\t\t\t 0.0019341157749295235 0.10455889254808426\n",
      "#>>>    20.19 8.83 \t\t|\t\t 11.360000000000001\n",
      "[Mar 16, 21:16:05] 84 2.0992128592354553\n",
      "\t\t\t\t 0.40917521715164185 0.12521377205848694\n",
      "#>>>    19.45 11.52 \t\t|\t\t 7.93\n",
      "[Mar 16, 21:16:06] 85 2.0976480353952325\n",
      "\t\t\t\t 0.000666690175421536 0.27347448468208313\n",
      "#>>>    18.62 9.13 \t\t|\t\t 9.49\n",
      "[Mar 16, 21:16:06] 86 2.095824528522471\n",
      "\t\t\t\t 0.04988386482000351 0.35562682151794434\n",
      "#>>>    18.79 11.95 \t\t|\t\t 6.84\n",
      "[Mar 16, 21:16:06] 87 2.094134214687737\n",
      "\t\t\t\t 0.008416174910962582 0.10592997074127197\n",
      "#>>>    20.67 8.79 \t\t|\t\t 11.880000000000003\n",
      "[Mar 16, 21:16:06] 88 2.0921544266196324\n",
      "\t\t\t\t 0.0021643496584147215 0.011530720628798008\n",
      "#>>>    19.74 10.4 \t\t|\t\t 9.339999999999998\n",
      "[Mar 16, 21:16:06] 89 2.0900759672635325\n",
      "\t\t\t\t 0.05917597562074661 0.26308828592300415\n",
      "#>>>    19.89 8.3 \t\t|\t\t 11.59\n",
      "[Mar 16, 21:16:06] 90 2.088308155550362\n",
      "\t\t\t\t 0.04338165000081062 0.44176074862480164\n",
      "#>>>    19.86 12.06 \t\t|\t\t 7.799999999999999\n",
      "[Mar 16, 21:16:06] 91 2.086704989804613\n",
      "\t\t\t\t 0.061278317123651505 0.061138223856687546\n",
      "#>>>    19.5 10.31 \t\t|\t\t 9.19\n",
      "[Mar 16, 21:16:06] 92 2.084740701355789\n",
      "\t\t\t\t 0.018152693286538124 0.01933583989739418\n",
      "#>>>    19.44 11.03 \t\t|\t\t 8.410000000000002\n",
      "[Mar 16, 21:16:06] 93 2.0826934491894797\n",
      "\t\t\t\t 0.014334306120872498 0.11667479574680328\n",
      "#>>>    20.23 11.46 \t\t|\t\t 8.77\n",
      "[Mar 16, 21:16:06] 94 2.0807417648421582\n",
      "\t\t\t\t 0.2566324472427368 0.1231403723359108\n",
      "#>>>    19.02 10.3 \t\t|\t\t 8.719999999999999\n",
      "[Mar 16, 21:16:07] 95 2.079040795889444\n",
      "\t\t\t\t 0.11541455239057541 0.10596206039190292\n",
      "#>>>    18.97 11.52 \t\t|\t\t 7.449999999999999\n",
      "[Mar 16, 21:16:07] 96 2.077183131706337\n",
      "\t\t\t\t 0.14415450394153595 0.015533298254013062\n",
      "#>>>    19.9 9.11 \t\t|\t\t 10.79\n",
      "[Mar 16, 21:16:07] 97 2.0752656363768267\n",
      "\t\t\t\t 0.0010507236002013087 0.29122358560562134\n",
      "#>>>    19.49 11.05 \t\t|\t\t 8.439999999999998\n",
      "[Mar 16, 21:16:07] 98 2.0734826450367336\n",
      "\t\t\t\t 0.0007214218494482338 0.20263069868087769\n",
      "#>>>    20.69 10.14 \t\t|\t\t 10.55\n",
      "[Mar 16, 21:16:07] 99 2.071612514515196\n",
      "\t\t\t\t 0.0016840669559314847 0.20141740143299103\n",
      "#>>>    19.95 7.87 \t\t|\t\t 12.079999999999998\n",
      "[Mar 16, 21:16:07] 100 2.0697440034717474\n",
      "\t\t\t\t 2.8221355023561046e-05 0.09454423189163208\n",
      "#>>>    22.12 9.2 \t\t|\t\t 12.920000000000002\n",
      "[Mar 16, 21:16:07] 101 2.0677688319229666\n",
      "[Mar 16, 21:16:07] #> Done with all triples!\n",
      "\n",
      "#> LR will use 10 warmup steps and linear decay over 500000 steps.\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who co-chaired the Mascot Identity Task Force at Carnegie Mellon?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2522,  1011, 12282,  1996, 13314,  4767,  4708,\n",
      "         2486,  2012, 11298, 22181,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:2')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:2')\n",
      "\n",
      "\n",
      "#> LR will use 10 warmup steps and linear decay over 500000 steps.\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who co-chaired the Mascot Identity Task Force at Carnegie Mellon?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2522,  1011, 12282,  1996, 13314,  4767,  4708,\n",
      "         2486,  2012, 11298, 22181,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:1')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:1')\n",
      "\n",
      "\n",
      "#> LR will use 10 warmup steps and linear decay over 500000 steps.\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who co-chaired the Mascot Identity Task Force at Carnegie Mellon?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2522,  1011, 12282,  1996, 13314,  4767,  4708,\n",
      "         2486,  2012, 11298, 22181,  1029,   102,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:3')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:3')\n",
      "\n",
      "#> Saving a checkpoint to .ragatouille/colbert/none/2024-03/16/21.14.40/checkpoints/colbert ..\n",
      "#> Joined...\n",
      "#> Joined...\n",
      "#> Joined...\n",
      "#> Joined...\n",
      "Model fine-tuned and saved at: None\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory where the processed training data has been saved\n",
    "# data_dir = './triplet_data/'\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for fine-tuning used the default ones but added for future configuration\n",
    "batch_size = 32\n",
    "nbits = 2\n",
    "maxsteps = 500000\n",
    "use_ib_negatives = True\n",
    "learning_rate = 5e-6  # Adjust based on your needs and observations\n",
    "dim = 128\n",
    "doc_maxlen = 256\n",
    "use_relu = False\n",
    "warmup_steps = 'auto'  # Auto will default to 10% of total steps\n",
    "accumsteps = 1\n",
    "\n",
    "# Call the train method to start fine-tuning\n",
    "model_path = trainer.train(\n",
    "    batch_size=batch_size,\n",
    "    nbits=nbits,\n",
    "    maxsteps=maxsteps,\n",
    "    use_ib_negatives=use_ib_negatives,\n",
    "    learning_rate=learning_rate,\n",
    "    dim=dim,\n",
    "    doc_maxlen=doc_maxlen,\n",
    "    use_relu=use_relu,\n",
    "    warmup_steps=warmup_steps,\n",
    "    accumsteps=accumsteps\n",
    ")\n",
    "    \n",
    "\n",
    "print(f\"Model fine-tuned and saved at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e128282bf74f538fe1b45912a5e9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import Repository\n",
    "repo = Repository(\".ragatouille/colbert/none/2024-03/16/21.14.40/checkpoints/colbert\", clone_from=\"your-hf-username/your-model-name\", use_auth_token=True)\n",
    "repo.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_HOME=$CONDA_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: faiss_gpu-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install https://github.com/kyamagu/faiss-wheels/releases/download/v1.7.3/faiss_gpu-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG = RAGPretrainedModel.from_pretrained(\"EddieT/colbert_cmu_lti_finetunev2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Base directory containing your folders\n",
    "base_dir = \".\"\n",
    "\n",
    "# Folders containing your data\n",
    "folders = [\"About Scottie\", \"Buggy News\", \"history_of_cmu\", \"history_of_scs\", \"Kiltie Band\", \"lti_faculty\", \"lti_programs\", \"Tartan Facts\", \"courses\", \"../academic_calendars\", \"../program_handbooks\", \"../Web Scholar PDFs\"]\n",
    "\n",
    "# Initialize empty list to hold all document texts\n",
    "collection = []\n",
    "# Optionally, prepare a list for document IDs if you wish to use custom IDs\n",
    "# document_ids = []\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    \n",
    "    # Iterate over each text file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\") and filename != \"annotation.txt\":\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                # Read the document content and add it to the collection\n",
    "                document_text = file.read()\n",
    "                collection.append(document_text)\n",
    "                \n",
    "                # Optionally, add a custom document ID, e.g., foldername-filename\n",
    "#                 document_id = f\"{folder}-{filename}\"\n",
    "#                 document_ids.append(document_id)\n",
    "\n",
    "# At this point, `collection` contains all your documents, and `document_ids` contains their IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "print(len(collection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already up-to-date: ninja in /home/trevea/.local/lib/python3.7/site-packages (1.11.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Mar 16, 22:42:52] #> Note: Output directory .ragatouille/colbert/indexes/colbertv2.0_cmu_lti_finetunev2.0 already exists\n",
      "\n",
      "\n",
      "[Mar 16, 22:42:52] #> Will delete 1 files already at .ragatouille/colbert/indexes/colbertv2.0_cmu_lti_finetunev2.0 in 20 seconds...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "nranks = 4 \t num_gpus = 4 \t device=1\n",
      "[Mar 16, 22:43:20] [1] \t\t #> Encoding 282 passages..\n",
      "#> Starting...\n",
      "nranks = 4 \t num_gpus = 4 \t device=2\n",
      "[Mar 16, 22:43:23] [2] \t\t #> Encoding 282 passages..\n",
      "nranks = 4 \t num_gpus = 4 \t device=3\n",
      "[Mar 16, 22:43:26] [3] \t\t #> Encoding 281 passages..\n",
      "nranks = 4 \t num_gpus = 4 \t device=0\n",
      "[Mar 16, 22:43:26] [0] \t\t #> Encoding 282 passages..\n",
      "[Mar 16, 22:43:28] [0] \t\t avg_doclen_est = 172.61654663085938 \t len(local_sample) = 282\n",
      "[Mar 16, 22:43:28] [3] \t\t avg_doclen_est = 172.61654663085938 \t len(local_sample) = 281\n",
      "[Mar 16, 22:43:28] [2] \t\t avg_doclen_est = 172.61654663085938 \t len(local_sample) = 282\n",
      "[Mar 16, 22:43:28] [1] \t\t avg_doclen_est = 172.61654663085938 \t len(local_sample) = 282\n",
      "[Mar 16, 22:43:28] [0] \t\t Creating 4,096 partitions.\n",
      "[Mar 16, 22:43:28] [0] \t\t *Estimated* 194,538 embeddings.\n",
      "[Mar 16, 22:43:28] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/colbertv2.0_cmu_lti_finetunev2.0/plan.json ..\n",
      "Clustering 184815 points in 128D to 4096 clusters, redo 1 times, 20 iterations\n",
      "  Preprocessing in 0.01 s\n",
      "  Iteration 19 (0.47 s, search 0.37 s): objective=36871.2 imbalance=1.399 nsplit=0       \n",
      "[Mar 16, 22:43:31] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/infra/launcher.py\", line 134, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 33, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 68, in run\n",
      "    self.train(shared_lists) # Trains centroids from selected passages\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 237, in train\n",
      "    bucket_cutoffs, bucket_weights, avg_residual = self._compute_avg_residual(centroids, heldout)\n",
      "                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/collection_indexer.py\", line 315, in _compute_avg_residual\n",
      "    compressor = ResidualCodec(config=self.config, centroids=centroids, avg_residual=None)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/codecs/residual.py\", line 24, in __init__\n",
      "    ResidualCodec.try_load_torch_extensions(self.use_gpu)\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexing/codecs/residual.py\", line 103, in try_load_torch_extensions\n",
      "    decompress_residuals_cpp = load(\n",
      "                               ^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1306, in load\n",
      "    return _jit_compile(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1710, in _jit_compile\n",
      "    _write_ninja_file_and_build_library(\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1793, in _write_ninja_file_and_build_library\n",
      "    verify_ninja_availability()\n",
      "  File \"/home/trevea/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1842, in verify_ninja_availability\n",
      "    raise RuntimeError(\"Ninja is required to load C++ extensions\")\n",
      "RuntimeError: Ninja is required to load C++ extensions\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolbertv2.0_cmu_lti_finetunev2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Choose an appropriate name for your index\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming RAG is your initialized RAGPretrainedModel with the loaded checkpoint\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m index_path \u001b[38;5;241m=\u001b[39m \u001b[43mRAG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;43;03m#     document_ids=document_ids,  # Include this only if you prepared document IDs\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True to overwrite existing index of the same name\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_document_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust based on your document length distribution\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True if documents should be split into shorter segments\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex created at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/ragatouille/RAGPretrainedModel.py:210\u001b[0m, in \u001b[0;36mRAGPretrainedModel.index\u001b[0;34m(self, collection, document_ids, document_metadatas, index_name, overwrite_index, max_document_length, split_documents, document_splitter_fn, preprocessing_fn, bsize)\u001b[0m\n\u001b[1;32m    201\u001b[0m     document_splitter_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    202\u001b[0m collection, pid_docid_map, docid_metadata_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_corpus(\n\u001b[1;32m    203\u001b[0m     collection,\n\u001b[1;32m    204\u001b[0m     document_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     max_document_length,\n\u001b[1;32m    209\u001b[0m )\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpid_docid_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpid_docid_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocid_metadata_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocid_metadata_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_document_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_document_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/ragatouille/models/colbert.py:368\u001b[0m, in \u001b[0;36mColBERT.index\u001b[0;34m(self, collection, pid_docid_map, docid_metadata_map, index_name, max_document_length, overwrite, bsize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexer \u001b[38;5;241m=\u001b[39m Indexer(\n\u001b[1;32m    363\u001b[0m     checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint,\n\u001b[1;32m    364\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    365\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    366\u001b[0m )\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexer\u001b[38;5;241m.\u001b[39mconfigure(avoid_fork_if_possible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 368\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m    373\u001b[0m     Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mroot)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mexperiment)\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_name\n\u001b[1;32m    377\u001b[0m )\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m    379\u001b[0m     Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mroot) \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mexperiment) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexer.py:80\u001b[0m, in \u001b[0;36mIndexer.index\u001b[0;34m(self, name, collection, overwrite)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merase()\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_does_not_exist \u001b[38;5;129;01mor\u001b[39;00m overwrite \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreuse\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/indexer.py:98\u001b[0m, in \u001b[0;36mIndexer.__launch\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m     95\u001b[0m shared_queues \u001b[38;5;241m=\u001b[39m [manager\u001b[38;5;241m.\u001b[39mQueue(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnranks)]\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Encodes collection into index using the CollectionIndexer class\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m \u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_queues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/site-packages/colbert/infra/launcher.py:72\u001b[0m, in \u001b[0;36mLauncher.launch\u001b[0;34m(self, custom_config, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m print_memory_stats(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAIN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# TODO: If the processes crash upon join, raise an exception and don't block on .get() below!\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([\u001b[43mreturn_value_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m all_procs])\n\u001b[1;32m     73\u001b[0m return_values \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m rank, val \u001b[38;5;129;01min\u001b[39;00m return_values]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_all:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/connection.py:430\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 430\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-rag/lib/python3.12/multiprocessing/connection.py:395\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "index_name = \"colbertv2.0_cmu_lti_finetunev2.0\"  # Choose an appropriate name for your index\n",
    "\n",
    "# Assuming RAG is your initialized RAGPretrainedModel with the loaded checkpoint\n",
    "index_path = RAG.index(\n",
    "    collection=collection,\n",
    "#     document_ids=document_ids,  # Include this only if you prepared document IDs\n",
    "    index_name=index_name,\n",
    "    overwrite_index=True,  # Set to True to overwrite existing index of the same name\n",
    "    max_document_length=256,  # Adjust based on your document length distribution\n",
    "    split_documents=True,  # Set to True if documents should be split into shorter segments\n",
    ")\n",
    "\n",
    "print(f\"Index created at: {index_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-rag",
   "language": "python",
   "name": "nlp-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
